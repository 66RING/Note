---
title: 爬虫学习笔记
date: 2019-2-29
tags: python, spider
---


## 正则表达式 re解析模块

### 最常规的匹配

``` python
import re

content = "hello 123 1234 world_this is a regex demo"
# re.match(pattern,string,flags = 0)   pattern和string比返回boolean
result = re.match('^hello\s\d\d\d\s\d{4}\s\w{10}.*demo$',content)
#   ^匹配字符串开头 空格 三个数分开读 空 四个数一起读 空格 匹配字母 .代替任意字符 指定结尾
print(result)
```

### 泛匹配

``` python
import re

content = "hello 123 1234 world_this is a regex demo"
result = re.match('^helle.*demo$',content)
# .*  匹配了中间所以字符 具体baidu
```

### 匹配目标

``` python
import re

content = "hello 123 1234 world_this is a regex demo"
result =  re.match('^hello\s(\d+)\sworld.*demo$',content)
print(result.group(1)) # 第一个括号的内容
```

### 贪婪匹配

``` python
import re

content = "hello 123 1234 world_this is a regex demo"
result =  re.match('^he.*(\d+).*demo$',content)
print(result.group(1))
# 结果 4  因为he后4前都被.*匹配了 但是(\d+)要求至少一个数字
```

### 非贪婪匹配

``` python
import re

content = "hello 123 1234 world_this is a regex demo"
result =  re.match('^he.*?(\d+).*demo$',content)
#                ?匹配0个或1个正则表达式，.*匹配了he后面的字母，数字前有个空格，那就被?匹配下来了
print(result.group(1))
# 结果 123 匹配尽可能少 碰到了数字就停止前面的匹配
```

### 匹配模式

``` python
import re

content = '''hello 123 1234 world_this is
a regex demo
'''
result =  re.match('^he.*?(\d+).*?demo$',content)
print(result)
# 结果None 因为.匹配不到换行符
result =  re.match('^he.*?(\d+).*?demo$',content,re.S)# 加了这个参数就可匹配任意字符了
```

### 转义

``` python
# 就像想要输出带有\n之类的字符串的话...
# 和传统的一样特殊字符前加 \  把特殊字符转义了
import re

content1 = 'price is $5.00'
result1 =  re.match('price is $5.00',content)
result2 =  re.match('price is \$5\.00',content)
print(result)
```

总结：尽量使用泛匹配，使用括号得到匹配目标，尽量使用非贪婪模式，要匹配换行符记得参数 re.S

### re.search vs re.match

``` python
# re.match从开头开始匹配 配不上就None
# re.search从第一个出现的字符开始匹配
```

### re.findall

``` python
# 搜索全部，以列表形式返回所有能匹配的子串，列表的每个元素是个元组
```

### re.sub

``` python
# 替换字符串中每一个匹配的子串,返回替换后的字符串
#            ^
import re

content = 'hello 123 1234 world_this isa regex demo'
result = re.sub('\d+','hhh',content)
print(result)

####
#那如果要在原字符串上增加呢
#截取，拼接，替换
import re

content = 'hello 123 1234 world_this isa regex demo'
result = re.sub('(\d+)',r'\1hhh',content)
#                ^存组    ^用\1取第一组，r是取消\的转义作用
print(result)
```

### re.compile

``` python
# 将正则字符串编译成正则表达式对象，！！！以便复用这个匹配模式
import re

content = '''hello 123 1234 world_this 
is a regex demo'''
pattern = re.compile('hello.*',re.S) # 匹配模式存为了 pattren
result = re.match(pattern,content)   # 以后就能直接用这种方法
print(result)
```

## BeautifulSoup

### 解析库

​		1.Python标准库   用法： BeatufulSoup(markup,'html.parser')
​		2.lxml HTML解析器  用法： BeatufulSoup(markup,'lxml')
​		3.lxml XML 解析器  用法： BeatufulSoup(markup,'xml')
​		4.html5lib  用法： BeatufulSoup(markup,'html5lib')

``` python
# 导入
from bs4 import BeatufulSoup
```

### 基本用法

``` python
from bs4 import BeatufulSoup

html = '''
   各种标签
'''
soup = BeatifulSoup(html,'lxml')
print(soup.prettify())  # 格式化代码 自动补全
print(soup.title.string) # 打印title标签里面的内容 
```

### 标签选择器

``` python
# 用法同上的 title
# 只返回第一个匹配的结果
```

#### 获取名称

``` python
soup.标签.name
```

#### 获取属性

``` python
soup.标签.attrs['属性名称']
#也可
soup.标签['属性名称']
```

#### 获取内容

```python
soup.标签.string
```

#### 嵌套选择

``` python
# 标签是套娃娃的嘛 so
soup.标签.标签. # 标签的子标签
```

#### 子节点和子孙节点

``` python
# 1
soup.标签.contents # 获取标签所有的子节点  返回列表

# 2
soup.标签.children # 迭代器

#3
soup.标签.decendants # 获取子孙节点(子的子也获取)  返回迭代器
```

#### 父节点于祖先节点

``` python
# 1
soup.标签.parent # 获取父节点

# 2
soup.标签.parent # 获取所有祖先节点
```

#### 兄弟节点

``` python
soup.标签.next_siblings # 获取后面的兄弟节点
soup.标签.previous_siblings # 获取前面的兄弟节点
```

### 标准选择器

``` python
# find_all(name, attrs, recursive, text, **kwargs)
可根据签名，属性，内容查找
soup.find_all('标签') # 返回的是列表的形式，可层层嵌套
```

#### attrs

``` python
soup.find_all(attrs={'属性名':'属性值'}) 
```

#### text

``` python
soup.find_all(text='内容') # 根据文本内容选择，返回内容的列表//好鸡肋
```

#### find扩展

``` python
find：类似find_all，但只返回第一个匹配结果
find_parent()  find_parents()
find_next_siblings()....等等
```

### CSS选择器

``` python
# 通过select()直接传入CSS选择器即可完成选择
1.选class
2.选标签
3.选id
```

### 获取内容

``` python
.get_text()
```

## PyQuery

像jQuery

### 初始化

``` python
from pyquery import PyQuery as pq # 导入
```

#### 字符串初始化

``` python
# 用法同上的标签选择器 class记得点和空格...
html = '''
    <div id="fakebox-container">
      <ul id="fakebox">
        <li id="fakebox-search-icon"></li>
        <li id="fakebox-text"></li>
        <input id="fakebox-input" autocomplete="off" tabindex="-1" type="url" aria-hidden="true">
        <li id="fakebox-cursor"></li>
        <button id="fakebox-microphone" hidden=""></button>
      </ul>
    </div>
'''
doc = pq(html)
print(doc('标签'))
```

#### URL初始化

``` python
doc = pq(url='')
print(doc('标签'))
```

#### 文件初始化

``` python
doc = pq(filename='路径')
print(doc('标签'))
```

### 基本CSS选择器

``` python
html = '''  '''
doc = pq(html)
print(doc('#   .   签名')	) # 可层级关系 空格隔开表嵌套，直接写在后表并列
# 按id找的前面加#   按class找的加.    标签找的直接签名   ps.class=''   id=''按内容找
```

### 查找元素

#### 子元素

``` python
html = '''  '''
doc = pq(html)
items = doc('.list')
lis = items.find('li') # 找所有
```

``` python
items.children()
```

#### 父元素

``` python
items.parent() # 拿到父元素
items.parents() # 拿所有祖先  
# 括号内可用CSS选择器筛选
```

#### 兄弟元素

``` python
items.siblings()  # 也可选择器筛选
```

### 遍历

```python
lis = doc('签名').items()  # 生成一个生成器，那就可for了
```

### 获取信息

#### 获取属性

```python
XXX.attr('属性名') # 和之前是一样的
```

#### 获取文本

``` python
.text()
```

#### 获取HTML

``` python
.html()  # 把里面的html(代码)获取出来
```

### DOM操作

#### addClass、removeClass

```python
.addClass 
.removeClass # 增减class(某个标签的)
```

#### attr、css

```python
.attr('A','B') # 增加一个 A=B的属性，如果已经存在就覆盖掉
。css('A','B') #增加一个sytle (width:10px)
```

#### remove

```python
.remove() # 删掉选中的内容
```

还有其他很多方法

### 伪类选择器

```python
doc = pq(html)
doc('标签:first-child') # 等等
doc('标签:nth-child(n)') # 低n个子
```

## Selenium

自动化测试工具，支持多浏览器，爬虫中主要用了解决JavaScript渲染问题

### 基本使用

```python
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.support.wait import WebDriverWait

browser = webdriver.Chrome() # 声明浏览器驱动对象，别的浏览器同理
try:
    browser.get('https://www.baidu.com') # 传入url，跳出浏览器，访问那个网址
    input = browser.find_element_by_id('kw') # 通过id找出信息
    input.send_keys('Python') # 向元素中发送一些键
    input.send_keys(Keys.ENTER) # 然后回车
    wait = WebDriverWait(browser,10) # 等待
    wait.until(EC.presence_of_element_located((By.ID,'content_left'))) # 等待id是con..那个元素被加载出来
    print(browser.current_url) # 打印出url
    print(browser.get_cookies()) # 打印
    print(browser.page_source) #打印源代码
finally:
    browser.close()
```

### 查找元素

#### 查找单个元素

```python
.find_element_by_id('id')
.find_elements_by_css_selector('#')
.find_elements_by_xpath('') # 等等很多方法
```

```python
# 法2
# 例
.find_elements(BY.ID,'id') #上述方法的通用实现 根据BY的不同不同
```

#### 查找多个元素

```python
# 同上只是用find_elements,返回列表
#                      ^
```

### 元素交互操作

```python
# 输入，点击等
.send_keys('')
.clear() # 清空
.click() # 等等等等
# 更多在WebDriver API ->webelement
```

### 交互动作

```python
# 不同于上，是将动作附加的动作链中串行执行
# 更多...WebDriver API ->Action Chains
```

### 执行JavaScript

```python
browser = webdriver.Chrome() 
browser.get('https://www.baidu.com')
browser.execute_script('js代码') # 这样传入js代码
```

### 获取元素信息

#### 获取属性

```python
# 通过find找到后
# .get_attribute('class') #获取class的属性
```

#### 获取文本值

```pytohn
.text
```

#### 获取ID、位置、标签名、大小

```python
.id
.location
.tag_name
.size
```

#### Frame

```python
# 雾
```

### 等待

确保元素加载完全

#### 隐式等待

到了一定时候发现元素还没加载出来，那继续等，超时抛出异常

```python
.implicitly_wait(等待时间)
```

#### 显示等待

指定一个等待条件，指定一个最长等待时间，超时抛异常

```python
# 有很多等待条件，如：
title_is
title_contains
# ...更多WebDriver API ->Expected condition Support
```

### 前进后退

浏览器的前进后退

```python
browser.forward()
browser.back()
```

### Cookies

```python
.get_cookies()
.add_cookies()
.delete_all_cookise()
# 等等
```

### 选项卡管理

（标签页）

```python
# 通过执行js控制
.......
```

### 异常处理

```python
# 官方文档
# ...更多WebDriver API -> Exception
```





























pass
