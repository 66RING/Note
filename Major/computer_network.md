---
title:  自顶向下计算机网络
date: 2020-3-25
---

#  自顶向下计算机网络

## 基本概念

- ISP: Internet Server Provider
- 拓扑：连线的方式
- 吞吐量：水管的大小
- 流量：网速
- 网络大小划分  
	- PAN:personal area network
	- LAN:局域网
	- MAN:城局域网
	- WAN:广局域网
	- 互联网（最大）


### IP地址

IPv4由32个位组成, 通常8个一组如192.168.1.1

前28个位为**网络编号**, 后4位为**主机编号**

**子网掩码**: 子网掩码的1对应网络位的编号, 子网掩码的0对应主机位的编号, 如255.255.255.0
- 作用: 限制广播的网络段, 将莫大的网络划分变小

**子网**表示方法: 网络编号 + 主机号 + / + 子网掩码1的个数
- 如:192.168.1.0/24, 子网掩码为255.255.255.0

**网段地址**: 每个网段的第0个地址
- 如:192.168.1.0. 0 = 0000 0000, 第0号主机

**广播地址**: 网段的最后一个IP地址
- 如:192.168.1.255. 255 = 1111 11111, 最后一个主机


### 路由

路由器的作用是实现跨网段的数据传输和转发, 类似于向导的作用, 这种指引的行为就叫最**路由**


#### 路由表

转发的指南

``` 
再linux下使用: route -n 可以查看路由表
:$ route -n  // 结果有8列
Destination  Gatewaty  Genmask  Flags  Metric  Ref  Use  Iface
```

分别为目的地址, 网关地址, 网关掩码, 最后一列为网卡

Flags带有G的说明是网关规则,
若数据包的目的IP与路由表的目的地址匹配,
路由器会将数据包(通过网卡)转发到Gateway中的网关地址,

如果Flags没有带G, 说明不是网关规则,
目标地址肯定就在本地链路通过用一个交换机相连

通过`traceroute -n IP`可以查看中途经过了哪些路由器

那路由表从何而来呢?
- 直连路由
    - 当主机配置好一个IP后, 会自动生成一个目的地址为该子网的路由
- 手动添加路由(静态路由)
- 通过动态路由协议获取


#### 路由器的功能

- DHCP
    - Dynamic Host Configuration Protocal, 动态主机配置协议
- (S)NAT/DNAT
    - (Source) Network Address Translation
    - 源地址转换NAT功能, 也叫IP伪装
    - 数据包在出路由器前会将数据包的源IP地址转换为路由器WAN口的公网IP地址, 以便被别人找到. 
        - 因为192.168.0.4等是私有的
- DNAT
    - 目的地址转换NAT功能
    - DNAT就是NAT的逆向
    - 实现公网对内部主机的主动访问


#### 路由器的桥接

把路由器的LAN合并到一起, 注意一下关键点
- 在一个LAN中IP地址必须唯一
    - 故从路由的的LAN必须和主路由属于同一网段, 并IP地址唯一
- 在一个LAN中最多有一个DHCP服务器
    - 故要关闭从路由的DHCP功能



## 参考模型  

### 分层原理

信宿机第n层收到的对象应与信源机第n层发出的对象完全一致.
好比做飞机的登机口和下机口

每一层都为他的上一层服务  
信息发送方要做什么:  
- 封装/打包:  
	- 然后从最高层逐层传到物理层
- 每一层上，数据都会被加上头部信息，用于信息传递  

收方要做什么:  
- 解封装/解包  


#### 典型的分层模型:

- ISO OSI 七层模型  
	- 应用层
    - 表示层
    - 会话层
    - 传输层
    - 网络层
    - 数据链路层
    - 物理层
- TCP/IP (DoD) 四层模型  
	- 应用层
    - 传输层
    - 网络互联层
    - 主机到网络层


## 应用层

### 应用程序体系结构

- 客户-服务器体系结构
    - 至少一个服务器主机负责处理多个来自客户主机的请求
- P2P体系结构
    - 主机到主机, 这些主机称为对等方

### 基本概念

- 套接字: socket
    - 进程通过socket的软件接口向网络发送报文和传输报文
        - 好比房子的大门
    - 套接字地址: ip + port
- API: Application Programming Interface

### HTTP

HTTP(HyperText Transfer Protocal, 超文本传输协议)是Web的核心, 客户端和服务器通过交换HTTP报文进行会话. HTTP使用TCP作为它的支撑传输协议, 即先建立TCP连接, 再通过TCP连接向彼此套接字发送报文. 

- TCP为HTTP提供了可靠数据传输服务
    - 即发出的每个请求到能完整的到达目的地
- HTTP是一个无状态协议


- 持续连接的HTTP
    - 可以一个接一个发送请求
- 非持续连接的HTTP
    - 发送一个对象后TCP连接关闭


#### HTTP报文格式

请求报文
- 请求行
    - 方法 URL 版本
    - 包含一系列必要信息
- 首部行
    - 首部字段: 值
    - 相当于指定配置
- 空行
- 实体主体
    - 使用POST方法时才使用

``` 
--- 请求行 ---
GET /some/dir HTTP/1.1
--- 首部行 ---
Host: www.some.com           # 指明对象所在的主机, 该首部行的Web高速缓存所要求的
Connection: close            # 非持续连接
User-agent: Mozilla/5.0      # 发送请求的浏览器类型
# 还会有很多的配置
```

HTTP使用的方法
- GET
- POST
- HEAD
    - 类似GET, 但不返回请求对象
- PUT
    - 允许用户上传对象到指定Web服务器
- DELETE
    - 允许用户删除服务器上的对象

响应报文
- 状态行
    - 版本 状态码 短语
    - 常见状态码
        - 200 请求成功
        - 301 请求的对象已被永久转移
        - 400 Bad Request 请求不能被理解
        - 404 Not Found 请求的文档不在服务器上
        - 505 服务器不支持请求报文的HTTP版本
- 首部行
- 空行
- 实体主体


#### cookie

前面提到HTTP服务器是无状态的, 所以要想内容和用户身份联系起来就要使用cookie.

``` sequence-diagrams
client->server: request
server-->client: response + cookie
client->server: request + cookie
server-->client: response
```


#### Web缓存

Web缓存器也叫代理服务器. Web缓存器既是服务器又是客户端, 它会把请求的结果保存在本地. 在遇到相同的请求是可以由本地数据提供

可以减少网络负担. 如在高速的局域网络架设缓存器

HTTP协议有一种机制, 允许缓冲器证实它的对象是最新的. 这种机制叫做**条件GET**. 使用含有`If-Modified-Since: Date`请求行


### FTP

文件传输协议

区别于HTTP, FTP也运行在TCP上, 但是它使用两个并行的TCP连接来传输文件: 一个是**控制连接**, 一个是**数据连接**.


### 因特网中的电子邮件

由三个部分组成: 用户代理, 邮件服务器, 简单传输协议(SMTP).
邮件通过SMTP在邮件服务器中传递, 在由邮件服务器分发给对应用户.


### DNS

域名系统(Domain Name System, DNS)


#### Host

除了DNS可以解析域名外, Host也能解析域名.
IP信息和域名信息的映射表.
Host映射的优先级要高于DNS.


#### DDNS

动态域名系统(Dynamic Domain Name System). 
其主要作用的动态更新dns服务器上的IP地址.
方便域名与IP的映射.  

可以自己写程序/脚本实现
- 思路1:
    - 调用dns服务商的api实现更新ip地址


## 运输层

运输层协议是在端系统中而不是路由器中实现的. 运输层把应用程序发送的报文转换成运输层分组, 该分组称谓运输层**报文段**.

在发送端系统中, 运输层将这些报文段传递给网络层, 网络层对其封装成网络层分组即(**数据报**)

网络层提供了主机之间的逻辑通信, 而运输层为运行在不同主机上的进程之间提供了逻辑通信.
网络层相当与邮递员负责送到家门口, 分发还得靠运输层, 所以说网络层是运行在主机间, 运输层才是运行在进程间的(端系统), 运输层负责把报文移动到网络边缘(网络层).

- 多路复用
    - 负责收集各个端口的报文, 为每个数据快封装上首部信息后传递到网络层
- 多路分解
    - 运输层负责获取从网络层接收到的报文首部中端口的信息, 并分发到适当的程序中


### 可靠数据传输(RDT)原理

- rdt1.0
    - 停等型
        - 浪费大量时间
    - 通过返回的报文确定是否需要重传
        - 会浪费大量资源重传分组
        - 返回报文也可能有误
- rdt2.0
    - 停等型
    - 肯定回复(ACK)或者否定回复(NAK)负责校验数据是否受损
    - 使用序号的概念,  分分为发送序号和期望序号, 用于检测是否失序
        - 序号可以解决多余的重传
        - 由于期望序号的存在, 也可解决返回报文的差错问题
        - 但接收方没收到会导致等待时间无限增加
- rdt3.0
    - 加入定时器的概念
        - 超时自动重发


#### 流水线可靠数据传输协议

上面提到的协议都是停等型, 性能不能使人满意, 使用窗口/流水线型提高效率

- 流水线
    - 对所有的分组使用序号空间进行编号
        - 序号空间: 如1, 2, 3, 1, 2, 3.序号空间就是1, 2, 3
    - 为什么使用序号空间
        - 报文的比特位是有限的
- 窗口
    - 流水线上一个范围内的分组
    - 为什么使用窗口
        - 报文的比特位是有限的


比较完善的选择重传(SR)协议
    - 校验和
        - 用于检测传输分组中的比特错误
    - 定时器
        - 用于重传丢失的分组
    - 序号
        - 用于检测分组是否失序或冗余
        - 已经接收到的分组可以储存在缓存中, 待顺序恢复后上报
    - 确认/否定确认
        - 接受放通过校验和检测到比特是否出错, 需要回复发送方
    - 窗口/流水线
        - 允许一次发送多个分组
        - 对于SR协议来说, 窗口长度要小于或等于序号空间大小的一半


## 网络层

网络层对运输层发送是分组(数据段)封装成网络层分组, 该分组称为**数据报**.

重要概念
- 转发
    - 涉及分组在单一路由器中一条入链路到一条出链路的传送
- 路由选择
    - 设计所以的路由器经过路由选择协议共同交互, 以决定到达目的地采用的路径


### 网络服务模型

网络层能够提供的某些可能的服务
- 确保交付
    - 确保分组最终将到达目的地
- 具有延时上界的确保交付
- 有序分组交付
- 确保最小带宽
- 确保最大时延抖动
    - 分组间的时延间隔变化不超过某个值
- 安全性服务
    - 数据加密

因特网的网络曾提供了单一的服务: 成为尽力而为服务


#### ATM网络体系结构

ATM网络体系结构提供了多重服务模型, 可以为不同的连接提供不同类型的服务. 其中两个重要的ATM服务模型
- **恒定比特率(CBR)ATM网络服务**
- **可用比特率(ABR)ATM网络服务**


### 虚电路和数据报

网络层提供了主机到主机的连接服务, 或者主机到主机的无连接服务, 而不提供两者. 
仅在网络层提供提供连接服务的计算机网络称为**虚电路(VC)网络**. 
仅在网络层提供提供无连接服务的计算机网络称为**数据报网络**. 


#### 虚电路

虚电路的组成如下:
- 源和目的主机间的路径
- VC号
    - 连着该路径的每段链路的一个号码
- 沿着该路径的每台路由器中转发表的表项
    - 一条虚电路在每条链路上可能具有不同的VC号, 每个中间路由器必须用新的VC号代替每个传输分组的VC号. 
    - 转发表: 当建立连接(虚电路)时增加一项, 终止时删除

一个分组沿其路由在每条链路上不简单保持相同VC号的原因:
- VC字段长度有限
    - 网络有上亿个链路不应一一编码, 浪费资源
- 简化虚电路的建立
    - 每个路由器只用维护自己本地的路由表


#### 数据报网络

在数据报网络中, 每当一个端系统要发送分组, 它就为该分组加上端系统的地址, 然后推进网络中. 
它通过一系列路由传递, 路由器使用其目的地址通过转发表转发. 

数据报网络中的转发表通过路由选择算法进行修改, 通常每1~5分钟更新一次. 
由于转发表随时可能发生变化, 所以一系列分组可能通过不同的路径到达目的, 并可能无序到达.


### 路由器工作原理

输入端口 --> 交换结构(路由选择处理器) --> 输出端口

- 输入端口
    - 将一条输入的物理层链路与路由相连接(一种物理层功能)
    - 需要与位于入链路远端的数据链路层交互(数据链路层功能)
    - 查找功能, 查询转发表决定路由器的输出端口
    - 控制分组从输入端口转发到路由选择器
- 交换结构
    - 路由器内部的一种网络, 连接输入和输出端口
- 输出端口
    - 储存从交换结构接收的分组, 并通过执行必要的链路层和物理层功能在输入链路上(下一个路由器)传输这些分组
- 路由选择处理器
    - 执行路由选择协议, 维护路由表及连接的状态信息, 并为路由器计算转发表

这些功能有时总称为**路由转发平面**


#### 输入端口

输入端口的查找功能能让分组通过交换结构转发到输出端口. 
路由表是由路由选择器计算和更新的, 但会在输入端口保存一份路由表的副本以完成查询功能.
路由表从路由选择器通过独立的总线(如PCI总线)复制到路由卡. 
有了副本, 转发决策能在输入端口进行, 无需调用中央路由选择器, 避免了处理瓶颈. 

查找功能实现的要点:
- 必须使用硬件执行查找
- 需要对大型转发表使用超出简单线性搜索的技术: 快速查找算法
- 注意内存访问的时间

一个分组可能在进入交换结构的时候被暂时阻塞, 这时需要在输入端口处排队. 

输入端口出来要执行重要的查找操作, 还要采用许多其他动作:
- 必须出现物理层和链路层处理
- 必须检查分组的版本号, 检验和以及寿命字段
- 必须更新用于网络管理的计数器


#### 交换结构

交换结构的方式
- 经内存交换
- 经总线交换
- 经互联网络交换


#### 排队处理

在输入端口和输出端口这样的"交叉路口"中会出现排队问题.
随着队伍的增长, 缓存空间最终会耗尽, 导致出现丢包现象. 

缓存设置的经验:
- 少连TCP流时
    - 缓存量等于平均往返延时(RTT)乘链路容量(C)
    - $B = RTT \times C$
- 大量TCP流(N)时
    - $B = RTT \times \frac{C}{\sqrt{N}}$

输出端口出现排队的原因: 假设有N条输入段, N条输出段链路, 每条链路传输速度是一样的.
交换的处理速度是每条链路速度的N被, 则若N条输入最终指向同一输出时, 就会出现阻塞.

输出端口排队的后果是在输出端口上的**分组调度程序**必须选择队列中一个分组进行发送. 
选择的原则可以是:
- 先来先服务(FCFS)
- 加权公平排队(WFQ)

这些分组丢弃与标记的策略叫做**主动队列管理(AQM)**算法.
**随机早期检测(RED)**算法是最广泛研究和实现的AQM算法.

RED算法
- 为输出队列维护一个加权平均值
- 这个平均值小于最小阀值则正在接收
- 这个平均值大于最小阀值小于最大阀值则以某种概率标记或丢弃
- 这个平均值大于最大阀值则标记或丢弃
 
输入端口出现排队的原因: 交换结构不够快. 
因为交换结构一次只能传递一个分组. 
若前方的分组正在排队, 后方分组的出口就算空闲也得等待前方排队完成. 
这种现象叫做输入排队交换机中的**线路前部(HOL)阻塞**.


### 网际协议(IP): 因特网中的转发和编址

因特网的网络层有三个主要组件:
- IP协议
- 路由选择
- 报告数据报中的差错和对某些网络层信息请求进行响应


#### 数据报格式

IPv4中的关键字:
- 版本号
- 首部长度
- 服务类型
- 数据包长度
- 标识, 状态, 片偏移
- 寿命
- 协议
- 首部校验和
- 源和目的的IP地址
- 选项
- 数据(有效载荷)

一条链路层帧能承载的最大数据量叫做**最大传输单元(MTU)**. 
每条链路可能运行具有不同MTU的链路层协议.
当MTU小于数据报长度时, 需要将输出包封装在更小的IP数据报中. 
这些较小的数据包叫做片(fragment)

IPv4设计者将标识, 标志和片偏移字段放在IP数据报首部, 以执行重新组合任务. 
由于IP是一种不靠谱的服务, 数据报可能丢失或失序.
所以需要偏移量来保证顺序, 标志字段来保证完整. 
最后一片标志比特设置为0, 其他片设置为1. 

在目的地, 数据段的有效载荷仅当在IP层已完全重构为初始IP数据报时才被传输到运输层. 
配合TCP就能实现丢包的恢复. 

分片的弊端:
- 有额外的开销
- 让路由器和端系统更复杂
- 能够用于DoS攻击, 攻击者发送一系列古怪的无法预测的片

IPv6从根本上废止了分片.


### IPv4编址

主机与物理链路之间的边界叫做**接口(interface)**, 
路由器与它任意一条链路之间的边界也叫做接口. 
因此IP地址技术上是一个接口相关联的, 而不是主机或路由相关联的. 

IPv4由32个位组成, 通常8个一组如192.168.1.1

前28个位为**网络编号**, 后4位为**主机编号**

**子网掩码**: 子网掩码的1对应网络位的编号, 子网掩码的0对应主机位的编号, 如255.255.255.0
- 作用: 限制广播的网络段, 将莫大的网络划分变小

**子网**表示方法: 网络编号 + 主机号 + / + 子网掩码1的个数
- 如:192.168.1.0/24, 子网掩码为255.255.255.0

**网段地址**: 每个网段的第0个地址
- 如:192.168.1.0. 0 = 0000 0000, 第0号主机

**广播地址**: 网段的最后一个IP地址
- 如:192.168.1.255. 255 = 1111 11111, 最后一个主机

子网的定义:
- 分开主机和路由器的每个接口, 产生几个隔离的网络岛, 使用接口端接这些隔离的网络端点, 这些隔离的网络中没一个叫做一个子网. 

较低阶的比特可能(或可能不)具有另网的子网结构. 


#### 获取一块IP地址

ISP可能会从已经分配给它的更大快地址中提供一些地址. 
ISP的IP地址又由因特网名字和编号分配机构(ICANN)管理.


#### 获取主机地址: 动态主机配置协议

某组织一旦获得了一块地址, 它就可以为组织内的主机分配IP地址. 
主机地址能够手动配置, 当然也能使用**动态主机配置协议(DHCP)**.

除了主机IP地址分配外, DHCP还允许一台主机获取其他信息. 
如子网掩码, 默认网关和他的本地DNS服务器地址. 
DHCP有常被称为**即插即用协议(plug-and-play protocal)**. 

每当一台主机加入时, DHCP服务器从其当前可用的地址中分配一个任意地址给它, 
当一台主机离开时收回池中. 

DHCP协议是一个4个步骤的过程:
- DHCP服务器发现
    - 刚开始, 没有分配地址也不知道DHCP服务器在哪. 所以DHCP客户端生成包含DHCP发送报文的IP数据报, 使用广播目的地址255.255.255.255, 使用0.0.0.0作为源地址. 
    - 链路层将帧广播到所有与该子网链接的子网
- DHCP服务器提供
    - DHCP服务器收到DHCP报文后, 用一个**DHCP提供报文**向客户端做出响应, 仍然使用255.255.255.255
    - 可能存在多台DHCP服务器提供DHCP报文供客户选择
- DHCP请求
    - 新到达的客户从一个或多个服务器提供中选择一个, 并向选中的服务器提供用一个**DHCP请求报文**进行响应
- DHCP ACK
    - 服务器用DHCP ACK报文对DHCP请求报文进行响应

然而一个移动的结点在子网之间移动时, 并不能维持与远程应用的TCP连接


#### 网络地址转换

如果一个组织想要扩容它的子网, 但是IPS已经为当前的范围分配过一块连续的地址了怎么办?

一种简单的方法就是: **网络地址转换(NAT)**.

NAT路由器上的一张NAT转换表, 并在表项中包含的端口号和其IP地址. 
一张NAT转换表就能实现WAN和LAN的映射. 

许多IETF团体中的纯化论这大声疾呼反对NAT
- 1. 
- 2. 
- 3. 

NAT的另一个重要问题是他妨碍P2P应用程序. 
因为如果对等方A, B在NAT后面, 它不能充当服务器并接收TCP连接. 


#### UPnP

NAT穿越越来越多地由通用即插即用(UPnP)提供,
UPnP是一种允许主机发现并配置临近NAT的协议. 

总而言之, UPnP允许外部主机使用TCP或UDP向NAT化的主机发起通信会话. 
UPnP由于提供了有效和健壮的NAT穿越解决方案, 可能成为P2P应用的救世主. 


#### 因特网控制报文协议(ICMP)

ICMP最典型的用途的差错检测, 如遇到"目的不可达"之类的错误报文就是有ICMP产生的. 

ICMP通常被认为是IP的一部分, 但从体系结构上将, 它是位于IP之上的,
因为ICMP报文是承载在IP分组中的. 
也就是说ICMP报文是作为IP的有效载荷的. 

ICMP报文有一个类型字段和一个编码字段, 
并且包含引起ICMP报文首次生成的IP数据报的首部和前8字节内容. 

Traceroute程序就是使用了ICMP的差错检测:
- 为了判断源和目的之间所有路由器的名字和地址, 源主机发送一系列普通的IP数据报, 并为每个报文设置计时器
- 每个数据报携带了一个具有不可达的UDP端口号的UDP报文
    - 当传递最后一个路由器时, 这个路由器就会因为这个不可达报文向源发送ICMP错误, 从而得以判断结束
- 第一个数据报的TTL为1, 第二个为2, 第n个为n
    - 所以当传到第n个路由器时, 就会因为TTL正好过期而返回ICMP报错
    - ICMP错误报文又含有IP等信息, 因此Traceroute程序就能使用这些信息和往返时延作为数据




### IPv6

IPv6引入的重要变化显示在其数据报中
- 扩大的地址容量
    - IPv6将地址长度从32比特扩大到128比特
    - IPv6还引入一种称为**任播地址**的新型地址
        - 这种地址可以使数数据报交付给一组主机中的任意一个
- 简化高效的40字节首部
    - 使用定长的40字节首部允许更快处理IP数据报
- 流标签与优先级

IPv6定义的字段
- 版本
- 流量类型
- 流标签
- 下一个首部
- 跳限制
- 源地址和目的地址
- 数据

IPv4中存在IPv6中不存在的
- 分片/重新组装
    - 当IPv6遇到"分组太大"的问题时, 向发送发发送一个"分组太大"的ICMP差错报文
- 首部校验和
    - 因为运输层协议(如TCP)和数据链路层协议(如以太网)直线的检验操作
- 选项
    - 选项不再的标准IP首部的一部分, 而是可能出现在"下一个首部"指示的位置上


#### 从IPv4到IPv6的迁移

推倒重建的方法是可以, 但是实现太困难了, 所以使用逐渐整合IPv6然后慢慢淘汰IPv4的方法.

- 双栈法
    - 一个结点具有完整的IPv6和完整的IPv4, 它有发生和接收两者的能力
    - 双栈法中如果任一一个结点是IPv4使能的, 则必须使用IPv4
        - 因为当IPv6结点要向一个IPv4结点发送数据报时, 需要"裁剪"自身的报文一符合IPv4
        - 而"裁剪"后就没办法恢复了
- 隧道法(双栈法法的一种)
    - 我们把两台IPv6之间的IPv4路由器集合成为**隧道**
    - IPv6要向IPv4发送数据报时, 将IPv6的数据报作为IPv4的有效载荷发送, 到另一端的IPv6路由器后在解封


### 路由选择算法

路由选择算法在网络路由器中运行, 交换和计算信息, 哟个这些信息配置转发表. 
路由选择的工作是: 确定从发送发到接收方的好路径. 

通常成与主机直接连接的一次路由器为**默认路由器**或**第一跳路由器**. 
将源主机的默认路由器成为**源路由器**, 将目的主机的路由器称为**目的路由器**. 

路由选择算法的分类
- 根据全局还是分散区分
    - 全局式路由选择算法
        - 具体实践中, 具有全局动态信息的算法称为**链路状态(LS)算法**
    - 分散式路由选择算法
        - **距离向量算法**是一个分散式路由选择算法
- 根据算法是静态还是动态区分
    - 静态路由选择算法
    - 动态路由选择算法
- 根据负载敏感区分
    - 负载敏感路由选择算法
    - 负载路迟钝由选择算法


#### 链路状态路由选择算法

链路状态路由选择算法中, 网络拓扑和所有链路的费用是已知的, 
所以可以用LS算法的输入. 

可以使用Dijkstra算法

存在的问题:
- 一条链路的吞吐量是有限的, 但是链路是双向的
    - 因此当多个路由同时进行路由选择时, 都不一而同的选择"空旷"的链路, 而原来拥堵的链路又因路由的离开变得"空旷", 如此反复震荡
    - 也就是说路由器之间能进行自同步
- 解决方法
    - 让每台路由器发送链路通过的时间随机化
    - 或使用其他路由选择算法, 如距离向量路由选择算法


#### 距离向量路由选择算法

距离向量(DV)算法是一种迭代的，异步的和分布式的算法，而LS是一种使用全局信息的算法。
- 分布式
    - 每个结点都要从一个或多个直接相连邻居接收某些信息，然后将计算结果分发给邻居
- 迭代的
    - 此过程一直要持续到邻居之间没有信息交换为止
- 异步的
    - 它不要求所有结点互相之间步伐一致地操作

最低费用$d_x(y)$的计算方法:
$$d_x(y) = min_y|c(x, v) + d_v(y)|$$
$c(x, v)$表示邻居结点v的距离， $d_v(y)$表示v到y的最低费用

每个结点维护一下信息：
- 对于每个邻居，从x到直接相连邻居v的费用
- 结点x到所有目的地y的距离向量
- 结点x的每个邻居结点v的距离向量

在DV算法中，每当结点x发现他的直接相连的链路费用发生变化或收到邻居发来的更新时，
它就更新(如果有更低费用路径的话)其转发表对应位置的距离向量。
同理，每个结点执行同x的操作，转发表更新时通知相邻结点。
结点重新计算距离向量后，它再次发送他们更新后的结果给邻居结点。
当所有结点已得到最到路径无需更新时，没有互相发生信息通知，从而进入等待状态。

但是DV算法会遇到路由选择环路问题，即当一条链路变得拥堵时，如费用从4变为60，
其他链路无法知道细节(只知道他们到某点的最短路径，但这个路径中可能包含已变拥堵的链路)，
从而产生环路，甚至会出现无穷循环的问题。


#### 层次路由选择

大规模的网络具有数亿的路由器，无论是LS算法还是DV算法，
在大量的运算中都得不到让人满意的复杂度，
甚是会网络的流量都用在了结点间数据获取上。

因此通过将路由器组织进**自治系统(AS)**来解决，
每个AS有一组通常处在相同管理控制下的路由且组成。
相同AS中的路由器使用相同的路由选择算法，
一个自治系统内运行的路由选择算法叫做**自治系统内部路由选择协议**。

多个AS互联形成大的网络，因此负责将AS与外界连接的一个或多个路由器称为**网关路由器**。
AS间最短路径又由**自治系统间路由选择协议**处理完成，
两个通信的AS间必须运行相同的自治系统间路由选择协议，
事实上因特网中所以AS都运行这相同的自治系统间路由选择协议：BGP4。

**热土豆路由选择**
- AS尽可能快的(准确的讲是尽可能经济的)扔掉分组(热土豆)。
这通过让路由器向某网关路由器发送分组来完成，
同时该网关路由器在到目的地路径上的所以网关路由器中有最低的费用。


### 因特网中的路由选择

一个AS是一个处于相同的管理与技术控制下的路由器集合，
在AS间都运行这相同的路由选择协议。

路由器内部路由选择协议用于确定一个AS内执行的路由选择方式。
AS内部路由选择协议又称为**内部网关协议**。

历史上有两个路由选择协议曾被广泛用于因特网上自治系统内路由的选择：
- **路由选择信息协议(RIP)**
- **开放最短路优先(OSPF)**


#### RIP

RIP是一种距离向量协议，类似DV协议。
在RIP中路由选择更新信息在邻居之间使用一种**RIP响应报文**来交换。
可由一个路由器发往AS内的多个子网。
响应报文又被称为**RIP通告**

每台路由器维护一张称为**路由选择表**的RIP表，
一台路由器的路由选择表包括该路由器在内的距离向量和该路由的转发表。
当一个路由收到通告时就会与旧路由选择表合并，特别是有更短路径时。

RIP使用一个位于网络层协议(IP)之上的传输层协议(UDP)来实现网络层功能。


#### OSPF

OSPF和IS-IS都设置在上层的ISP中，
而RIP被设置在下层ISP和企业网络中。

OSPF的核心是使用一个洪泛链路状态信息的链路状态协议
和一个Dijkstra最低费用的路径算法。

使用OSPF时，路由器向自治系统内所有其他路由器广播路由选择信息。
每当一条链路的状态变化时，路由器就会广播。
即使链路状态没有变化，它也会周期性的广播(增加了健壮性)。

OSPF的优点
- 安全
- 允许多条相同费用的路径
- 对单播和多播路由选择的综合支持
- 支持在单个路由选择域内的层次结构

一个OSPF自治系统可以分配成多个区域。
每个区域运行自己的OSPF链路状态路由选择算法，
一个区域内每台路由器都向区域内其他路由器广播状态。
区域内一台或多台**区域边界路由器**负责为流向该区域外的分钟提供路由选择。


### 自治系统间的路由选择：BGP

通过定义**边界网关协议**来跨越多个AS进行路由选择。
它通常被称为BGP4或简称BGP。

BGP为每个AS提供里进行以下工作的手段：
- 从相邻AS获取子网可达信息
- 向本AS内部的所有路由器传播这些可达信息
- 基于可达信息和AS策略，决定到达子网的"好"路由

BGP的使得每个子网想因特网的其余部分通告它的存在。


#### BGP基础

BGP极其复杂，这里简单介绍。
在BGP中，路由器对通过使用179端口的半永久TCP来连接交换路由信息。
对于在两个不同AS中的路由器链路而言，通常有一条BGP TCP链接。
在一个AS中的路由器之间还有许多半永久BGP TCP连接。

对于每条TCP连接，位于连接端点的两台路由器称为**BGP对等方**，
沿着该连接发送所有BGP报文的TCP连接成为**BGP会话**。
此外，跨越两个AS的BGP会话称为**外部BGP(eBGP)会话**，
在同一个AS中的BGP会话成为**内部BGP(iBGP)会话**。

BGP使得每个AS知道经过其相邻AS可达哪些目的地。
在BGP中，目的地不是主机而是CDIR化的前缀，
每个前缀表示一个子网或一个子网集合。

在任何AS中的网关路由器接收到eBGP学到的前缀后，
该网关路由器使用它的iBGP会话来向该AS中其他路由器发布这些前缀。


#### 路径属性和BGP路由

在BGP中，一个自治系统由其全局唯一的**自治系统号(ANS)**所标识。
当一台路由器通过BGP会话通告一个前缀是，他在前缀中包括一些**BGP属性**.
用BGP术语来说，带有属性的前缀称为一条**路由**。
BGP对等方彼此通告路由。

两个较为重要的属性是AS-PATH和NEXT-HOP
- AS-PATH
    - 该属性包含前缀通告已经通过了的那些AS
    - 当一个前缀传送到一个AS时，该AS将它的ASN增加到AS-PATH属性中
    - AS-PATH属性用来检测和防止循环通告
        - 如果路由器看到它的AS被包括在该路径列表中，它将拒绝该通告
    - 类似并查集
- NEXT-HOP
    - NEXT-HOP是一个开始某AS-PATH的路由器接口
    - 类似根(起点)
- BGP也包括允许路由器对路由分配偏好测试度的属性，以及前缀如何插入位于其实AS的BGP的属性

一台网关路由器接收到一台路由器通告时，
它使用其**输入策略**来决定是否接收该路由，
是否设置某种属性。


#### BGP路由选择

如果对相同前缀存在两条或多条路由，
则BGP顺序的调用下列消除规则，直到留下一条路由
- 路由被指派一个本地偏好值作为它们的属性之一
    - 具有最高本地偏好值的路由将被选择
- 余下路由中(路由偏好值相同)，具有最短AS-PATH的路由将被选择
- 余下路由中，将选择具有最靠近NEXT-HOP路由器的路由
- 如果仍留下许多路由，则使用BGP标识符来选择


### 广播和多播路由选择

在**广播路由选择**中，网络提供了从一种源结点到网络中所有其他结点交付分组的服务;
**多播路由选择**使单个源结点能向其他网络结点的子集发送分组的副本。


#### 广播路由选择算法

- N次单播
    - 源结点产生该分组的N个副本，对不同目的地的每个副本进行编址并传输
    - 缺点
        - 效率底
        - 要获取所以结点的信息就又要获取全局的数据

显然更有效率的方式是，经第一跳仅发送分组的单个副本，
然后让第一跳后面其他端的结点生成并转发任何附加的所需副本。
类似细胞分裂。

- 无控制洪泛(flooding)
    - 该方法要求源结点向它所有邻居结点发送分组副本。
    - 当某结点收到一个广播的分组时重复上一步操作
    - 缺点
        - 如果图中有圈，广播将会无限循环
        - 产生大量重复的分组副本，导致**广播风暴**
- 受控洪泛
    - **序号控制洪泛**
        - 源结点将其地址以及**广播序号**放入广播分组，再向邻居发送分组
        - 每个结点维护它已经收到的，复制和转发的源地址和每个广播分组的序号列表
    - **反向路径转发(RPF)**
        - 当分组是从它到发送方的最短路径上的下一个邻居传来时才向所以出链路传输报文
        - 它仅使用这个邻居的身份以决定是否洪泛一个接收到的分组
- 生成树广播
    - 虽然受控洪泛避免了广播风暴，但是它们不能完全避免冗余分组传输
    - 首先对网络结点构造出一棵生成树
    - 当一个源结点要发送广播分组时，它向属于该生成树的特定链路发送分组
    - 接收广播分组的结点则向生成树的所以邻居转发该分组
    - 注意到一个结点不必知道整棵树，只需要知道它在的哪些邻居是生成树中的


#### 实践中的广播算法

building


### 多播

多播服务可以将分组从一个或多个发送方交付给一组(多个)接收方。

提出问题：
- 怎么标识多播分组的接收方？
- 怎么为发送到这些接收方的分组编址？
    - 如果是从发送方一一遍历接收方来发送，那就有N次单播的问题
    - 如果不是上述方式，那要分组要携带很多的IP地址吗

由于这些原因，在因特网体系结构中，
多播数据报使用**间接地址**来编址。
也就是说用一个标识来表示一组接收方，
寻址到该组的分组副本会被交付到所有与改组关联的多播接收方(多播组)。


- 一个组如何形成，如何终结？
- 如何选择组地址？
- 新主机如何加入某个组？
- 任何主机都能加入一个组吗？谁来限制？
- 一个组成员知道其他组成员的标识吗？
- 网络结点互相之间如何交互，以向所以组成员交付一个多播数据报呢？

对于这些问题的回答都与因特网组管理协议(IGMP)有关


#### 因特网组管理协议(IGMP)

IGMP版本3运行在一台主机与其直接相连的路由器之间，
IGMP为一台主机提供了手段，让它通知与其相连的路由器：
在本主机上运行的一个应用程序想加入一个特定的多播组。
由于IGMP的交互范围局限在主机与其相连的路由器之间，
显然需要一种协议来协调遍及因特网内的多播路由器，
以便多播数据报能路由到其最终的目的地。

因此因特网中的网络层多播是由两个互补的组件组成：
IGMP和多播路由选择协议。

IGMP只有三种报文类型
- 由一台路由器向所有与主机相连的接口发送一个membership\_query报文
    - 以确定该接口上主机已加入的所以多播组集合
- 主机用一个membership\_report报文来相应membership\_query
    - 当一个应用程序首次加入一个多播组时，也可由主机产生membership\_report报文
- 最后一种是leave\_group报文，是可选的
    - 当无主机响应一个具有给定地址的membership\_query报文时，路由器就推断出已没有主机在这个多播组了
    - 这是**软状态**的一个例子


#### 多播路由选择算法

多播路由选择算法的目标就是发现一棵链路树，
这些链路连接了所有具有属于该多播组的相连主机的路由器。
当然，该树也许会包含一些没有属于该多播组的相连主机的路由器(路过)。

实践中采用两种方法来确定多播路由选择树，
两种方法的区别在于：
- 使用一棵组共享树的多播路由选择。
    - 使用基于中心的方法来构造多播路由选择树
    - 具有属于多播组的相连主机的边缘路由器向中心结点发送加入保报文，直到到达多播树中的一台路由器
    - 然后沿原路转发多波分组给发送加入报文的路由器
- 使用一棵基于源的树的多播路由选择
    - 使用具有剪枝RPF算法来构造一棵多播转发树
    - 一个接收到多播分组的多播路由器，如果它无加入该组的相连主机，则它向它的上游路由器发送一个**剪枝(pruning)**报文
        - 因为如果一个路由器有很多下游路由器，但是他们都不是多播组中的，这样就会导致大量冗余的转发
    - 如果一台路由器从它的每个下游路由器都收到剪枝报文，则它向它的上游路由器发生剪枝报文


#### 因特网中的多播路由选择

第一个用于因特网的多播路由选择协议的**距离向量多播路由选择协议(DVMRP)**，
DVMRP使用前面描述的具有剪枝的RFP算法。

也许使用最广泛的因特网多播路由选择协议是**协议无关的多播路由选择协议(PIM)**,
该协议明确辨识两种多播分发情形。
- 稠密模式
    - 稠密模式是一种洪泛与剪枝反向路径转发技术，类似DVMRP的思想
- 稀疏模式
    - RIP稀疏模式使用聚集点来建立多播分发树
    - 在**源特定多播(SSM)**中仅允许单一发送方向多播树中发送流量，大大简化树的构建和维护


## 链路层：链路、接入网和局域网

两种不同类型的链路层信道
- 广播信道
    - 如有线局域网、卫星网
- 点对点信道
    - 如以太网
        
几个概念和技术
- 差错检测和纠正
- 多路访问网络和交换局域网
    - 如以太网
- 虚拟局域网和数据中心网络


### 链路层概述

将运行链路层协议的任何设备均称为**结点**。
把沿着通信路径连接相邻结点的信道成为**链路**。
在通过特定的链路时，传输结点将数据报分装在**数据层帧**中，
并将该帧传送到链路中。

游客好比数据报，每个运输区段好比一条链路，
每种运输方式好比链路层协议，而旅行社好比路由选择协议。


#### 链路层提供的服务

链路层协议能够提供的可能服务包括
- 成帧(framing)
    - 每个网络层数据报经链路传送之前，几乎所以链路层协议都有将其链路层帧封装起来
    - 一个帧由一个数据字段和若干首部字段组成，其中网络层数据报就插在数据字段中
- 链路接入
    - **媒体访问控制(MAC)**协议规定了帧在链路上传输的规则
- 可靠交付
    - 与运输层可靠交付服务类似，链路层的可靠交付服务通常通过确认和重传却的的。
    - 对于一些低比特差错的链路，如光纤、同轴电缆等，可靠交付会产生不必要的开销
    - 许多有线的链路层协议不提供可靠交付服务
- 差错检测和纠正
    - 链路层的差错检测通常给复杂，而且由硬件实现


#### 链路层在何处实现

链路层的主体部分是在**网络适配器**中实现的，
网络适配器有时也称为**网络接口卡(NIC)**。
位于网络适配器核心的是链路层控制器，
该控制器通常是一个实现了许多链路层服务的专用芯片。

在发送端，控制器取得了由协议栈较高层生成并储存在主机内存中的数据报，
在链路层中封装该数据段，然后遵循链路介入协议将该帧传进通信链路中。

在接收端，控制器接收了整个帧，抽取出网络层数据报。
如果链路从执行差错检测，则需要控制器在帧的首部设置差错检测比特，
有接收控制器执行差错检测。


#### 差错检测和纠正技术

为了避免差错，使用**差错检测和纠正比特(EDC)**来增强传输的数据。

即使使用了差错检测比特，也可能有为检测出的比特差错，
因此我们要适当选择检测方案来使得这种概率很小，
但是出现的概率月小说明技术越复杂，开销越大。


#### 奇偶校验

以偶检验为例，奇校验同理。

设一段数据有d个比特，设置一位校验位，
使得这d+1个比特中1的个数为偶数。
接收方只用数d+1个比特中1的个数。
如果发现奇数个1，则至少出现了奇数个比特差错。

显然，这样的单纯的奇偶校验无法实现纠正功能，
所以使用一种**二维奇偶校验**。
把d个比特划分为i行j列，
对每行没列计算奇偶值，
产生的i+j+1个比特构成了链路层帧的差错检测比特。

``` 
d1,1 d1,2 ...   d1,j | d1,j+1
... ..... ...   d2,j | d2,j+1
... ..... ...   .... | ...
di,1 di,2 ...   di,j | di,j+1
—————————————————————+———————
di+1,1 di+1,2 di+1,j | di,j+1

```

这样，包含比特差错的行和列都会检测到差错，就能够实现纠正了。
但是检验比特本身也是可能出现差错的。
而且二维奇偶校验能检测一个分组中两个比特差错的任意组合，
但无法对其纠正。

这种由接收方检测和纠正差错的能力成为**向前纠错(FEC)**。
FEC避免了重传带来的时延。


#### 校验和方法

将b个比特数据作为一个k比特整数的序列处理，
一个简单的校验和方法就是将这k个比特加起来，
并用得到的和作为差错检测比特。

因特网校验和就是基于这种方法，
即数据的字节作为16比特的整数对待并求和。
这个和的反码形成了携带在报文首部的因特网校验和。

校验和方法需要相对小的分组开销，
如TCP和UDP中的校验和只用了16比特。
但是也提供了较弱的差错保护。


#### 循环冗余检测

现今的计算机网络中广泛应用的差错检测技术基于**循环冗余检测(CRC)编码**。
CRC编码也称为**多项式编码**，因为该编码能够将要发送的比特串看作为系数的0和1的一个多项式，
对比特串的操作被解释为多项式算术。

CRC编码操作如下。对于一个d比特是数据D，
发送发和接收方要事先协商一个r+1比特，
成为**生成多项式**G。
我们要求G的最高为有效比特是1。
对于一个给定的数据段D，发送方选择r个附加比特R，
并将它附加到D上，使得得到的d+r模式用模2算数恰好能被G整除。
接收方用G去除接收到的d+r比特，看余数是否为零就可以做到差错检测。

所有CRC计算采用模2算数来做，
在加法中不进位，在减法中不借位。
所以加法和减法是相同的，且等价于操作数按位异或(XOR)。
除此之外，乘法和除法还是二进制算数的乘除。

对于怎么求R，根据我们的要求有：
$$D \times 2^k\ XOR\ R = nG$$

两边都用R异或
$$D \times 2^k = nG\ XOR\ R$$

由这个等式可知，如果我们用G来除$D \times 2^k$，
余数正好是R，换句话说我们可以这样计算R：
$$R = remainder \frac{D \times 2^k}{G}$$

国际标准已经定义了8、12、16和32比特的生成多项式G。

每个CRC标准都能检测小于r+1比特的突发差错。
此外，在适当的假设下，长度大于r+1比特的突发差错以概率$1-0.5^r$被检测到。
每个CRC标准也能检测任何奇数个比特差错。


### 多路访问链路和协议

我们提到有两种类型的网络链路：
**点对点链路**和**广播链路**。

一个对链路层很重要的问题是：
如何协调多个发送和接收节点对一个共享广播信道的访问，
就是**多路访问问题**。
**多路访问协议**就是用来规范结点们在共享广播上的传输行为，
来解决多路访问问题。

因为所有结点都可以传输帧，所以可能出现多个结点同时传输的情况。
当这种情况发生时，传输的帧在所有的接收方出**碰撞**.
当碰撞发生时，没有一个接收结点能够有效的获取任何帧。
显然，大量的宽带资源因此浪费。

我们能够将任何多路访问协议划分为3类型之一：
- **信道划分协议**
- **随机接入协议**
- **轮流协议**


#### 信道划分协议

时分多路复用(TDM)和频分多路复用(FDM)是两种比较简单的技术。
举例来说，假设一个支持N个结点的信道且信道传输速率为R bps。
TDM将时间划分为**时间帧**，并进一步划分每个时间帧为N个**时隙(slot)**。
然后把每个时隙分配给N个结点中的一个。
无论何时某个结点有分组要发送时，它在循环的TDM帧中指派给它的时隙内传输分组比特。
通常，选择的时隙长度应使一个时隙内能够传输单个分组。

同理，FDM将R bps信道划分为不同的频段，每个频段具有R/N宽带。
并把每个频率分配给N个结点中的一个。

TDM和FDM有相同的优点和缺点
- 优点
    - 避免了碰撞
    - 公平分配
- 缺点
    - 限制于R/N的平均速率，即使只有一个分组要发送时

第三种信道划分协议是**码分多址(CDMA)**，
CDMA对每个结点分配一种不同的编码，
然后每个结点用它唯一的编码来对它发送的数据进行编码。

如果精心选择这些编码，则CDMA可以做到不同的结点同时传输，
此外，它还具有抗干扰特性。


#### 随机接入协议

随机接入协议中，一个传输结点总是一信道的全部速率(R bps)进行发送。
当有碰撞时，涉及碰撞的每个结点反复的重新发送它的帧，到该帧无碰撞为止。
但重发不是立即重发，而是等待一个随机时延再重发。
每个结点独立选择随机时延。

最常用的随机接入协议有ALOHA协议和载波侦听多路访问(CSMA)协议。
以太网是一种流行并广泛部署的CSMA协议。

- 时隙ALOHA
    - 假设
        - 所以帧由L比特组成
        - 时间被划分成长度为L/R秒的时隙
        - 结点只在实习起点开始传帧
        - 结点是同步的，每个结点知道时隙何时开始
        - 如果一个时隙中有两个或多个帧碰撞，则所以结点在该时隙结束前能检测到该碰撞时间
    - 操作
        - 当节点有一个帧要发送时，它等到下一个时隙开始并在该时隙传输整个帧
        - 如果没有碰撞，则传输成功
        - 如果有碰撞，结点会在时隙结束之前检测到。然后该结点以p的概率在后续的每个时隙中重传它的帧，直到没有碰撞发生
    - 优点
        - 当某结点是唯一活跃的结点时，能够全速R传输
    - 效率：当有大量活跃结点且每个结点总有大量的帧要发送是，长期运行中成功时隙的份额
        - 对于N个节点，每个节点都有$p(1-p)^{N-1}$的概率传输成功，则N个节点就有$np(1-p)^{N-1}$的概率
- 纯ALOHA
    - 效率是时隙ALOHA的一半


## TCP

面向连接的传输

三次握手
- 用户发送特殊的TCP报文
- 服务器用一个特殊的TCP报文回复
    - 两次握手后建立起连接
    - 连接建立后可以互相发送数据
- 最后用户通过第三次报文发送有效载荷


### TCP报文结构

TCP报文段首部包含一下字段:
- 源端口/目的端口
- 校验和
- 32比特的序号字段和确认号字段
- 16比特的接收窗口字段
    - 用于流量控制, 用于指示接收方愿意接受的字节数量
- 可选与变长的选项字段
- 4比特的首部长度字段
    - 因为首部长度是可变的
- 6比特的标志字段
    - ACK比特用于指示字段中的值是否有效
    - RSY, SYN, FIN比特用于连接的建立和拆除
    - URG比特用来指示报文里"紧急"数据
        - 紧急数据的最后一个字节由16比特的**紧急数据指针**字段指出

字段的具体表现
- 最大报文段长度(MSS)
    - TCP从缓存中取出并放入报文段是数据量受MSS限制
    - 应用层数据的最大长度
    - MSS通常由最初确定的由本机发送的最大链路层帧(MTU)长度设置
- 最大传输单元(MTU)
    - 如果链路层协议有1500字节的MTU, 报文首部长40字节, 则MSS长1460字节
- 一个报文的序号
    - 报文段首字节的字节流编号
        - 如一个500 000字节的文件, MSS为1000字节, 第一个首字节编号为0, 第二个为1000...
- 超时间隔计算
    - $TimeoutInterval = EstimatedRTT + 4DevRTT$
    - 每次重传时都会将超时间隔设置为上一个值的两倍
        - 应为有时真的很拥堵
        - 但是也不能这么一直的指数增长
        - 当接受到ACK后重新估计
        - 收到3个冗余ACK后执行快速重传
    - 往返时间(RTT)的估计: $EstimatedRTT = (1 - \alpha)EstimatedRTT + \alpha SampleRTT$
        - $\alpha$通常为0.125
        - 在某个时间会测量一次SampleRTT
    - 波动时间: $DevRTT = (1 - \beta)DevRTT + \beta{|SampleRTT - EstimatedRTT|}$
        - $\beta$通常为0.25
- 流量控制
    - 防止缓冲区溢出
- 拥塞控制
    - 当网络阻塞时遏制网络


#### TCP连接管理

TCP连接管理包括连接的建立和连接的关闭

连接建立的过程
- 1. 客户端向服务发送一个特殊的TCP报文
    - 不包含应用层数据
    - 首部标志位SYN设置为1
    - 客户端还会适当的随机选择一个初始序号(client\_isn), 置于序号字段中
- 2. 服务器回复
    - 服务器收到TCP SYN报文后提取数据, 并为TCP分配缓存和变量
    - 服务器将自己的初始序号(server\_isn)放到报文段中
        - SYN置为1
        - client\_isn + 1
    - 向客户端发送允许连接的报文段
        - 允许连接的报文段有时候被称为**SYNACK报文段**
- 3. 客户端向服务器
    - 客户端也要为连接分配缓存和变量
    - 段对服务器的允许报文进行确认
        - 通过server\_isn + 1放置在报文段中进行确认
        - SYN置为0
    - 可以在报文段中携带客户到服务器的数据

三次握手完成后客户端便可与服务器相互通信. 但是如果只进行了前两次握手, 分配了资源, 但是没有第三次握手就会造成大量资源浪费. **SYN洪泛攻击**就是利用这点. 现在的一种有效的防御系统称为**SYN cookie**

连接关闭
- 客户端向服务器发送
    - 标志位FIN置为1
    - 服务器确认后回复(ACK)
- 服务器向客户端发生它自己的终止报文
    - 标志位FIN置为1
    - 客户端确认后回复(ACK)
- 连接资源释放


#### 拥塞控制的原理

拥塞原因
- 情况1: 两个发送方和一台有无限大缓存的路由器
    - 假设共用的链路吞吐量为R
    - 当两个发送方都以R/2的速率发送时, 速率达到最优
    - 由于共用的吞吐量有限, 当超过R/2时, 排队队列会趋于无限大, 平均排队时间也无限大
- 情况2: 两个发送方和一台有限大缓存的路由器
    - 存在缓存溢出, 溢出部分还得重传
- 情况3: 四个发送方和有无限大缓存的路由器以及多跳路径

拥塞控制的方法
- 端到端拥塞控制
    - 网络层没有提供显示支持
- 网络辅助的拥塞控制
    - 网络层构件(即路由器)向发送方提供拥塞状态的反馈信息(拥塞分组)
        - 可以有路由器直接发给发送方
        - 也可是路由器标记或更新发送发向接受方的分组, 以提示接收方, 再由接收方提示发送方
            - 会多一个完整的往返时间

**网络辅助的拥塞控制例子: ATM ABR拥塞控制**
- 数据中夹杂着所谓的**资源管理信元(RM信元)**
    - 这些信元用来在主机和交换机之间传递拥塞信息
    - 默认32个数据信元中有一个RM信元
- EFCI比特(显示转发拥塞指示)
    - 拥塞的网络交换机可以把数据信元中的EFCI比特设置为1来向主机发送网络已拥塞的信令
    - 如果多数近来收到EFCI为1,则目的地将RM信元的拥塞指示比特(CI比特)设置为1, 并把该信元发送回发送方
- CI和NI比特
    - CI比特是RM信元中拥塞指示(Congestion Indication, CI)比特
    - NI比特是RM信元中的无增长(No Increase)比特
    - 交换机可以在轻微拥塞时将NI比特设置为1, 在严重拥塞时将CI比特设置为1
- ER的设置
    - 每个RM信元还包含一个两字节的显示速率(Explicit Rate, ER)字段
    - 拥塞的交换机也许会降低经过的信元中ER的值


#### TCP拥塞控制

TCP必须使用端到端拥塞控制而不是使用网络辅助拥塞控制, 因为IP层不向端系统提供显示的网络拥塞反馈.
TCP采用的方法是让每个发送方根据所感知的网络拥塞程度来限制其能向连接发送流量的速率.

- 限制流量的方式, 拥塞窗口(congestion window, cwnd)
    - 限制发送流量的速率, 就是流水线的窗口的作用
- 拥塞感知
    - 一个丢失的报文(超时或3个冗余)意味着拥塞
    - 一个确认报文指示能正常接收, 不拥塞
    - 宽带探测, 通过改变速率和检测丢包, ACK来探测
- 速率修改的策略
    - TCP拥塞控制算法
        - 1. 慢启动
        - 2. 拥塞避免
        - 3. 快速恢复
        - 慢启动和拥塞避免是TCP的强制部分

**TCP拥塞控制算法**
- 慢启动
    - 开始时cwnd设置为一个MSS的较小值, 大约为MSS/RTT
    - 如果都是ACK回复, 则一个RTT发送速率就会翻番
    - 指数增长
    - 慢启动结束的第一种标志: 当遇到超时引发的丢包现象时, 将拥塞阀值ssthresh设置为cwnd/2, 然后将cwnd设置为1, 重新开始慢启动
    - 慢启动结束的第二种标志: 达到阀值
    - 慢启动结束的第一种标志: 当遇到3个ACK冗余引发的丢包现象时, 进入快速恢复状态
- 拥塞避免
    - 当cnwd达到阀值ssthresh时, 进入拥塞避免模式, cnwd不再指数增长, 而是每个RTT增加一个MSS
- 快速恢复
    - 很多变种, 不一一陈述, 如冗余丢包后cwnd=ssthresh+1等

TCP拥塞控制常被称为加性增, 乘性减(AIMD)拥塞控制方式


## UDP

无连接传输

优点
- 控制更加精细
    - TCP的拥塞控制机制在链路变得拥塞时来遏制运输层的TCP发送方. 
    - TCP会不惜一切时间代价来确认报文被接收且确认, 对于有最小发送速率要求的应用不友好.
    - 对于不希望过分延时但能容忍一些数据丢失的应用来说是好的
- 无需连接建立
    - TCP需要三次握手, 而UDP不会, 故UDP不会引入建立连接时延
- 无状态连接
    - TCP需要维护连接状态, 接收和发送缓存, 拥塞控制参数以及确认号的参数等等
- 首部开销很小

**UDP提供了差错检测**, 通过在报文中添加校验和(checksum). 校验和工作原理如下

``` 
将报文段中 所有的16比特字的和 进行反码运算, 求和时遇到任何溢出都被回卷.
得到的结果放在报文的校验和字段中. 接收方收到后将所有16比特字和检验和相加应该得到16个1

简单举例: 要三个字段
10011
00111
01111

10011
00111
-------
11010
01111
-------
01001

checksum: 10110 # 和的反码
```
