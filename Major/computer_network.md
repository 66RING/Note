---
title:  自顶向下计算机网络
date: 2020-3-25
tags: cs
mathjax: true
---

#  自顶向下计算机网络

## 基本概念

- ISP: Internet Server Provider
- 拓扑：连线的方式
- 吞吐量：水管的大小
- 流量：网速
- 网络大小划分  
	- PAN:personal area network
	- LAN:局域网
	- MAN:城局域网
	- WAN:广局域网
	- 互联网（最大）


### IP地址

IPv4由32个位组成, 通常8个一组如192.168.1.1

前28个位为**网络编号**, 后4位为**主机编号**

**子网掩码**: 子网掩码的1对应网络位的编号, 子网掩码的0对应主机位的编号, 如255.255.255.0
- 作用: 限制广播的网络段, 将莫大的网络划分变小

**子网**表示方法: 网络编号 + 主机号 + / + 子网掩码1的个数
- 如:192.168.1.0/24, 子网掩码为255.255.255.0

**网段地址**: 每个网段的第0个地址
- 如:192.168.1.0. 0 = 0000 0000, 第0号主机

**广播地址**: 网段的最后一个IP地址
- 如:192.168.1.255. 255 = 1111 11111, 最后一个主机


### 路由

路由器的作用是实现跨网段的数据传输和转发, 类似于向导的作用, 这种指引的行为就叫最**路由**


#### 路由表

转发的指南

``` 
再linux下使用: route -n 可以查看路由表
:$ route -n  // 结果有8列
Destination  Gatewaty  Genmask  Flags  Metric  Ref  Use  Iface
```

分别为目的地址, 网关地址, 网关掩码, 最后一列为网卡

Flags带有G的说明是网关规则, 若数据包的目的IP与路由表的目的地址匹配, 路由器会将数据包(通过网卡)转发到Gateway中的网关地址,

如果Flags没有带G, 说明不是网关规则, 目标地址肯定就在本地链路通过用一个交换机相连

通过`traceroute -n IP`可以查看中途经过了哪些路由器

那路由表从何而来呢?
- 直连路由
    - 当主机配置好一个IP后, 会自动生成一个目的地址为该子网的路由
- 手动添加路由(静态路由)
- 通过动态路由协议获取


#### 路由器的功能

- DHCP
    - Dynamic Host Configuration Protocal, 动态主机配置协议
- (S)NAT/DNAT
    - (Source) Network Address Translation
    - 源地址转换NAT功能, 也叫IP伪装
    - 数据包在出路由器前会将数据包的源IP地址转换为路由器WAN口的公网IP地址, 以便被别人找到. 
        - 因为192.168.0.4等是私有的
- DNAT
    - 目的地址转换NAT功能
    - DNAT就是NAT的逆向
    - 实现公网对内部主机的主动访问


#### 路由器的桥接

把路由器的LAN合并到一起, 注意一下关键点
- 在一个LAN中IP地址必须唯一
    - 故从路由的的LAN必须和主路由属于同一网段, 并IP地址唯一
- 在一个LAN中最多有一个DHCP服务器
    - 故要关闭从路由的DHCP功能



## 参考模型  

### 分层原理

信宿机第n层收到的对象应与信源机第n层发出的对象完全一致. 好比做飞机的登机口和下机口

每一层都为他的上一层服务  
信息发送方要做什么:  
- 封装/打包:  
	- 然后从最高层逐层传到物理层
- 每一层上，数据都会被加上头部信息，用于信息传递  

收方要做什么:  
- 解封装/解包  


#### 典型的分层模型:

- ISO OSI 七层模型  
	- 应用层
    - 表示层
    - 会话层
    - 传输层
    - 网络层
    - 数据链路层
    - 物理层
- TCP/IP (DoD) 四层模型  
	- 应用层
    - 传输层
    - 网络互联层
    - 主机到网络层


## 应用层

### 应用程序体系结构

- 客户-服务器体系结构
    - 至少一个服务器主机负责处理多个来自客户主机的请求
- P2P体系结构
    - 主机到主机, 这些主机称为对等方

### 基本概念

- 套接字: socket
    - 进程通过socket的软件接口向网络发送报文和传输报文
        - 好比房子的大门
    - 套接字地址: ip + port
- API: Application Programming Interface

### HTTP

HTTP(HyperText Transfer Protocal, 超文本传输协议)是Web的核心, 客户端和服务器通过交换HTTP报文进行会话. HTTP使用TCP作为它的支撑传输协议, 即先建立TCP连接, 再通过TCP连接向彼此套接字发送报文. 

- TCP为HTTP提供了可靠数据传输服务
    - 即发出的每个请求到能完整的到达目的地
- HTTP是一个无状态协议


- 持续连接的HTTP
    - 可以一个接一个发送请求
- 非持续连接的HTTP
    - 发送一个对象后TCP连接关闭


#### HTTP报文格式

请求报文
- 请求行
    - 方法 URL 版本
    - 包含一系列必要信息
- 首部行
    - 首部字段: 值
    - 相当于指定配置
- 空行
- 实体主体
    - 使用POST方法时才使用

``` 
--- 请求行 ---
GET /some/dir HTTP/1.1
--- 首部行 ---
Host: www.some.com           # 指明对象所在的主机, 该首部行的Web高速缓存所要求的
Connection: close            # 非持续连接
User-agent: Mozilla/5.0      # 发送请求的浏览器类型
# 还会有很多的配置
```

HTTP使用的方法
- GET
- POST
- HEAD
    - 类似GET, 但不返回请求对象
- PUT
    - 允许用户上传对象到指定Web服务器
- DELETE
    - 允许用户删除服务器上的对象

响应报文
- 状态行
    - 版本 状态码 短语
    - 常见状态码
        - 200 请求成功
        - 301 请求的对象已被永久转移
        - 400 Bad Request 请求不能被理解
        - 404 Not Found 请求的文档不在服务器上
        - 505 服务器不支持请求报文的HTTP版本
- 首部行
- 空行
- 实体主体


#### cookie

前面提到HTTP服务器是无状态的, 所以要想内容和用户身份联系起来就要使用cookie.

``` sequence-diagrams
client->server: request
server-->client: response + cookie
client->server: request + cookie
server-->client: response
```


#### Web缓存

Web缓存器也叫代理服务器. Web缓存器既是服务器又是客户端, 它会把请求的结果保存在本地. 在遇到相同的请求是可以由本地数据提供

可以减少网络负担. 如在高速的局域网络架设缓存器

HTTP协议有一种机制, 允许缓冲器证实它的对象是最新的. 这种机制叫做**条件GET**. 使用含有`If-Modified-Since: Date`请求行


### FTP

文件传输协议

区别于HTTP, FTP也运行在TCP上, 但是它使用两个并行的TCP连接来传输文件: 一个是**控制连接**, 一个是**数据连接**.


### 因特网中的电子邮件

由三个部分组成: 用户代理, 邮件服务器, 简单传输协议(SMTP). 邮件通过SMTP在邮件服务器中传递, 在由邮件服务器分发给对应用户.


### DNS

域名系统(Domain Name System, DNS)


#### Host

除了DNS可以解析域名外, Host也能解析域名. IP信息和域名信息的映射表. Host映射的优先级要高于DNS.


#### DDNS

动态域名系统(Dynamic Domain Name System). 其主要作用的动态更新dns服务器上的IP地址. 方便域名与IP的映射.  

可以自己写程序/脚本实现
- 思路1:
    - 调用dns服务商的api实现更新ip地址


## 运输层

运输层协议是在端系统中而不是路由器中实现的. 运输层把应用程序发送的报文转换成运输层分组, 该分组称谓运输层**报文段**.

在发送端系统中, 运输层将这些报文段传递给网络层, 网络层对其封装成网络层分组即(**数据报**)

网络层提供了主机之间的逻辑通信, 而运输层为运行在不同主机上的进程之间提供了逻辑通信. 网络层相当与邮递员负责送到家门口, 分发还得靠运输层, 所以说网络层是运行在主机间, 运输层才是运行在进程间的(端系统), 运输层负责把报文移动到网络边缘(网络层).

- 多路复用
    - 负责收集各个端口的报文, 为每个数据快封装上首部信息后传递到网络层
- 多路分解
    - 运输层负责获取从网络层接收到的报文首部中端口的信息, 并分发到适当的程序中


### 可靠数据传输(RDT)原理

- rdt1.0
    - 停等型
        - 浪费大量时间
    - 通过返回的报文确定是否需要重传
        - 会浪费大量资源重传分组
        - 返回报文也可能有误
- rdt2.0
    - 停等型
    - 肯定回复(ACK)或者否定回复(NAK)负责校验数据是否受损
    - 使用序号的概念,  分分为发送序号和期望序号, 用于检测是否失序
        - 序号可以解决多余的重传
        - 由于期望序号的存在, 也可解决返回报文的差错问题
        - 但接收方没收到会导致等待时间无限增加
- rdt3.0
    - 加入定时器的概念
        - 超时自动重发


#### 流水线可靠数据传输协议

上面提到的协议都是停等型, 性能不能使人满意, 使用窗口/流水线型提高效率

- 流水线
    - 对所有的分组使用序号空间进行编号
        - 序号空间: 如1, 2, 3, 1, 2, 3.序号空间就是1, 2, 3
    - 为什么使用序号空间
        - 报文的比特位是有限的
- 窗口
    - 流水线上一个范围内的分组
    - 为什么使用窗口
        - 报文的比特位是有限的


比较完善的选择重传(SR)协议
    - 校验和
        - 用于检测传输分组中的比特错误
    - 定时器
        - 用于重传丢失的分组
    - 序号
        - 用于检测分组是否失序或冗余
        - 已经接收到的分组可以储存在缓存中, 待顺序恢复后上报
    - 确认/否定确认
        - 接受放通过校验和检测到比特是否出错, 需要回复发送方
    - 窗口/流水线
        - 允许一次发送多个分组
        - 对于SR协议来说, 窗口长度要小于或等于序号空间大小的一半


## 网络层

网络层对运输层发送是分组(数据段)封装成网络层分组, 该分组称为**数据报**.

重要概念
- 转发
    - 涉及分组在单一路由器中一条入链路到一条出链路的传送
- 路由选择
    - 设计所以的路由器经过路由选择协议共同交互, 以决定到达目的地采用的路径


### 网络服务模型

网络层能够提供的某些可能的服务
- 确保交付
    - 确保分组最终将到达目的地
- 具有延时上界的确保交付
- 有序分组交付
- 确保最小带宽
- 确保最大时延抖动
    - 分组间的时延间隔变化不超过某个值
- 安全性服务
    - 数据加密

因特网的网络曾提供了单一的服务: 成为尽力而为服务


#### ATM网络体系结构

ATM网络体系结构提供了多重服务模型, 可以为不同的连接提供不同类型的服务. 其中两个重要的ATM服务模型
- **恒定比特率(CBR)ATM网络服务**
- **可用比特率(ABR)ATM网络服务**


### 虚电路和数据报

网络层提供了主机到主机的连接服务, 或者主机到主机的无连接服务, 而不提供两者. 仅在网络层提供提供连接服务的计算机网络称为**虚电路(VC)网络**. 仅在网络层提供提供无连接服务的计算机网络称为**数据报网络**. 


#### 虚电路

虚电路的组成如下:
- 源和目的主机间的路径
- VC号
    - 连着该路径的每段链路的一个号码
- 沿着该路径的每台路由器中转发表的表项
    - 一条虚电路在每条链路上可能具有不同的VC号, 每个中间路由器必须用新的VC号代替每个传输分组的VC号. 
    - 转发表: 当建立连接(虚电路)时增加一项, 终止时删除

一个分组沿其路由在每条链路上不简单保持相同VC号的原因:
- VC字段长度有限
    - 网络有上亿个链路不应一一编码, 浪费资源
- 简化虚电路的建立
    - 每个路由器只用维护自己本地的路由表


#### 数据报网络

在数据报网络中, 每当一个端系统要发送分组, 它就为该分组加上端系统的地址, 然后推进网络中. 它通过一系列路由传递, 路由器使用其目的地址通过转发表转发. 

数据报网络中的转发表通过路由选择算法进行修改, 通常每1~5分钟更新一次. 由于转发表随时可能发生变化, 所以一系列分组可能通过不同的路径到达目的, 并可能无序到达.


### 路由器工作原理

输入端口 --> 交换结构(路由选择处理器) --> 输出端口

- 输入端口
    - 将一条输入的物理层链路与路由相连接(一种物理层功能)
    - 需要与位于入链路远端的数据链路层交互(数据链路层功能)
    - 查找功能, 查询转发表决定路由器的输出端口
    - 控制分组从输入端口转发到路由选择器
- 交换结构
    - 路由器内部的一种网络, 连接输入和输出端口
- 输出端口
    - 储存从交换结构接收的分组, 并通过执行必要的链路层和物理层功能在输入链路上(下一个路由器)传输这些分组
- 路由选择处理器
    - 执行路由选择协议, 维护路由表及连接的状态信息, 并为路由器计算转发表

这些功能有时总称为**路由转发平面**


#### 输入端口

输入端口的查找功能能让分组通过交换结构转发到输出端口. 路由表是由路由选择器计算和更新的, 但会在输入端口保存一份路由表的副本以完成查询功能. 路由表从路由选择器通过独立的总线(如PCI总线)复制到路由卡. 有了副本, 转发决策能在输入端口进行, 无需调用中央路由选择器, 避免了处理瓶颈. 

查找功能实现的要点:
- 必须使用硬件执行查找
- 需要对大型转发表使用超出简单线性搜索的技术: 快速查找算法
- 注意内存访问的时间

一个分组可能在进入交换结构的时候被暂时阻塞, 这时需要在输入端口处排队. 

输入端口出来要执行重要的查找操作, 还要采用许多其他动作:
- 必须出现物理层和链路层处理
- 必须检查分组的版本号, 检验和以及寿命字段
- 必须更新用于网络管理的计数器


#### 交换结构

交换结构的方式
- 经内存交换
- 经总线交换
- 经互联网络交换


#### 排队处理

在输入端口和输出端口这样的"交叉路口"中会出现排队问题. 随着队伍的增长, 缓存空间最终会耗尽, 导致出现丢包现象. 

缓存设置的经验:
- 少连TCP流时
    - 缓存量等于平均往返延时(RTT)乘链路容量(C)
    - $B = RTT \times C$
- 大量TCP流(N)时
    - $B = RTT \times \frac{C}{\sqrt{N}}$

输出端口出现排队的原因: 假设有N条输入段, N条输出段链路, 每条链路传输速度是一样的. 交换的处理速度是每条链路速度的N被, 则若N条输入最终指向同一输出时, 就会出现阻塞.

输出端口排队的后果是在输出端口上的**分组调度程序**必须选择队列中一个分组进行发送. 选择的原则可以是:
- 先来先服务(FCFS)
- 加权公平排队(WFQ)

这些分组丢弃与标记的策略叫做**主动队列管理(AQM)**算法. **随机早期检测(RED)**算法是最广泛研究和实现的AQM算法.

RED算法
- 为输出队列维护一个加权平均值
- 这个平均值小于最小阀值则正在接收
- 这个平均值大于最小阀值小于最大阀值则以某种概率标记或丢弃
- 这个平均值大于最大阀值则标记或丢弃
 
输入端口出现排队的原因: 交换结构不够快. 因为交换结构一次只能传递一个分组. 若前方的分组正在排队, 后方分组的出口就算空闲也得等待前方排队完成. 这种现象叫做输入排队交换机中的**线路前部(HOL)阻塞**.


### 网际协议(IP): 因特网中的转发和编址

因特网的网络层有三个主要组件:
- IP协议
- 路由选择
- 报告数据报中的差错和对某些网络层信息请求进行响应


#### 数据报格式

IPv4中的关键字:
- 版本号
- 首部长度
- 服务类型
- 数据包长度
- 标识, 状态, 片偏移
- 寿命
- 协议
- 首部校验和
- 源和目的的IP地址
- 选项
- 数据(有效载荷)

一条链路层帧能承载的最大数据量叫做**最大传输单元(MTU)**. 每条链路可能运行具有不同MTU的链路层协议. 当MTU小于数据报长度时, 需要将输出包封装在更小的IP数据报中. 这些较小的数据包叫做片(fragment)

IPv4设计者将标识, 标志和片偏移字段放在IP数据报首部, 以执行重新组合任务. 由于IP是一种不靠谱的服务, 数据报可能丢失或失序. 所以需要偏移量来保证顺序, 标志字段来保证完整. 最后一片标志比特设置为0, 其他片设置为1. 

在目的地, 数据段的有效载荷仅当在IP层已完全重构为初始IP数据报时才被传输到运输层. 配合TCP就能实现丢包的恢复. 

分片的弊端:
- 有额外的开销
- 让路由器和端系统更复杂
- 能够用于DoS攻击, 攻击者发送一系列古怪的无法预测的片

IPv6从根本上废止了分片.


### IPv4编址

主机与物理链路之间的边界叫做**接口(interface)**, 路由器与它任意一条链路之间的边界也叫做接口. 因此IP地址技术上是一个接口相关联的, 而不是主机或路由相关联的. 

IPv4由32个位组成, 通常8个一组如192.168.1.1

前28个位为**网络编号**, 后4位为**主机编号**

**子网掩码**: 子网掩码的1对应网络位的编号, 子网掩码的0对应主机位的编号, 如255.255.255.0
- 作用: 限制广播的网络段, 将莫大的网络划分变小

**子网**表示方法: 网络编号 + 主机号 + / + 子网掩码1的个数
- 如:192.168.1.0/24, 子网掩码为255.255.255.0

**网段地址**: 每个网段的第0个地址
- 如:192.168.1.0. 0 = 0000 0000, 第0号主机

**广播地址**: 网段的最后一个IP地址
- 如:192.168.1.255. 255 = 1111 11111, 最后一个主机

子网的定义:
- 分开主机和路由器的每个接口, 产生几个隔离的网络岛, 使用接口端接这些隔离的网络端点, 这些隔离的网络中没一个叫做一个子网. 

较低阶的比特可能(或可能不)具有另网的子网结构. 


#### 获取一块IP地址

ISP可能会从已经分配给它的更大快地址中提供一些地址. ISP的IP地址又由因特网名字和编号分配机构(ICANN)管理.


#### 获取主机地址: 动态主机配置协议

某组织一旦获得了一块地址, 它就可以为组织内的主机分配IP地址. 主机地址能够手动配置, 当然也能使用**动态主机配置协议(DHCP)**.

除了主机IP地址分配外, DHCP还允许一台主机获取其他信息. 如子网掩码, 默认网关和他的本地DNS服务器地址. DHCP有常被称为**即插即用协议(plug-and-play protocal)**. 

每当一台主机加入时, DHCP服务器从其当前可用的地址中分配一个任意地址给它, 当一台主机离开时收回池中. 

DHCP协议是一个4个步骤的过程:
- DHCP服务器发现
    - 刚开始, 没有分配地址也不知道DHCP服务器在哪. 所以DHCP客户端生成包含DHCP发送报文的IP数据报, 使用广播目的地址255.255.255.255, 使用0.0.0.0作为源地址. 
    - 链路层将帧广播到所有与该子网链接的子网
- DHCP服务器提供
    - DHCP服务器收到DHCP报文后, 用一个**DHCP提供报文**向客户端做出响应, 仍然使用255.255.255.255
    - 可能存在多台DHCP服务器提供DHCP报文供客户选择
- DHCP请求
    - 新到达的客户从一个或多个服务器提供中选择一个, 并向选中的服务器提供用一个**DHCP请求报文**进行响应
- DHCP ACK
    - 服务器用DHCP ACK报文对DHCP请求报文进行响应

然而一个移动的结点在子网之间移动时, 并不能维持与远程应用的TCP连接


#### 网络地址转换

如果一个组织想要扩容它的子网, 但是IPS已经为当前的范围分配过一块连续的地址了怎么办?

一种简单的方法就是: **网络地址转换(NAT)**.

NAT路由器上的一张NAT转换表, 并在表项中包含的端口号和其IP地址. 一张NAT转换表就能实现WAN和LAN的映射. 

许多IETF团体中的纯化论这大声疾呼反对NAT
- 1. 
- 2. 
- 3. 

NAT的另一个重要问题是他妨碍P2P应用程序. 因为如果对等方A, B在NAT后面, 它不能充当服务器并接收TCP连接. 


#### UPnP

NAT穿越越来越多地由通用即插即用(UPnP)提供, UPnP是一种允许主机发现并配置临近NAT的协议. 

总而言之, UPnP允许外部主机使用TCP或UDP向NAT化的主机发起通信会话. UPnP由于提供了有效和健壮的NAT穿越解决方案, 可能成为P2P应用的救世主. 


#### 因特网控制报文协议(ICMP)

ICMP最典型的用途的差错检测, 如遇到"目的不可达"之类的错误报文就是有ICMP产生的. 

ICMP通常被认为是IP的一部分, 但从体系结构上将, 它是位于IP之上的, 因为ICMP报文是承载在IP分组中的. 也就是说ICMP报文是作为IP的有效载荷的. 

ICMP报文有一个类型字段和一个编码字段, 并且包含引起ICMP报文首次生成的IP数据报的首部和前8字节内容. 

Traceroute程序就是使用了ICMP的差错检测:
- 为了判断源和目的之间所有路由器的名字和地址, 源主机发送一系列普通的IP数据报, 并为每个报文设置计时器
- 每个数据报携带了一个具有不可达的UDP端口号的UDP报文
    - 当传递最后一个路由器时, 这个路由器就会因为这个不可达报文向源发送ICMP错误, 从而得以判断结束
- 第一个数据报的TTL为1, 第二个为2, 第n个为n
    - 所以当传到第n个路由器时, 就会因为TTL正好过期而返回ICMP报错
    - ICMP错误报文又含有IP等信息, 因此Traceroute程序就能使用这些信息和往返时延作为数据




### IPv6

IPv6引入的重要变化显示在其数据报中
- 扩大的地址容量
    - IPv6将地址长度从32比特扩大到128比特
    - IPv6还引入一种称为**任播地址**的新型地址
        - 这种地址可以使数数据报交付给一组主机中的任意一个
- 简化高效的40字节首部
    - 使用定长的40字节首部允许更快处理IP数据报
- 流标签与优先级

IPv6定义的字段
- 版本
- 流量类型
- 流标签
- 下一个首部
- 跳限制
- 源地址和目的地址
- 数据

IPv4中存在IPv6中不存在的
- 分片/重新组装
    - 当IPv6遇到"分组太大"的问题时, 向发送发发送一个"分组太大"的ICMP差错报文
- 首部校验和
    - 因为运输层协议(如TCP)和数据链路层协议(如以太网)直线的检验操作
- 选项
    - 选项不再的标准IP首部的一部分, 而是可能出现在"下一个首部"指示的位置上


#### 从IPv4到IPv6的迁移

推倒重建的方法是可以, 但是实现太困难了, 所以使用逐渐整合IPv6然后慢慢淘汰IPv4的方法.

- 双栈法
    - 一个结点具有完整的IPv6和完整的IPv4, 它有发生和接收两者的能力
    - 双栈法中如果任一一个结点是IPv4使能的, 则必须使用IPv4
        - 因为当IPv6结点要向一个IPv4结点发送数据报时, 需要"裁剪"自身的报文一符合IPv4
        - 而"裁剪"后就没办法恢复了
- 隧道法(双栈法法的一种)
    - 我们把两台IPv6之间的IPv4路由器集合成为**隧道**
    - IPv6要向IPv4发送数据报时, 将IPv6的数据报作为IPv4的有效载荷发送, 到另一端的IPv6路由器后在解封


### 路由选择算法

路由选择算法在网络路由器中运行, 交换和计算信息, 哟个这些信息配置转发表. 路由选择的工作是: 确定从发送发到接收方的好路径. 

通常成与主机直接连接的一次路由器为**默认路由器**或**第一跳路由器**. 将源主机的默认路由器成为**源路由器**, 将目的主机的路由器称为**目的路由器**. 

路由选择算法的分类
- 根据全局还是分散区分
    - 全局式路由选择算法
        - 具体实践中, 具有全局动态信息的算法称为**链路状态(LS)算法**
    - 分散式路由选择算法
        - **距离向量算法**是一个分散式路由选择算法
- 根据算法是静态还是动态区分
    - 静态路由选择算法
    - 动态路由选择算法
- 根据负载敏感区分
    - 负载敏感路由选择算法
    - 负载路迟钝由选择算法


#### 链路状态路由选择算法

链路状态路由选择算法中, 网络拓扑和所有链路的费用是已知的, 所以可以用LS算法的输入. 

可以使用Dijkstra算法

存在的问题:
- 一条链路的吞吐量是有限的, 但是链路是双向的
    - 因此当多个路由同时进行路由选择时, 都不一而同的选择"空旷"的链路, 而原来拥堵的链路又因路由的离开变得"空旷", 如此反复震荡
    - 也就是说路由器之间能进行自同步
- 解决方法
    - 让每台路由器发送链路通过的时间随机化
    - 或使用其他路由选择算法, 如距离向量路由选择算法


#### 距离向量路由选择算法

距离向量(DV)算法是一种迭代的，异步的和分布式的算法，而LS是一种使用全局信息的算法。
- 分布式
    - 每个结点都要从一个或多个直接相连邻居接收某些信息，然后将计算结果分发给邻居
- 迭代的
    - 此过程一直要持续到邻居之间没有信息交换为止
- 异步的
    - 它不要求所有结点互相之间步伐一致地操作

最低费用$d_x(y)$的计算方法:
$$d_x(y) = min_y|c(x, v) + d_v(y)|$$
$c(x, v)$表示邻居结点v的距离， $d_v(y)$表示v到y的最低费用

每个结点维护一下信息：
- 对于每个邻居，从x到直接相连邻居v的费用
- 结点x到所有目的地y的距离向量
- 结点x的每个邻居结点v的距离向量

在DV算法中，每当结点x发现他的直接相连的链路费用发生变化或收到邻居发来的更新时，它就更新(如果有更低费用路径的话)其转发表对应位置的距离向量。同理，每个结点执行同x的操作，转发表更新时通知相邻结点。结点重新计算距离向量后，它再次发送他们更新后的结果给邻居结点。当所有结点已得到最到路径无需更新时，没有互相发生信息通知，从而进入等待状态。

但是DV算法会遇到路由选择环路问题，即当一条链路变得拥堵时，如费用从4变为60，其他链路无法知道细节(只知道他们到某点的最短路径，但这个路径中可能包含已变拥堵的链路)，从而产生环路，甚至会出现无穷循环的问题。


#### 层次路由选择

大规模的网络具有数亿的路由器，无论是LS算法还是DV算法，在大量的运算中都得不到让人满意的复杂度，甚是会网络的流量都用在了结点间数据获取上。

因此通过将路由器组织进**自治系统(AS)**来解决，每个AS有一组通常处在相同管理控制下的路由且组成。相同AS中的路由器使用相同的路由选择算法，一个自治系统内运行的路由选择算法叫做**自治系统内部路由选择协议**。

多个AS互联形成大的网络，因此负责将AS与外界连接的一个或多个路由器称为**网关路由器**。AS间最短路径又由**自治系统间路由选择协议**处理完成，两个通信的AS间必须运行相同的自治系统间路由选择协议，事实上因特网中所以AS都运行这相同的自治系统间路由选择协议：BGP4。

**热土豆路由选择**
- AS尽可能快的(准确的讲是尽可能经济的)扔掉分组(热土豆)。
这通过让路由器向某网关路由器发送分组来完成，
同时该网关路由器在到目的地路径上的所以网关路由器中有最低的费用。


### 因特网中的路由选择

一个AS是一个处于相同的管理与技术控制下的路由器集合，在AS间都运行这相同的路由选择协议。

路由器内部路由选择协议用于确定一个AS内执行的路由选择方式。AS内部路由选择协议又称为**内部网关协议**。

历史上有两个路由选择协议曾被广泛用于因特网上自治系统内路由的选择：
- **路由选择信息协议(RIP)**
- **开放最短路优先(OSPF)**


#### RIP

RIP是一种距离向量协议，类似DV协议。在RIP中路由选择更新信息在邻居之间使用一种**RIP响应报文**来交换。可由一个路由器发往AS内的多个子网。响应报文又被称为**RIP通告**

每台路由器维护一张称为**路由选择表**的RIP表， 一台路由器的路由选择表包括该路由器在内的距离向量和该路由的转发表。当一个路由收到通告时就会与旧路由选择表合并，特别是有更短路径时。

RIP使用一个位于网络层协议(IP)之上的传输层协议(UDP)来实现网络层功能。


#### OSPF

OSPF和IS-IS都设置在上层的ISP中，而RIP被设置在下层ISP和企业网络中。

OSPF的核心是使用一个洪泛链路状态信息的链路状态协议和一个Dijkstra最低费用的路径算法。

使用OSPF时，路由器向自治系统内所有其他路由器广播路由选择信息。每当一条链路的状态变化时，路由器就会广播。即使链路状态没有变化，它也会周期性的广播(增加了健壮性)。

OSPF的优点
- 安全
- 允许多条相同费用的路径
- 对单播和多播路由选择的综合支持
- 支持在单个路由选择域内的层次结构

一个OSPF自治系统可以分配成多个区域。每个区域运行自己的OSPF链路状态路由选择算法，一个区域内每台路由器都向区域内其他路由器广播状态。区域内一台或多台**区域边界路由器**负责为流向该区域外的分钟提供路由选择。


### 自治系统间的路由选择：BGP

通过定义**边界网关协议**来跨越多个AS进行路由选择。它通常被称为BGP4或简称BGP。

BGP为每个AS提供里进行以下工作的手段：
- 从相邻AS获取子网可达信息
- 向本AS内部的所有路由器传播这些可达信息
- 基于可达信息和AS策略，决定到达子网的"好"路由

BGP的使得每个子网想因特网的其余部分通告它的存在。


#### BGP基础

BGP极其复杂，这里简单介绍。在BGP中，路由器对通过使用179端口的半永久TCP来连接交换路由信息。对于在两个不同AS中的路由器链路而言，通常有一条BGP TCP链接。在一个AS中的路由器之间还有许多半永久BGP TCP连接。

对于每条TCP连接，位于连接端点的两台路由器称为**BGP对等方**，沿着该连接发送所有BGP报文的TCP连接成为**BGP会话**。此外，跨越两个AS的BGP会话称为**外部BGP(eBGP)会话**，在同一个AS中的BGP会话成为**内部BGP(iBGP)会话**。

BGP使得每个AS知道经过其相邻AS可达哪些目的地。在BGP中，目的地不是主机而是CDIR化的前缀，每个前缀表示一个子网或一个子网集合。

在任何AS中的网关路由器接收到eBGP学到的前缀后，该网关路由器使用它的iBGP会话来向该AS中其他路由器发布这些前缀。


#### 路径属性和BGP路由

在BGP中，一个自治系统由其全局唯一的**自治系统号(ANS)**所标识。当一台路由器通过BGP会话通告一个前缀是，他在前缀中包括一些**BGP属性**. 用BGP术语来说，带有属性的前缀称为一条**路由**。BGP对等方彼此通告路由。

两个较为重要的属性是AS-PATH和NEXT-HOP
- AS-PATH
    - 该属性包含前缀通告已经通过了的那些AS
    - 当一个前缀传送到一个AS时，该AS将它的ASN增加到AS-PATH属性中
    - AS-PATH属性用来检测和防止循环通告
        - 如果路由器看到它的AS被包括在该路径列表中，它将拒绝该通告
    - 类似并查集
- NEXT-HOP
    - NEXT-HOP是一个开始某AS-PATH的路由器接口
    - 类似根(起点)
- BGP也包括允许路由器对路由分配偏好测试度的属性，以及前缀如何插入位于其实AS的BGP的属性

一台网关路由器接收到一台路由器通告时，它使用其**输入策略**来决定是否接收该路由，是否设置某种属性。


#### BGP路由选择

如果对相同前缀存在两条或多条路由，则BGP顺序的调用下列消除规则，直到留下一条路由
- 路由被指派一个本地偏好值作为它们的属性之一
    - 具有最高本地偏好值的路由将被选择
- 余下路由中(路由偏好值相同)，具有最短AS-PATH的路由将被选择
- 余下路由中，将选择具有最靠近NEXT-HOP路由器的路由
- 如果仍留下许多路由，则使用BGP标识符来选择


### 广播和多播路由选择

在**广播路由选择**中，网络提供了从一种源结点到网络中所有其他结点交付分组的服务;**多播路由选择**使单个源结点能向其他网络结点的子集发送分组的副本。


#### 广播路由选择算法

- N次单播
    - 源结点产生该分组的N个副本，对不同目的地的每个副本进行编址并传输
    - 缺点
        - 效率底
        - 要获取所以结点的信息就又要获取全局的数据

显然更有效率的方式是，经第一跳仅发送分组的单个副本，然后让第一跳后面其他端的结点生成并转发任何附加的所需副本。类似细胞分裂。

- 无控制洪泛(flooding)
    - 该方法要求源结点向它所有邻居结点发送分组副本。
    - 当某结点收到一个广播的分组时重复上一步操作
    - 缺点
        - 如果图中有圈，广播将会无限循环
        - 产生大量重复的分组副本，导致**广播风暴**
- 受控洪泛
    - **序号控制洪泛**
        - 源结点将其地址以及**广播序号**放入广播分组，再向邻居发送分组
        - 每个结点维护它已经收到的，复制和转发的源地址和每个广播分组的序号列表
    - **反向路径转发(RPF)**
        - 当分组是从它到发送方的最短路径上的下一个邻居传来时才向所以出链路传输报文
        - 它仅使用这个邻居的身份以决定是否洪泛一个接收到的分组
- 生成树广播
    - 虽然受控洪泛避免了广播风暴，但是它们不能完全避免冗余分组传输
    - 首先对网络结点构造出一棵生成树
    - 当一个源结点要发送广播分组时，它向属于该生成树的特定链路发送分组
    - 接收广播分组的结点则向生成树的所以邻居转发该分组
    - 注意到一个结点不必知道整棵树，只需要知道它在的哪些邻居是生成树中的


#### 实践中的广播算法

building


### 多播

多播服务可以将分组从一个或多个发送方交付给一组(多个)接收方。

提出问题：
- 怎么标识多播分组的接收方？
- 怎么为发送到这些接收方的分组编址？
    - 如果是从发送方一一遍历接收方来发送，那就有N次单播的问题
    - 如果不是上述方式，那要分组要携带很多的IP地址吗

由于这些原因，在因特网体系结构中，多播数据报使用**间接地址**来编址。也就是说用一个标识来表示一组接收方，寻址到该组的分组副本会被交付到所有与改组关联的多播接收方(多播组)。


- 一个组如何形成，如何终结？
- 如何选择组地址？
- 新主机如何加入某个组？
- 任何主机都能加入一个组吗？谁来限制？
- 一个组成员知道其他组成员的标识吗？
- 网络结点互相之间如何交互，以向所以组成员交付一个多播数据报呢？

对于这些问题的回答都与因特网组管理协议(IGMP)有关


#### 因特网组管理协议(IGMP)

IGMP版本3运行在一台主机与其直接相连的路由器之间，IGMP为一台主机提供了手段，让它通知与其相连的路由器：在本主机上运行的一个应用程序想加入一个特定的多播组。由于IGMP的交互范围局限在主机与其相连的路由器之间，显然需要一种协议来协调遍及因特网内的多播路由器，以便多播数据报能路由到其最终的目的地。

因此因特网中的网络层多播是由两个互补的组件组成：IGMP和多播路由选择协议。

IGMP只有三种报文类型
- 由一台路由器向所有与主机相连的接口发送一个membership\_query报文
    - 以确定该接口上主机已加入的所以多播组集合
- 主机用一个membership\_report报文来相应membership\_query
    - 当一个应用程序首次加入一个多播组时，也可由主机产生membership\_report报文
- 最后一种是leave\_group报文，是可选的
    - 当无主机响应一个具有给定地址的membership\_query报文时，路由器就推断出已没有主机在这个多播组了
    - 这是**软状态**的一个例子


#### 多播路由选择算法

多播路由选择算法的目标就是发现一棵链路树，这些链路连接了所有具有属于该多播组的相连主机的路由器。当然，该树也许会包含一些没有属于该多播组的相连主机的路由器(路过)。

实践中采用两种方法来确定多播路由选择树，两种方法的区别在于：
- 使用一棵组共享树的多播路由选择。
    - 使用基于中心的方法来构造多播路由选择树
    - 具有属于多播组的相连主机的边缘路由器向中心结点发送加入保报文，直到到达多播树中的一台路由器
    - 然后沿原路转发多波分组给发送加入报文的路由器
- 使用一棵基于源的树的多播路由选择
    - 使用具有剪枝RPF算法来构造一棵多播转发树
    - 一个接收到多播分组的多播路由器，如果它无加入该组的相连主机，则它向它的上游路由器发送一个**剪枝(pruning)**报文
        - 因为如果一个路由器有很多下游路由器，但是他们都不是多播组中的，这样就会导致大量冗余的转发
    - 如果一台路由器从它的每个下游路由器都收到剪枝报文，则它向它的上游路由器发生剪枝报文


#### 因特网中的多播路由选择

第一个用于因特网的多播路由选择协议的**距离向量多播路由选择协议(DVMRP)**，DVMRP使用前面描述的具有剪枝的RFP算法。

也许使用最广泛的因特网多播路由选择协议是**协议无关的多播路由选择协议(PIM)**,该协议明确辨识两种多播分发情形。
- 稠密模式
    - 稠密模式是一种洪泛与剪枝反向路径转发技术，类似DVMRP的思想
- 稀疏模式
    - RIP稀疏模式使用聚集点来建立多播分发树
    - 在**源特定多播(SSM)**中仅允许单一发送方向多播树中发送流量，大大简化树的构建和维护


## 链路层：链路、接入网和局域网

两种不同类型的链路层信道
- 广播信道
    - 如有线局域网、卫星网
- 点对点信道
    - 如以太网
        
几个概念和技术
- 差错检测和纠正
- 多路访问网络和交换局域网
    - 如以太网
- 虚拟局域网和数据中心网络


### 链路层概述

将运行链路层协议的任何设备均称为**结点**。把沿着通信路径连接相邻结点的信道成为**链路**。在通过特定的链路时，传输结点将数据报分装在**数据层帧**中，并将该帧传送到链路中。

游客好比数据报，每个运输区段好比一条链路，每种运输方式好比链路层协议，而旅行社好比路由选择协议。


#### 链路层提供的服务

链路层协议能够提供的可能服务包括
- 成帧(framing)
    - 每个网络层数据报经链路传送之前，几乎所以链路层协议都有将其链路层帧封装起来
    - 一个帧由一个数据字段和若干首部字段组成，其中网络层数据报就插在数据字段中
- 链路接入
    - **媒体访问控制(MAC)**协议规定了帧在链路上传输的规则
- 可靠交付
    - 与运输层可靠交付服务类似，链路层的可靠交付服务通常通过确认和重传却的的。
    - 对于一些低比特差错的链路，如光纤、同轴电缆等，可靠交付会产生不必要的开销
    - 许多有线的链路层协议不提供可靠交付服务
- 差错检测和纠正
    - 链路层的差错检测通常给复杂，而且由硬件实现


#### 链路层在何处实现

链路层的主体部分是在**网络适配器**中实现的，网络适配器有时也称为**网络接口卡(NIC)**。位于网络适配器核心的是链路层控制器，该控制器通常是一个实现了许多链路层服务的专用芯片。

在发送端，控制器取得了由协议栈较高层生成并储存在主机内存中的数据报，在链路层中封装该数据段，然后遵循链路介入协议将该帧传进通信链路中。

在接收端，控制器接收了整个帧，抽取出网络层数据报。如果链路从执行差错检测，则需要控制器在帧的首部设置差错检测比特，有接收控制器执行差错检测。


#### 差错检测和纠正技术

为了避免差错，使用**差错检测和纠正比特(EDC)**来增强传输的数据。

即使使用了差错检测比特，也可能有为检测出的比特差错，因此我们要适当选择检测方案来使得这种概率很小，但是出现的概率月小说明技术越复杂，开销越大。


#### 奇偶校验

以偶检验为例，奇校验同理。

设一段数据有d个比特，设置一位校验位，使得这d+1个比特中1的个数为偶数。接收方只用数d+1个比特中1的个数。如果发现奇数个1，则至少出现了奇数个比特差错。

显然，这样的单纯的奇偶校验无法实现纠正功能，所以使用一种**二维奇偶校验**。把d个比特划分为i行j列，对每行没列计算奇偶值，产生的i+j+1个比特构成了链路层帧的差错检测比特。

``` 
d1,1 d1,2 ...   d1,j | d1,j+1
... ..... ...   d2,j | d2,j+1
... ..... ...   .... | ...
di,1 di,2 ...   di,j | di,j+1
—————————————————————+———————
di+1,1 di+1,2 di+1,j | di,j+1

```

这样，包含比特差错的行和列都会检测到差错，就能够实现纠正了。但是检验比特本身也是可能出现差错的。而且二维奇偶校验能检测一个分组中两个比特差错的任意组合，但无法对其纠正。

这种由接收方检测和纠正差错的能力成为**向前纠错(FEC)**。FEC避免了重传带来的时延。


#### 校验和方法

将b个比特数据作为一个k比特整数的序列处理，一个简单的校验和方法就是将这k个比特加起来，并用得到的和作为差错检测比特。

因特网校验和就是基于这种方法， 即数据的字节作为16比特的整数对待并求和。这个和的反码形成了携带在报文首部的因特网校验和。

校验和方法需要相对小的分组开销，如TCP和UDP中的校验和只用了16比特。但是也提供了较弱的差错保护。


#### 循环冗余检测

现今的计算机网络中广泛应用的差错检测技术基于**循环冗余检测(CRC)编码**。CRC编码也称为**多项式编码**，因为该编码能够将要发送的比特串看作为系数的0和1的一个多项式，对比特串的操作被解释为多项式算术。

CRC编码操作如下。对于一个d比特是数据D，发送发和接收方要事先协商一个r+1比特，成为**生成多项式**G。我们要求G的最高为有效比特是1。对于一个给定的数据段D，发送方选择r个附加比特R，并将它附加到D上，使得得到的d+r模式用模2算数恰好能被G整除。接收方用G去除接收到的d+r比特，看余数是否为零就可以做到差错检测。

所有CRC计算采用模2算数来做，在加法中不进位，在减法中不借位。所以加法和减法是相同的，且等价于操作数按位异或(XOR)。除此之外，乘法和除法还是二进制算数的乘除。

对于怎么求R，根据我们的要求有：
$$D \times 2^k\ XOR\ R = nG$$

两边都用R异或
$$D \times 2^k = nG\ XOR\ R$$

由这个等式可知，如果我们用G来除$D \times 2^k$，余数正好是R，换句话说我们可以这样计算R：
$$R = remainder \frac{D \times 2^k}{G}$$

国际标准已经定义了8、12、16和32比特的生成多项式G。

每个CRC标准都能检测小于r+1比特的突发差错。此外，在适当的假设下，长度大于r+1比特的突发差错以概率$1-0.5^r$被检测到。每个CRC标准也能检测任何奇数个比特差错。


### 多路访问链路和协议

我们提到有两种类型的网络链路：**点对点链路**和**广播链路**。

一个对链路层很重要的问题是：如何协调多个发送和接收节点对一个共享广播信道的访问，就是**多路访问问题**。**多路访问协议**就是用来规范结点们在共享广播上的传输行为，来解决多路访问问题。

因为所有结点都可以传输帧，所以可能出现多个结点同时传输的情况。当这种情况发生时，传输的帧在所有的接收方出**碰撞**. 当碰撞发生时，没有一个接收结点能够有效的获取任何帧。显然，大量的宽带资源因此浪费。

我们能够将任何多路访问协议划分为3类型之一：
- **信道划分协议**
- **随机接入协议**
- **轮流协议**


#### 信道划分协议

时分多路复用(TDM)和频分多路复用(FDM)是两种比较简单的技术。举例来说，假设一个支持N个结点的信道且信道传输速率为R bps。TDM将时间划分为**时间帧**，并进一步划分每个时间帧为N个**时隙(slot)**。然后把每个时隙分配给N个结点中的一个。无论何时某个结点有分组要发送时，它在循环的TDM帧中指派给它的时隙内传输分组比特。通常，选择的时隙长度应使一个时隙内能够传输单个分组。

同理，FDM将R bps信道划分为不同的频段，每个频段具有R/N宽带。并把每个频率分配给N个结点中的一个。

TDM和FDM有相同的优点和缺点
- 优点
    - 避免了碰撞
    - 公平分配
- 缺点
    - 限制于R/N的平均速率，即使只有一个分组要发送时

第三种信道划分协议是**码分多址(CDMA)**，CDMA对每个结点分配一种不同的编码，然后每个结点用它唯一的编码来对它发送的数据进行编码。

如果精心选择这些编码，则CDMA可以做到不同的结点同时传输，此外，它还具有抗干扰特性。


#### 随机接入协议

随机接入协议中，一个传输结点总是一信道的全部速率(R bps)进行发送。当有碰撞时，涉及碰撞的每个结点反复的重新发送它的帧，到该帧无碰撞为止。但重发不是立即重发，而是等待一个随机时延再重发。每个结点独立选择随机时延。

最常用的随机接入协议有ALOHA协议和载波侦听多路访问(CSMA)协议。以太网是一种流行并广泛部署的CSMA协议。

- 时隙ALOHA
    - 假设
        - 所以帧由L比特组成
        - 时间被划分成长度为L/R秒的时隙
        - 结点只在实习起点开始传帧
        - 结点是同步的，每个结点知道时隙何时开始
        - 如果一个时隙中有两个或多个帧碰撞，则所以结点在该时隙结束前能检测到该碰撞时间
    - 操作
        - 当节点有一个帧要发送时，它等到下一个时隙开始并在该时隙传输整个帧
        - 如果没有碰撞，则传输成功
        - 如果有碰撞，结点会在时隙结束之前检测到。然后该结点以p的概率在后续的每个时隙中重传它的帧，直到没有碰撞发生
    - 优点
        - 当某结点是唯一活跃的结点时，能够全速R传输
    - 效率：当有大量活跃结点且每个结点总有大量的帧要发送是，长期运行中成功时隙的份额
        - 对于N个节点，每个节点都有$p(1-p)^{N-1}$的概率传输成功，则N个节点就有$np(1-p)^{N-1}$的概率
- 纯ALOHA
    - 效率是时隙ALOHA的一半


#### 载波侦听多路访问(CSMA)

**载波侦听多路访问**和**具有碰撞检测的CSMA(CSMA with Collision Detection, CSMA/CD)**协议族中。
包含有两个规则：
- 说话之前先听
    - 如果其他人正在说话，等他们说完为止。
    - 在网络领域中称为**载波侦听**，即一个结点在传输前先听信道
- 如果与其他人同时开始说话，停止说话。
    - 在网络领域中称为**碰撞检测**，即当一个传输结点在传输时一直侦听此信道

信号从一个结点到另一个结点所花费的时间称为**信道传播时延**。设$t_0$时刻信道空闲，结点B开始传输，在$t_1$时刻，B结点开始传输的信号没有传输到D，D结点仍然以为信道空闲，此时结点D传输信号就会发生碰撞，导致接下来传输的信号被浪费。显然，信道传播时延在决定其性能方面起着关键作用。


#### 具有碰撞检测的载波侦听多路访问(CSMA/CD)

当某结点执行碰撞检测时，一旦它检测到碰撞将立刻停止传输。CSMA/CD能在很短的时间内(一个信号传播时延)检测到碰撞，并他们的传输。通过不传输无用帧、损坏帧，将有助于改善协议性能。

从与广播信道相连的适配器(在结点中)的角度总结CSMA/CD的运行：
- 1. 适配器从网络层获取一条数据报，准备链路层帧，并将其放入适配器缓存中
- 2. 如果适配器侦听到信道空闲，则开始传输。否则，它将等待，直到侦听到没有信号能量时才能开始传帧
- 3. 传输过程中，适配器监视来自其他使用该广播信道的适配器信号的存在
- 4. 如果适配器传输整个帧而未检测到来自其他适配器的信号能量，则传输完成，否则中止传输
- 5. 中止传输后，适配器等待一个随机时间量，然后返回步骤2

对于适配器等待的随机时间量，我们希望事件间隔应该是这样：当碰撞结点数量较小时，时间间隔较短;当碰撞结点数量较大时，时间间隔较长。

因此，用于以太网以及DOCSIS电缆网络多路访问协议中的**二进制指数后退**算法，简练的解决了这个问题。特别是，当传输一个给定帧时，在该帧经历了一连串的n次碰撞后，节点随机地从[0, 1, 2, ..., $2^n-1$]中选择一个K值。因此，一个帧经历的碰撞越多，K的选择间隔就越大。对于以太网，一个节点等待的实际时间量是K\*512比特，n最大值为10。K的集合长度随着碰撞次数呈指数增长，因此称为二进制指数后退。

**CSMA/CD效率**
- 我们将CSMA/CD效率定义为：
当有大量的活跃结点，且每个节点有大量的帧要发送时，
帧在信道中无膨胀地传输的呢部分时间在长期运行时间中占的份额
- CSMA/CD效率：
    - $效率 = \frac{1}{1+5d_{prop}/d_{trans}}$
    - 其中$d_{trans}$表示传输一个最大长度的以太网帧的时间，
    $d_{prop}$表示信号能量在任意两个适配器之间传播所需的最大时间


#### 轮流协议

ALOHA和CSMA协议能做到在只有一个结点活跃时，该结点具有R bps的吞吐量;但不能做到当有M个结点活跃时每活跃节点的吞吐量接近R/M bps。

比较重要的两种轮流协议：
- **轮询(poll)协议**
    - 轮询协议要求有一个主结点，
    主节点首先向结点1发送一个报文，告诉结点1能传输的帧的最多数量，
    结点1传输后，直接点再告诉结点2，以此方式循环每个结点
    - 缺点
        - 引入了轮询时延，即通知一个结点所需要的时间
        - 一旦主节点故障，整个信道变得不可操作
- **令牌(token)传递协议**
    - 这种协议没有主节点，而是将令牌(一个小的特殊帧)在结点之间以某种特定顺序传递
        - 如结点1传给结点2，结点2传给结点3，而结点N可能传给结点1
        - 当一个结点收到令牌后如果它有帧要发送则持有令牌，否则立即向下传递
        - 发送最大数目的帧数后，把令牌传给下一个结点
    - 缺点
        - 如果一个结点故障，可能整个信道崩溃
        - 如果存在结点忘记释放令牌，则必须使用某回复步骤使令牌回到循环中


#### DOCSIS：用于电缆因特网接入的链路层协议

电缆接入网可作为多我访问协议(即FDM，TDM，随机访问接入和集中分配时隙都用于一个网络中)的一个极好例子

一个电缆接入网络通常在电缆网络头端将几千个住宅电缆调制解调器与一个**电缆调制解调器端接系统**(Cable Modem Termination System,CMTS)连接。**数据经电缆服务接口**规范(DOCSIS)定义了电缆数据网络体系结构及其协议。

DOCSIS使用FDM将下行(CMTS到调制解调器)和上行(调制解调器到CMTS)网络段划分为了多个频率信道。每个下行信道宽6MHz，每个信道具有大约40Mbps吞吐量;每个上行信道具有6.4MHz的最大信道带宽，并且最大的上行吞吐量约为30Mbps。每个上行和下行信道均为广播信道。CMTS在下行信道中传输的帧被所以信道上做接收的电缆调制解调器接收到;然而因为仅有带一的CMTS在下行信道上传输，不存在多路访问问题。但在上行方向，存在多个技术挑战，因为多个电缆调制解调器共享到CMTS的相同上行信道(频率)，因此能够潜在地出现碰撞。

每条上行信道被划分为时间间隔(类似TDM)，每个时间间隔包含一序列微时隙，电缆调制解调器可在该微时隙中向CMTS传输。CMTS显示地准许各个电缆调制解调器在特定的时隙中传输。CMTS在下行信道上通过发送称为MAP报文的控制报文，指定哪个电缆调制解调器能够在微时隙中传输由控制报文指定的时间间隔。

那CMTS一开始是如何知道哪个电缆调制解调器有数据要发送呢？通过让电缆调制解调器在专用于此目的的一组特殊微时隙间隔内向CMTS发送微时隙请求帧来完成该人物。浙西微实习请求帧以随机接入的方式传输，故可能发生碰撞。电缆调制解调器既不能侦听上行是否忙，也不能检测碰撞。相反，该电缆调制解调器如果没有在下一个下行控制报文中收到对请求分配的响应话，就推断它的微时隙经历了一次碰撞。然后电缆调试解调器使用二进制指数回退将其微时隙请求帧延缓到以后时隙重新发送。当上行信道有很少流量，电缆调制解调器可能在名义上分配给微时隙请求帧的的时隙内实际传输数据帧。


### 交换局域网

因为交换机运行在链路层，所以它们交换链路层帧(而不是网络层帧)，不识别网络地址，不使用RIP或OSPF这样的路由选择算法来确定通过第2层交换机网络的路径。它们使用链路层地址而不是IP地址来转发链路层帧通过交换机网络。


#### MAC地址

并不是主机或者路由具有链路层地址，而是它们的适配器(即网络接口)具有链路层地址。重要的是注意到链路层交换机并不具有与它们的接口(这些接口与主机和路由器相连)相关联的链路层地址。这是因为链路层交换机的任务是在主机与路由器之间承载数据报;交换机透明地执行，主机和路由器不必明确地将帧寻址到其间的交换机。

链路层地址有各种不同的称呼：**LAN地址**、**物理地址**或**MAC地址**。MAC地址似乎是最为流行的术语。

MAC地址长度为6字节，通常用十六进制表示。没有两块适配器具有相同的MAC地址。

IEEE管理这MAC地址空间，IEEE的MAC地址分配方式是：前24个比特固定，后24个让公司自己生成。

适配器的MAC地址具有扁平结构(这与层次结构相反)，而且不论适配器到哪里都不会变化。

当某适配器要向某些目的适配器发送一个帧时，发送适配器将目的适配器的MAC地址插入到该帧中，并将该帧发送到局域网上。一块适配器可以接受一个并非向它寻址的帧。这样，当适配器接收到一个帧时，将检查帧中的目的MAC地址是否与它自己的MAC地址匹配。如果匹配，在适配器提取数据报，并沿着协议栈向上传递。否则丢弃该帧。

当某发送适配器要让局域网上所有其他适配器来接收并处理它打算发的帧时，发送适配器可以在帧中插入一个特殊的**MAC广播地址**。对于使用6字节地址的局域网，广播地址为48个1。


#### 地址解析协议(ARP)

地址解析协议负责网络层地址(如IP地址)和链路层地址(MAC地址)的转换。

为了发送数据报，不仅要向适配器提供IP数据报，还要提供目的主机的MAC地址。然后发送适配器将构造一个包含目的MAC地址的链路层帧，并把该帧送进局域网。

那发送主机如何知道目的主机的MAC地址呢？ARP。在发送主机中的ARP模块将取IP地址作为输入，然后返回MAC地址。

ARP和DNS有些类似，但是DNS为因特网中任何地方的主机解析主机名，而ARP只为在同一个子网上的主机和路由器解析IP地址。

ARP的工作方式：每台主机或路由器在其内存中具有一个**ARP表**，这张表包含IP地址到MAC地址的映射关系。该ARP表也包含一个寿命(TTL)值，它指示了从表中删除每个映射的时间。

ARP的表项从何而来？发送方用广播ARP分组来解析目的地址，首先发送方构造一个称为**ARP分组**的特殊分组。一个ARP分组包含几个字段，包括发送和接收IP地址及MAC地址。ARP查询分组和响应分组都具有相同的格式。ARP查询分组的目的是询问网络上其他主机和路由器以确定要解析的IP地址对应的MAC地址。当子网上其他适配器接受到查询分组时，适配器将ARP分组传给ARP模块，如果模块检测到它的IP与ARP分组的目的IP匹配，则返回一个希望映射的相应ARP分组。然后查询主机更新它的ARP表。


#### 发送数据报到子网以外

发送主机向它的适配器传递数据报，同时还要指示一个适当的目的MAC地址。该MAC地址就在通往目的主机路径上的下一跳路由器的MAC地址。一旦发送适配器有了这个MAC地址，它创建一个包含最终目的地址的帧，并把改帧送入子网。当子网上的路由器适配器看到链路层帧向它寻址，它就把该帧传递给路由器的网络层。路由器通过查询转发表来决定数据报要被转发到哪个接口。然后该接口把这个数据报传递给它的适配器，适配器把该数据报封装到一个新的帧中并发向下个子网。


### 以太网

今天以太网是目前为止最流行的有线局域网记住。以太网的成功有很多原因：
- 以太网是第一个广泛部署的高速局域网
- 令牌环、FDDI和ATM比以太网更加复杂、更加昂贵
- 以太网总是能产生运行在相同或更高数据速率下的版本

以太网的发展：
- 20实际70年代Bob Metecalfe和David Boggs发明了初始的以太局域网。使用同轴电缆总线来连接节点
- 以太网的总线拓扑实际上从20实际80到90年代中期一直保持不变
    - 使用总线拓扑的以太网是一种广播局域网
- 20实际90年代后期大多数公司和学校使用一种基于集线器的星形拓扑以太网
    - 主机(和路由器)直接用双绞对铜线与一台集线器相连
        - **集线器(hub)**是一种物理设备，当表示0或1的比特到达一个接口时，集线器向它的其他接口转发该比特的副本
        - 如果两个接口同时收到帧则发生碰撞
- 21实际早期，以太网继续使用星形拓扑，当位于中心位置的集线器被**交换机(switch)**代替


#### 以太网帧结构

| 前同步码 | 目的地址 | 源地址 | 类型 | 数据字段 | CRC |
|----------|----------|--------|------|----------|-----|

- 前同步码 
    - 前7个字节都是10101010;最后一个字节是10101011
    - 适配器会根据以太局域网类型不同以不同速率传输帧
    - 但是并不能精确额定传输速率
    - 通过前同步码就可以锁定前一个适配器的时钟
- 目的地址 
    - 目的适配器的MAC地址
- 源地址 
    - 发送该帧的适配器的MAC地址
- 类型 
    - 类型字段允许以太网复用多种网络层协议
    - 每种协议都有各自的、标准化的类型编号
- 数据字段 
    - 这个字段(46~1500字节)承载了IP数据报
    - 过大要分片，过小要填充
- CRC 
    - 循环冗余检查

所有的以太网技术都向网络层提供无连接服务。也就是说不需要事先握手。

以太网技都向网络层提供不可靠服务。它既不发送确认帧也不发送否定帧，CRC校验出错时只是丢弃帧。(在链路层)缺乏可靠的传输有助于使得以太网简单便宜。但是它也意味着传递到网络层的数据报流能够有时间间隙。


#### 以太网技术

以太网具有某种字母的缩写词，如：10BASE-2、100BASE-T等。它们具有一定规律性：首字母缩写词的第一部分指该标准的速率，"BASE"指基带以太网，最后一部分指物理媒介。

今天大多数的安装中，结点经点对点的由双绞铜线或光纤线缆构成的线段与一台交换机相连。

吉比特以太网是对10Mbps和100Mbps以太网标准的扩展。吉比特以太网提供1000Mbps的总数据速率，与大量已安装的以太网设备基础保持完全兼容。吉比特以太网的标准称为IEEE802.3z，它完成一下工作：
- 使用标准以太网帧格式，并且向后兼容10BASE-T和100BASE-T技术
- 允许点对点链路以及共享的广播信道
- 使用CSMA/CD来共享广播信道
- 对于点对点信道，允许两个方向上都以1000Mbps全双工操作


#### 链路层交换机

交换机的任务是接收入链路层帧并將它们转发到出链路。交换机自身对子网中的主机和路由器是透明的。这些帧到达该交换机的任何输出接口之一的速率可能暂时会超过该接口的链路层容量，为了解决这个问题，交换机的输出接口设有缓存。

##### 过滤和转发

交换机具有**过滤**和**转发**的功能，该功能借助**交换机表**完成。

交换机表包含：
- 1. 一个MAC地址
- 2. 通向该MAC地址的交换机接口
- 3. 表项放置在表中的时间

一个目的地址为DD的帧从交换机接口x到达，有3种可能的情况：
- 表中没有对于DD的表项
    - 交换机向除了接口x外的所有接口前面的输出缓存转发该帧的副本
- 表中有一个表项DD与接口x联系起来
    - 说明该帧从适配器DD的局域网网段到来，丢弃即可
- 表中有一个表项DD与接口y(y!=x)联系起来
    - 交换机将该帧转发到与接口y相连的局域网网段。
        - 通过将该帧放到接口y前的输出缓存完成转发功能

##### 自学习

交换机具有令人惊奇的特性，那就是它的表是自动的、动态的和自治地建立的，不需要人为的来配置。

这种能力的实现方式如下：
- 1. 交换机表初始为空
- 2. 对于在每个接收到的每个入帧，交换机在其表中储存
    - 该帧源地址字段中MAC地址
    - 该帧到达的接口
    - 当前时间
    - 交换机用这种方式记录发送结点所在的网段
- 3. 如果在一段时间后(称为老化期)，交换机没有接收到以该地址作为源地址的帧，就在表中删除该帧。

交换机是**即插即用设备**，因为它们不需要网络管理员或用户的干预。

##### 链路层交换机的性质

交换机的优点和性质：
- 消除碰撞
    - 在使用交换机构建的局域网中，没有因碰撞而浪费的宽带
- 异质的链路
    - 交换机将链路彼此隔离，因此局域网中的不同链路能够以不同的速率运行并且能够在不同的媒体上运行
- 易于管理

##### 交换机和路由器比较

路由器是使用网络层地址转发分组的储存转发分组交换机。尽管交换机也是一个储存转发分组交换机，但是它是使用MAC地址转发分组。交换机的第二层的分组交换机，而路由器是第三层的分组交换机。

- 交换机的优缺点
    - 即插即用
    - 相对高的分组过滤和转发速率
        - 因为交换机处理高至第二层的帧，而路由器必须出来高至第三层的帧
    - 为了防止广播帧的循环，交换网络的活跃拓扑限制为一棵生成树
    - 一个大型的交换网络将要求主机和路由器中有大的ARP表，这将生成大量的ARP流量和处理量，而且交换机对于广播风暴没有提供任何措施
- 路由器的优缺点
    - 因为网络寻址通常是分层的，即使当前网络中存在冗余路径时，分组通常也不会通过路由器循环(除非路由表配置错误)
        - 因此路由器没有生成树限制，并可以使源和目的地之间的路径最佳
    - 对第二层的广播风暴提供了防火墙保护
    - 不是即插即用，需要人为配置
    - 每个分组处理时间比交换机要更长
 
 路由器和交换机的选择：
 - 通常由几百台主机组成的小网络通常有几个局域网段。对于这些小网络，交换机足够了
    - 因为它们不要求IP地址的任何配置能够使流量局部化并增加总计吞吐量
- 对于几千台主机组成的更大网络，通常网络中(处理交换机外)还包括路由器。
    - 路由器提供更健壮的流量隔离方式和对广播风暴的控制，并在网络的主机之间使用更"智能的"路由

流行的互联设备的典型特色的比较
| -        | 集线器 | 路由器 | 交换机 |
|----------|--------|--------|--------|
| 流量隔离 | 无     | 有     | 有     |
| 即插即用 | 有     | 无     | 有     |
| 优化路由 | 无     | 有     | 无     |


#### 虚拟局域网

我们注意到现代机构的局域网常常是配置为等级结构的，每个工作组(部门)有自己的交换局域网，经过一个交换机结构与其他工作组的交换局域网互联。但是现实世界常常有不尽人意的地方：
- 缺乏流量隔离
    - 广播流量(如携带ARP和DHCP报文或那些目的地没有被自学习交换机学习到的帧)仍然必须跨越整个机构网络，限制广播的流量能改善局域网的性能
    - 为了安全/隐私的目的也希望限制局域网广播流量，如行政组的流量不希望通过工作组
- 交换机的无效使用
- 管理用户
    - 当雇员在不同组间移动，必须改变物理布线

这些问题都能通过支持**虚拟局域网(VLAN)**的交换机来处理。支持VLAN的交换机允许经一个单一的物理局域网基础设施定义多个虚拟局域网。在一个VLAN内的主机彼此通信，仿佛他们与交换机连接。

在一个基于端口的VLAN中，交换机的端口(接口)由管理员划分分组。每个分组构成VLAN，在每个VLAN中的端口形成一个广播域(即来自一个端口的广播流量仅能到达该组中的其他端口)。

VLAN解决了上面提到的所有困难，当一个组的用户想加入另一个组时，管理员只需要重新配置VLAN软件时其所在端口改变关联的分组即可。在交换机中维护一张端口到VLAN的映射表，交换机软件仅在属于相同VLAN的端口之间交付帧。

两个完全隔离的VLAN怎么彼此之间通信呢？
- 将VLAN交换机的一个端口设置为两组的公共端口
- 公共端口与一台外部路由器链接
- 当需要通信是，从一个VLAN先发到路由器，再由路由器跨越另一个分组的VLAN到达主机
    - 逻辑上仿佛是两个组具有分离的路由器连接的交换机
    
两个交换机的互连
- 法一：不具有扩展性
    - 两个交换机中，相同的组在选择一个端口连接起来
    - 交换机上具有N个VLAN则需要N个端口
- 法二：**VLAN干线练级**
    - 每台交换机上设置一个特殊的干线端口
    - 干线端口属于所有VLAN
    - 发送到任何VLAN的帧经过干线链路转发到其他交换机
    - 但这样会引发一个问题：一个交换机怎么知道到达干线端口的帧属于某个特定的VLAN呢？
        - IEEE定义了一种以太网格式——802.1Q，用于跨越干线的帧

802.1Q帧由标准以太网与加进首部的4字节**VLAN标签**组成，而VLAN标签承载这该帧所属的VLAN标识符。VLAN标签由在VLAN干线发送侧的交换机加进帧中，解析后并由VLAN干线接受侧的交换机删除。

VLAN标签自身由一个2字节的**标签协议标识符(TPID)**字段、一个2字节的标签控制信息字段和一个3比特优先权字段组成。


##### 多协议标签交换

通过采用虚电路网络领域的一个关键概念——固定长度标签，**多协议标签交换(MPLS)**改善了路由器的转发速度。其目标是：
- 对于基于固定长度标签和虚电路的技术，在不放弃基于目的地IP数据报转发的基础设施的前提下，当可能时通过选择性地标识数据报并允许路由器基于固定长度的标签(而不是目的地IP地址)转发数据报来增强其功能。

building


#### 数据中心网路

每个数据中心都有自己的**数据中心网络**，这些数据中心网络将其内部主机彼此互联并与因特网中的数据中心互联。

主机就像是数据中心的工蜂：它们负责提供内容(如网页和视频)，储存邮件和文档，并共同执行大型文件的分布式计算(如搜索引擎)。数据中心的主机称为**刀片**(blade)，主机被堆放在机架上，每个机架堆放20～40台刀片。每个机架顶部有一台交换机，这台交换机被形象的称为**机架顶部(TOR)交换机**，它们与机架上的主机互联，并与数据中心的其他交换机互联。每台主机也会分配一个自己数据中心内部的IP地址。

数据中心网络支持两种类型的流量：在外部客户与内部主机之间流动的流量和内部主机之间流动的流量。为了处理外部客户与内部主机之间流量的流动，数据中心网络包括了一台或多台**边界路由器**，它们将数据中心与公共因特网相连。数据中心因此需要将所有机架彼此互联，并将机架与边界路由器链接。


##### 负载均衡

为了支持来自外部客户的请求，每个应用都与一个公开可见的IP地址关联，外部用户向该地址发送其请求并从该地址接收响应。在数据中心内部，外部请求首先被定向到一个**负载均衡器**。负载均衡器的任务是向主机分发请求，以主机当前的负载作为函数来在主机之间均衡负载。当主机处理完成请求后向负载均衡器发送响应，再由负载均衡器发回给外部客户。

负载均衡器不仅平衡主机间的工作负载，而且还提供类似NAT的功能，将外部的IP地址转换为内部适当主机的IP地址，然后将反方向流向客户的分组按照相反的转换进行处理。这防止了客户直接接触主机，从而具有隐藏网络内部结构和防止客户直接与主机交互等安全性益处。


##### 等级体系结构

当主机规模大到一定程度之后，往往需要更精心的设计，数据中心通常应用**路由器和交换机等级结构**。在等级结构顶端，边界路由器与接入路由器相连。每台接入路由器下面有3层交换机。每台接入路由器与一台顶层交换机相连，每台顶层交换机与多台二层交换机以及一台负载均衡器相连。每台二层交换机又通过机架的TOR交换机与多个机架相连。通过这种等级式设计，可以将数据中心扩展到几十万台主机的规模。

为了提供持续的高可用性，数据中心在它们的设计中也包含了冗余网络设备和冗余链路。每台接入路由器下的这些主机构成了单一子网。为了使ARP广播流量本地化，这些子网的每个都将进一步划分为更小的VLAN子网，每个由数百太主机组成。

但是这种等级式设计存在主机容量受限的问题。如过一个子网下40台或更多主机要和另一个子网的主机在同一时间通信，那么那么这些流量将通过公共的信道(二层到接入主机的信道)，假设公共信道是10Gbps的，每台主机的链路是1Gbps的，没在公共信道处的速率只有250Mbps远远小于每个主机的速率。如果物理主机跨越了多个机架，前面描述的网络瓶颈可能会导致性能不佳。


##### 数据中心网络的发展趋势

其中一个趋势就是部署能客服传统等级设计缺陷的新型互联体系结构和网络协议。一种方法是采用**全连接拓扑**来代替交换机和路由器的等级结构。在这种设计中，每台第一层交换机都与第二层交换机相连，因此：
- 1. 主机到主机的流量绝不会超过该交换机层次
- 2. 对于n台第一层交换机，在任意两台二层交换机间有n条不相交的路径。

这种设计不仅减轻了主机到主机的容量限制，同时创建了一种更加灵活的计算和服务环境。在这种环境中，任何未连接到同一台交换机的两个机架之间的通信在逻辑上是等价的，而不论其在数据中心的位置如何。

另外一个主要的趋势就是采用基于船运集装箱的**模块化数据中心(MDC)**。每个集装箱内构建一个"迷你数据中心"并将该集装箱运送到数据中心的位置。在数据中心位置，多个集装箱彼此互联，同时也和因特网连接。


### Web页面请求的过程

假定Bob启动他的便携机，然后将其用一根以太网线缆连接到学校的以太网交换机，交换机又与学校路由器互联。学校这台路由器与一个ISP连接，本例中ISP为comcat.net。

#### 准备：DHCP、UDP、IP和以太网

当Bob首先将其便携机与网络连接时，没有IP地址他就不能做任何事情。所以Bob的便携机所采取的一个网络相关动作是运行DHCP协议，以从本地DHCP服务器获取一个IP地址以及其他信息

- 1. Bob便携机上的操作系统生成一个**DHCP请求报文**，并将这个报文放入具有目的地端口67(DHCP服务器)和源端口68(DHCP客户)的**UDP报文段**。该UDP报文段则被放置在一个具有广播IP目的地地址(255.255.255.255)和源IP地址0.0.0.0的**IP数据报**中
- 2. 包含DHCP请求报文的IP数据报则被放置在**以太网帧**中。该以太网帧具有目的的MAC地址FF:FF:FF:FF，使用该帧广播到与交换机连接的所有设备;该帧的源MAC地址是Bob便携机的MAC地址：00:16:D3:23:68:8A
- 3. 包含DHCP请求的广播以太网帧是第一个由Bob便携机发送到以太网交换机的帧。该交换机在所有的出端口广播入帧，包括连接到路由器的端口
- 4. 路由器在他具有MAC地址00:22:6B:45:1F的接口接收到该广播以太网帧，该帧包含DHCP请求，并且从该以太网帧中抽取出IP数据报。该数据报的广播IP目的地址指示了这个IP数据报应由在该结点的高层协议处理，因此该数据报的载荷(一个UDP报文段)**被分解**向上到达UDP，DHCP请求报文从此UDP报文段中抽取出来。此时DHCP服务器有了DHCP请求报文。
- 5. 我们假设运行自爱路由器中的DHCP服务器能够以**CIDR**块68.85.2.0/24分配IP地址。所以在本例中，在学校内使用的所有IP地址都在Comcast的地址中。我们假设DHCP服务器分配地址68.85.2.101给Bob的便携机。DHCP服务器生成包含这个IP地址以及DNS服务器的IP地址(68.87.71.226)、默认网关路由器IP地址(68.85.2.1)和子网块(68.85.2.0/24)的一个DHCP **ACK报文**。该DHCP报文被放入一个UDP报文段中，UDP报文段被放入IP数据报中，IP数据报再被放入一个以太网帧中。这个以太网帧的源MAC地址是路由器连到归属网络时接口的MAC地址，目的MAC地址是Bob便携机的MAC地址
- 6. 包含DHCP ACK的以太网帧由路由器发送给交换机。因为交换机是**自学习**的，并且先前从Bob便携机收到以太网帧，所以该交换机知道寻址到00:16:D3:23:68:8A的帧仅从通向Bob便携机的输出端口转发
- 7. Bob便携机接收到包含DHCP ACK的以太网帧，从该以太网帧中抽取IP数据报，从IP数据报中抽取UDP数据段，从UDP数据段中抽取DHCP ACK报文。Bob的DHCP客户则记录下它的IP地址和它的DNS服务器的IP地址。它还在其**IP转发**表中安装默认网关的地址。Bob便携机向该默认网关发送目的地址为其子网68.85.2.0/24以外的所以数据报。此时，Bob便携机已经初始化好它的网络组件，并准备开始处理Web网页获取


#### 仍在准备：DNS和ARP

当Bob将www.google.com的URL输入Web浏览器是，他开启了一长串事件，这将导致谷歌主页最终显示在其Web浏览器上。Bob的Web浏览器通过生成一个**TCP套接字**开始了该过程，套接字用于向www.google.com发送**HTTP**请求。为了生成该套接字，Bob便携机需要知道www.google.com的IP地址。使用DNS协议提供这种名字到IP地址的转换服务

- 8. Bob便携机上的操作系统因此生成一个**DNS查询报文**，将字符串www.google.com放入DNS报文的问题段中。该DNS报文则放置在一个具有53号(DNS服务器)目的端口的UDP报文段中。该UDP报文段则被放入具有IP目的地址68.87.71.226(DNS服务器地址)和源地址68.85.2.101的IP数据报中
- 9. Bob便携机则将包含DNS请求报文的数据报放入一个以太网帧中。该帧将发送(在链路层寻址)到Bob学校网络中的网关路由器。然而，即使Bob便携机经过上述第5步的DHCP ACK报文知道了学校网关路由器的IP地址，但仍不知道该网关路由器的MAC地址。为了获取该网关路由器的MAC地址，Bob便携机将需要使用**ARP协议**
- 10. Bob便携机生成一个具有目的IP地址68.85.2.1(默认网关)的**ARP查询报文**，将该ARP报文放置在一个具有广播目的地址(FF:FF:FF:FF:FF:FF)的以太网帧中，并向交换机发送该以太网帧，交换机将该帧交付该所有连接的设备，包括网关路由器
- 11. 网管路由器在通往学校网络的接口上接收到包含ARP查询报文的帧，发现在ARP报文中目标IP地址68.85.2.1匹配其接口的IP地址。网关路由器因此准备一个**ARP回答**，指示它的MAC地址00:22:6B:45:1F:1B对应IP地址68.85.2.1。它将ARP回答放入一个以太网帧中，其目的地址为Bob便携机的MAC地址，并向交换机发送该帧，再由交换机将该帧交付给Bob便携机
- 12. Bob便携机现在能够使包含DNS查询的以太网帧寻址到网关路由器的MAC地址。注意到该数据报的目的IP地址是DNS服务，但是帧具有的目的MAC地址是网管路由器。Bob便携机向交换机发送该帧，交换机将该帧交付给网关路由器


#### 仍在准备：域内路由器选择到DNS服务器

- 14. 网关路由器接收该帧并抽取包含DNS查询的IP数据报。路由器查找该数据报的目的地址，并根据其转发表决定该数据报应当发送到的路由器。
- 15. DNS服务器前的路由器接收到该帧后，抽取IP数据报，检查该数据报的目的地址，并根据其转发表确定出接口，经过该接口朝着DNS服务器转发数据报，而转发表以根据DNS服务器域内协议(如RIP、OSPF或IS-IS)以及**因特网的域间协议BGP**所填写
- 16. 最终包含DNS查询的IP数据报到达了DNS服务器。DNS服务器抽取出DNS查询报文，在它的DNS数据库中查找名字www.google.com，找到包含对应的IP地址的DNS**源记录**。这种缓存数据源于google.com的**权威DNS服务器**。该DNS服务器形成了一个包含这种主机名到IP地址映射的**DNS回答报文**，该DNS回答报文放入UDP报文段中，该报文段放入寻址到Bob便携机的IP数据报中。该数据报将通过DNS服务器网络反向转发到学校路由器，并从这里经过以太网交换机到Bob便携机
- 17. Bob便携机从DNS报文抽取出服务器www.google.com的IP地址。最终，在大量工作后，Bob便携机此时准备接触www.google.com的服务器


#### Web客户——服务器交互：TCP和HTTP

- 18. 既然Bob便携机有了www.google.com的IP地址，它能够生成**TCP套接字**，该套接字将用于想www.google.com发送**HTTP GET**报文。当Bob生成TCP套接字时，在Bob便携机中的TCP必须首先与www.google.com中的TCP执行**三次握手**。Bob便携机因此首先生成一个具有目的端口80(针对HTTP的)的**TCP SYN**报文段，将该TCP报文段放置在具有目的IP地址(www.google.com)的IP数据报中，将该数据报放置在MAC地址为网关路由器的帧中，并向交换机发送帧
- 19. 在学校网络、DNS网络和谷歌网络中的路由器朝着www.google.com转发保护TCP SYN的数据报，使用每台路由器中的转发表，如前面步骤14～16那样
- 20. 最终，包含TCP SYN的数据报到达www.google.com。从数据报抽取出TCP SYN报文并分解到与端口80相联系的欢迎套接字。对于谷歌HTTP服务器和Bob便携机之间的TCP连接生成一个连接套接字。产生一个TCP SYNACK报文段，将其放入Bob便携机选址的一个数据报中，最后放入链路层帧中，该链路将www.google.com连接到其第一跳路由器
- 21. 包含TCP SYNACK报文段的数据报通过谷歌、DNS和学校网络，最终到达Bob的便携机的以太网卡。数据报在操作系统中分解到步骤18生成的TCP套接字，从而进入连接状态
- 22. 借助与Bob便携机上的套接字，现在准备向www.google.com发送字节了，Bob的浏览器生成包含要获取的URL的HTTP GET报文。HTTP GET报文则写入套接字，其中GET报文成为TCP报文段的载荷。在TCP报文段放置进一个数据报中，并交付到www.google.com
- 23. 在www.google.com的HTTP服务器从TCP套接字读取HTTP GET报文，生成一个**HTTP响应**报文，将请求的Web页内容放入HTTP响应体中，并将报文发送进TCP套接字
- 24. 包含HTTP回答报文的数据报通过谷歌、DNS和校园网转发，到达Bob便携机。Bob的Web浏览器程序从套接字读取HTTP响应，从HTTP响应体中抽取Web网页的html，最终显示网页


---


## 无线网路和移动网络

我们在无线网络中能指出下列要素
- 无线主机
- 无线链路
    - 主机通过无线链路连接到一个基站或者另一台无线主机
    - 不同的无线链路技术具有不同的传输速度和能够传输不同的距离
- 基站
    - 基站是无线网络基础设施的一个关键部分
    - 它负责向与之关联的无线主机发送数据和从主机哪里接收数据
    - 基站通常负责协调与之相关联的多个无线主机的传输
    - 所谓相关联指
        - 主机位于该基站的无线通信覆盖范围内
        - 该主机使用该基站中继它和更大网络之间的数据

与基站相关联的主机通常称为以**基础设施模式**运行，因为所有传统的网络服务都由网络向通过基站相连的主机提供。在**自组织网络**中，无线主机没有这样的基础设施与之相连。在没有这样的基础设施的情况下，主机本身必须提供诸如路由选择、地址分配等服务。

我们可以根据两个准则对无线网络分类：1. 在该无线网络中的分组是否跨越了一个无线跳或多个无线跳;2. 网路中是否有诸如基站这样的记住设施
- 单跳，基于基础设施。
    - 这些网络具有与较大的网络连接的基站
    - 该基站与无线主机之间的所有通信都经过一个无线跳
    - 如3G蜂窝网络
- 单跳，无基础设施
    - 不存在与网络连接的基站
    - 这种单跳网络中欧给你的一个结点可以协调其他节点的传输
    - 如蓝牙
- 多跳，基于基础设施
    - 基站表现为以有线方式与较大网络相连
    - 某种无线结点为了经该基站通信，可能不得不通过其他无线结点中继它们的通信
    - 如某些无线感应网络和所谓的**无线网状网络**
- 多跳，无基础设施
    - 没有基站，并且节点为了到达目的地可能需寻在几个其他无线结点之间中继报文
    - 这些结点也可能是移动的，多个结点中改变连接关系，一类网络被称为**移动自组织网络(MANET)**


### 无线链路和网络特征

无线链路与有线链路的重要区别
- 递减的信号强度
- 来自其他源的干扰
    - 在同一个频段发送信号的电磁波将互相干扰
- 多路径传播
    - 电磁波的一部分受物体和地面反射，在发送方和接收方之间走了不同长度的路径，则会出现多经传播
        - 使得接收方收到的信号变得模糊

这表明，无线链路中的比特差错将比有线链路中常见。因此，无线链路协议不仅采用有效的CRC错误检测码，还采用里链路层的ARQ协议来重传

**信噪比(SNR)**是所收到的信号和噪声强度的相对测量，单位通常是分贝(dB)，较大的信噪比使接收方更容易从背景噪音中提取传输的信号

物理层的几种特征
- 对于给定的调制方案，SNR越高，BER(差错率)越低
- 对于给定的SNR，具有较高比特传输速率的调制技术将具有较高的BER
- 物理层调制技术的动态选择能用于适配对信息条件的调制技术

有线无线不单单仅有误比特率这一项，还存在所谓的**隐藏终端问题**
- 一种的环境妨碍了几个发送方的通信，使得无法检测到碰撞
- 第二种是由于信号强度衰弱，使得信号强度不足以使发送方检测到对方的传输，但是足以在接收方处互相干扰


#### CDMA

**多码分址(CDMA)** 属于信道划分协议一族，可以保证多个发送方的信号不在接收方互相干扰。在CDMA协议中，要发送的每个比特都通过乘以一个信号(编码)的比特来进行编码，这个信号的变化速率(通常称为**码片速率**)比初始比特序列的变化速率快得多。

设$d_i$为第i个比特时隙中数据的比特值。为了数学上便利，我们把有0值的数据比特表示为-1。每个比特时隙又能进一步细分为M个微时隙(这就是上面说的快得多的原因)。设发送方使用的CDMA编码由M个值的序列$c_m$组成，m=1,...,m，每个值取+1或-1。

那么CDMA编码器的输出$Z_{i,m}$是$d_i$乘以分配的CDMA编码的第m个比特$c_m$:
$$Z_{i,m} = d_i \times c_m$$

接收方收到编码的比特$Z_{i,m}$，并恢复初始的数据比特$d_i$，如下：
$$d_i = \frac1M \sum_{m=1}^M{Z_{i,m} \times c_m}$$

例如：初始比特为[1, -1]，CDMA编码为[1, 1, 1, -1, 1, -1, -1, -1],那么得到的Z为[(1, 1, 1, -1, 1, -1, -1, -1), (-1, -1, -1, 1, -1, 1, 1, 1)]

恢复过程：$d_1 = \frac18 \sum_{m=1}^8 {Z_{1,m} \times c_m}$ = 1, d2同理


但是实际情况并非这么理想，CDMA必然是存在于有干扰的环境中的。当发送方的数据比特与其他发送方的比特混在一起时，接收方如何恢复呢？

CDMA的工作有一种假设，即对干扰的传输比特信号的加性的，这意味着，例如在同一个微时隙中，如果3个发送方发送1，一个发送-1，那么对于接收这个微时隙的所有接收方收到的信号都是2。所以对于N个发送发s，接收方收到的值是所有N个发送方传输比特的总和：
$$Z_{i,m} = \sum_{s=1}^N Z_{i,m}^s$$

令人吃惊的是，如果仔细地选择发送方的编码，每个接收方通过上述方式就能从聚合的信号中恢复一个给定发送方的数据：
$$d_i = \frac1M \sum_{m=1}^M{Z_{i,m} \times c_m}$$


- 为了使CDMA接收方能够提取一个特定的发送方的信号，必须仔细选择CDMA编码。
- 我们的讨论假设在接收方收到的来自不同发送方的信号强度的相同的


### WIFI——IEEE802.11 无线LAN

#### 802.11体系结构

802.11体系结构的基本构件模块是 **基本服务集(BBS)** 。一个BBS包含一个或多个站点和一个在802.11术语中称为 **接入点(AP)** 的中央基站

与以太网设备类似，每个802.11无线站点都具有一个6字节的MAC地址，该地址存储在该站的适配器(网络接口卡)的固件中。每个AP的无线接口也具有一个MAC地址。这些MAC地址有IEEE管理。

配置AP的无线LAN经常被称作 **基础设施无线LAN** ，其中"基础设施"是指AP连同互联AP和一台路由器的有线以太网。


##### 信道与关联

在802.11中，每个无线站点在能够发送或者接收网络层数据之前，必须与一个AP相关联。在网络管理员安装一个AP时，管理员为该接入点分配一个单字或双字的 **服务集标识(SSID)** 。管理员还必须为该AP分配一个信道号。

**WIFI丛林** 是任意一个物理位置，在这里无线站点能从两个或多个AP中收到很强的信号。

设在一个WIFI丛林中有5个AP，为了获取因特网接入，你的无线站点需要加入其中一个子网并因此需要与其中一个AP相 **关联** 。关联意味着这一无线站点在自身和该AP之间创建一个虚拟线路。仅有关联的AP才能向你的无线站点发生数据帧，并且你的无线站点也仅仅通过该关联AP向因特网发送数据帧。

- 如何如某个特定的AP相关联
    - 802.11标准要求每个AP周期性的发送 **信标帧** ，每个信标帧包括该AP的SSID和MAC地址。
    - 你的无线站点为了得知正在发送信标帧的AP，扫描所有信道，找出来自可能位于该区域的AP所发送的信标帧(一些AP可能在相同的信道中传输，即这里有一个丛林)
    - 通过信标帧了解到可用AP后，你的无线主机选择一个AP用于关联

扫描信道和监听信标帧的过程称为 **被动扫描** 。无线主机也能执行 **主动扫描** ，这是通过向位于主机范围内的所有的AP广播探测帧完成的。
- 被动扫描
    - 自AP发送信标帧
    - 无线主机向选择的AP发送关联请求帧
    - 选择的AP向无线主机发送关联响应帧
- 主动扫描
    - 自无线主机广播探测请求帧
    - 自AP发送探测响应
    - 无线主机向选择的AP发送关联请求帧
    - 选择的AP向无线主机发送关联响应帧

一旦与一个AP关联，该主机通常希望加入该AP的所属子网，该主机通常通过关联的AP向该子网发送一个DHCP发现报文，以获取在该AP子网中的一个IP地址。一旦获得地址就成功加入了子网。

为了与特定的AP创建一个关联，某无线站点可能向该AP鉴定自身。802.11无线LAN提供了几种不同的鉴别和接入方式
- 第一种方式是基于一个站点的MAC地址允许其接入以为无线网络
- 第二种方式是应用用户名和口令


#### 802.11MAC协议

许多站点可能希望同时经相同的信道传输数据帧，因此需要一个多路访问协议来协调传输。类似有线网络，也可宽泛的将访问协议分为三类：信道划分、随机访问和轮流。而802.11使用的是一种随机访问协议，称为 **带碰撞避免的CSMA(CSMA/CA)** 。

不同于CSMA/CD，CDMA/CA使用的是避免而非碰撞检测;其次因为无线信道误比特率较高，802.11使用链路层确认/重传(ARQ)方案。

与802.3以太网不同，802.11MAC协议并未实现碰撞检测。主要由两个原因所致
- 碰撞检测要求站点具有同时发送(站点到自己的信号)和接收(检测其他站点是否也发送)的能力。因为在802.11适配器上，接收信号的强度通常远远小于发送信号的强度，制造具有碰撞检测能力的硬件代价较大
- 更重要的是，即使适配器同时具有发送和监听信号的能力，适配器也会由于隐藏终端问题和衰减问题而无法检测所有的碰撞

802.11的 **链路层确认** 方案：
- 目的站点收到一个通过CRC校验的帧后，它等待一个被称作 **短帧间间隔(SIFS)** 的小段时间，然后发回一个确认帧
- 如果发送站点在给定时间内没有收到确认帧，它假定出现了错误并重传该帧，使用CSMA/CA协议访问该信道
- 在若干次重传后仍未收到确认，发送站点将放弃发送并丢弃该帧


##### CSMA/CA协议

假设一个站点有一个帧要发送
- 1. 如果初始时某站点监听到信道空闲，它将在一个被称作 **分布式帧间间隔(DIFS)** 的短时间段后发送该帧
- 2. 否则，该站点选取一个随机回退值并且在侦听到信道空闲时递减该值，当信道侦听到信道忙时，计数值保持不变
    - 之所以不再空闲后立马发送是因为，不同于以太网的CSMA/CD，CSMA/CA没有碰撞检查，一旦碰撞，遭受碰撞的帧仍将被完全传输，因此802.11的目的是避免碰撞
    - 当然碰撞还是可能发生
- 3. 当计数值减为0时(只可能发生在信道空闲时)，该站点发送整个数据帧并等待确认
- 4. 如果收到确认，则发送站知道它的帧以被目的站正确接收。如果该站要发送另一个帧，它将从第二步开始CSMA/CA协议。如果未收到确认，发送站点将重新进入第二步的回退阶段，并从一个更大的范围内取随机值


##### 处理隐藏终端问题：RTS和CTS

前面讲过，两台主机信号不足以互相通信，但足以在AP处互相干扰，那两者是彼此隐藏的，从而碰撞导致整个发送阶段信道浪费。

为避免这一问题，802.11协议允许站点使用一个短 **请求发送(RTS)** 控制帧和一个短 **允许发送(CTS)** 控制帧来预约信道的访问。当发送方要发送一个DATA帧时，它首先向AP发送一个RTS帧，指示传输DATA帧和确认(ACK)帧需要的总时间。当AP收下RTS后，它广播一个CTS帧作为响应。该CTS帧有两个目的：给发送方明确的发送许可，也指示其他站点在预约期内不要发送。

RTS和CTS帧的使用能够在两个重要方面提升性能：
- 隐藏终端问题被缓解了，因为长DATA帧只能在信道预约后才能被传输
- 因为RTS和CTS帧较短，涉及RTS和CTS帧的碰撞将仅持续短RTS和CTS帧的持续期。一旦RTS和CTS帧被正确传输，后续的DATA和ACK帧应当能无碰撞发送

尽管RTS和CTS交换有助于降低碰撞，但它同样引入了时延以及消耗了信道资源。因此，RTS/CTS交换仅仅用于为长数据帧预约信道。实际中，每个无线站点可以设置一个RTS门限值，仅当帧长超过门限值时才使用RTS/CTS序列。


#### IEEE 802.11帧

| 帧         | 帧控制 | 持续期 | 地址1 | 地址2 | 地址3 | 序号控制 | 地址4 | 有效载荷 | CRC |
|------------|--------|--------|-------|-------|-------|----------|-------|----------|-----|
| 帧长(字节) | 2      | 2      | 6     | 6     | 6     | 2        | 6     | 0~2312   | 4   |

帧控制又包含
| 帧         | 协议版本 | 类型 | 子类型 | 到AP | 从AP | 更过标识 | 重试 | 功率管理 | 更多数据 | WEP | Rsvd |
|------------|----------|------|--------|------|------|----------|------|----------|----------|-----|------|
| 帧长(比特) | 2        | 2    | 4      | 1    | 1    | 1        | 1    | 1        | 1        | 1   | 1    |


##### 有效载荷和CRC字段

帧的核心是有效自爱和，它通常是由一个IP数据报或者ARP分组组成。有效载荷通常小于1500字节，放置一个IP数据报或者一个ARP分组。CRC字段可以检测收到帧中的比特错误。


##### 地址字段

每个地址都是6字节的MAC地址，但为什么会有4个地址呢？事实表明，出于互联目的需要3个地址字段，特别是将网络层数据从一个无线站点通过一个AP送到一台路由器接口。当AP在自组织模式中互相转发时使用第四个地址。

802.11标准定义如下：
- 地址2是传输该帧的站点的MAC地址
- 地址1是要接收该帧的无线站点的MAC地址
- 地址3是个路由器接口的MAC地址
    - 因为AP是链路层设备，它不认识IP地址，但路由器并不知道它和目标主机之间有一个AP，所以在无线的链路层设备中传输时，要记录网络层设备的MAC地址，以此来寻址到网络层设备
    - 路由器知道主机的IP地址(从数据报的目的地址中得到)，它使用ARP来确定主机的MAC地址，这与在普通的以太网LAN中相同
    - 当以太网帧到达AP后，该AP再将其传输到无线信道前，先将该以太网帧转化为802.11帧。AP将地址1和地址2分别填上目的在主机的MAC地址。对于地址3，AP插入路由器接口的MAC地址。通过这一方式，主机可以确定将数据发送到子网中路由器接口的MAC地址


##### 序号、持续期和帧控制字段

因为确认帧可能丢失，发送站点可能会发送一个给定的帧的多个副本。使用序号可以是接收方区分新传输的帧和以前帧的重传。

前面讲过802.11协议允许传输结点预约信道一段时间，包括传输其数据帧的时间和传输确认的时间。这个持续期值被包括在该帧的持续期字段中。

帧控制包含很多子字段，一下是比较重要的子字段：
- 类型和子类型字段用于关联、RTS、CTS、ACK和数据帧
- To(到)和From(从)字段用于定义不同地址字段的含义
- WEP字段指示了是否使用加密


##### 在相同的IP子网中的移动性

为了增加无线LAN的物理范围，公司或大学经常会在同一个IP子网中部署多个BSS(基本服务集)。这自然就引出了多个BSS之间的移动性问题，即无线站点如何在维持进行中的TCP会话的情况下，无缝的从一个BSS移动到另一个BSS？

连接两个BSS的互联设备不是一台路由器时，说明两个BSS中所有的站点都属于一个IP子网。因此移动时可以保持自己的IP地址和所有正在进行的TCP连接。

如果连接两个BSS的互联设备是一台路由器，则主机必须在它移动进入的子网中获得一个新地址，但这样的地址变化会打断TCP连接。当H1(Host1)从BSS1移动到BSS2时，随着H1逐步远离BSS1，来自BSS1的信号会逐渐减弱并重新扫描更强的信号。当H1收到来自H2的信号后，接触与BSS1的关联，并与BSS2关联。


#### 802.11中的高级特色

厂商可使用他们自己的方法实现这些能力，这也许能让他们增强竞争力

##### 802.11速率适应

不同的调制技术(提供不同的传输速率)适合于不同的SNR(信噪比)情况。在高信噪比的情况下，使用可提供高速传输速率的物理层调制技术进行通信能够维持低BER(差错率)。

因此802.11实现一种速率自适应能力，该能力能适当的根据当前和近期的信道特点来选择下面的物理层调制技术。
- 如果一个节点连续发送两个帧而都没有收到确认帧
    - 该传输速率降低到前一个较低的速率
- 如果10个帧连续得到确认，或如果用来跟踪自上次降速以来时间的定时器超时
    - 该传输速率提升到上一个较高的速率


##### 功率管理

功率是移动设备的宝贵资源，因此802.11提供了功率管理能力，以使"打开"电路的时间最小化。

通过将802.11帧首部的功率管理功能比特设置为1,某结点向AP指示它打将打算休眠。设置结点中的一个定时器，使得正好在AP计划发送它信标帧前唤醒结点(前面讲过AP通常每100ms发送一个信标帧)。因为AP知道了哪个结点打算休眠，所以该AP知道它不应该向这个结点发送任何帧，先缓存目的地为休眠主机的任何帧，待以后发送。

在AP发送信标帧前，恰好唤醒结点，并迅速进入全面活动状态(约250us)。由AP发送的信标帧包含了帧被缓存在AP中的结点列表。如果没有缓存的帧，则结点返回休眠状态。否则，该结点能够通过向AP发送一个探询报文明确地请求发送缓存的帧。


#### 802.11以外的标准：蓝牙和ZigBee

其他两个IEEE802协议：蓝牙和ZigBee(定义在IEEE802.15.1和802.15.5标准中)，以及WiMAX(定义在IEEE802.16标准中)，它们分别用于短距离和长距离通信的标准。


##### 蓝牙

IEEE802.15.1网络以小范围、低功率和低成本运行。它本质上是一个低功耗、小范围、低速率的"电缆代替"技术，而802.11是一个大功率、中范围、高速率的"接入"技术。

802.15.1是自组织网络：不需要网络基础设施来互连802.15.1设备。802.15.1设备首先组成一个多达8个活动设备的 **皮可网(piconet)** 。这些设备之一被指定为主设备，其余充当从设备。主结点真正可控皮可网，而从设备进当主设备在前一时隙与其通信后才可以发送，并且只能发送给主设备。除了从设备，网络中还有多达255个的寄放(parked)设备。这些设备仅当其状态被主结点从寄放转换为活动之后才可以进行通信。


##### ZigBee

IEEE的第二个个人区域网络标准是802.14.5，称为ZigBee。ZigBee较之蓝牙仍是以低功率、低数据率、低工作周期应用为目标。适用于如家庭温控和光线传感等。

ZigBee网络中的结点具有两个特色。多个所谓"简化功能设备"在单个"全功能设备"控制下作为从设备运行，类似蓝牙的从设备。一个全功能设备能够作为一个主设备运行，并且多个全功能设备还能够配置成一个网状(mesh)网络，其中全功能设备在它们之间发送帧。


### 蜂窝因特网接入

WiFi范围有限要想全球实现无线网络很自然的策略就是扩展蜂窝网络，使它们不仅支持语音电话，同时也支持无线因特网接入。


#### 蜂窝网络体系结构的概述

大多数蜂窝用户使用GSM(全球移动通信系统)。

##### 2G蜂窝网络体系结构：与电话网的语音连接

蜂窝(cellular)是指这样的事实，即由一个蜂窝覆盖的区域被分成许多称作小区(cell)的地理覆盖区域。GSM有自己的特殊命名法。每个小区包含一个 **收发基站(BTS)** ，负责向位于其小区内的移动站点发送或接收信号。一个小区的覆盖区域取决于很多因素，包括BTS的发射速率、用户设备的传输速率、小区中的障碍建筑以及基站天线的高度。多数系统将BTS放置在3个小区的交叉处，使得具有有向天线的单个BTS能够为三个小区提供服务。

2G蜂窝系统的GSM标准对空中接口使用了组合的FDM/TDM(无线电)。在组合的FDM/TDM系统中，信道被划分为若干频率子带;对于每个子带，时间又被划分为帧和时隙。因此，对于一个组合的FDM/TDM系统，如果信道被划分为F个子带，并且时间被划分为T个时隙，那么该信道能够支持F×T个并发的呼叫。

一个GSM网络的 **基站控制器(BSC)** 通常服务于几十个收发基站。BSC负责的是为移动用户划分BTS无线信道，执行 **寻呼(paging)** ，执行用户的切换。基站控制器及其控制的收发基站共同构成了 **GSM基站系统(BSS)** 。

在用户鉴别和帐户管理以及呼叫建立和切换中， **移动交换中心(MSC)** 起着决定性作用。单个MSC通常将包含多达5个BSC，因此每个MSC有大约200 000个用户。一个蜂窝提供商的网络将有若干个MSC，使用称为网关MSC的特殊MSC将提供蜂窝网络与更大公共电话网络相连。


#### 3G蜂窝数据网络：将因特网扩展到蜂窝用户

没有单一的官方机构对2.5G、3G、3.5G技术设立要求，以下我们关注由第三代合作伙伴项目(3GPP)研发的通用移动通信服务(UMTS)3G标准。

##### 3G核心网

3G核心蜂窝数据网将无线电接入网连接到公共因特网。3G设计者们采用的方法非常清楚：不去触动现有核心GSM蜂窝语音网，增加与现有蜂窝语音网平行的附加蜂窝数据功能。

3G核心网中有两类结点： **服务通用分组无线服务支持结点(SGSN)** 和 **网关GPRS支持结点(GGSN)** 。一个SGSN负责向位于其连接的无线电接入网络中的移动结点交付数据报。SGSN与该区域蜂窝语音网的MSC进行交互，提供用户认证和切换，维护活跃移动结点的位置信息，执行位于无线接入网中的移动结点和GGSN之间的数据转发。GGSN起到网关的作用，将多个SGSN连接到更大的因特网。GGSN因此是源于移动结点的一个数据报在进入更大因特网之前遇到的3G基础设施的最后一部分。


##### 3G无线电接入网：无线边缘

3G无线电接入网是我们作为3G用户看到的无线第一跳网络。 **无线电网络控制器(RNC)** 通常控制几个小区的收发基站，类似于2G网络中的基站。每个小区的无线链路运行在移动结点和收发基站之间。RNC通过MSC与电路交换蜂窝语音网络连接，有通过SGSN与分组交换的因特网连接。因此，尽管3G蜂窝语音服务和蜂窝数据服务使用不同的核心网，但他们共享一个相同的第一/最后一跳无线电接入网。


### 移动管理：原理

在一个网络环境中，一个移动结点的永久居所被称为 **归属网络(home network)** ，在归属网络中代表移动结点执移动管理功能的实体称为 **归属代理(home agent)** 。移动结点当前所在网络叫做 **外部网络(foreign network)** 或 **被访问网络(visited network)** ，在外部网络中帮助结点做移动管理功能的实体称为 **外部代理(foreign agent)** 。一个 **通信者(correspondent)** 就是希望与该移动结点通信的实体。


#### 寻址

为了使用户移动性对网络应用透明，希望一个移动结点从一个网络移动到另一个网络时保持其地址不变。

外部网络可用的一种方法是向所有其他网络发送通告，告诉他们该移动结点正在它的网络中。当移动结点离开一个外部网络后又加入另一个外部网路时，新的外部网络会通告一条新的通向该移动结点的路由，就的外部网络将撤销其与该移动结点有关的路由选择信息。

然而这种方法有个很大的缺点，即扩展性不好。如果移动性管理是网络路由器的责任的话，则路由器必须维护可能多达数百万个移动结点的转发表表项。

一种替代的方法(也是实际使用的方法)是将移动性功能从网络核心搬到网络边缘。一种自然的做法就是由该结点的归属网络来实现。移动结点的归属网络中的归属代理也能跟踪该移动结点所在的外部网络。这当然需要一个移动结点(或一个代表该结点的外部代理)与归属代理之间的协议来更新结点位置。

外部代理的作用之一就是为移动结点创建一个所谓的 **转交地址(Care-Of Address, COA)** ，该COA的网络部分与外部网络的网络部分相匹配。因此一个移动结点可与两个地址相关联，即其 **永久地址** 与其 COA，该COA有时又称为 **外部地址** 。外部代理的第二个作用就是告诉归属代理，该结点在它的(外部网络的)网络中具有给定的COA，该COA将用于将数据报通过外部代理"重新路由选择"到移动结点。

某移动结点可在外部网络中得到一个COA(使用DHCP之类的协议)，且由它自己把其COA通告给归属网络。


#### 路由选择到移动结点

数据报应怎样寻址并转发给移动结点呢？目前有两种不同的方法：间接路由选择与直接路由选择。


##### 移动结点的间接路由选择

在 **间接路由选择** 方法中，移动性对于通信者来说是完全透明的。

归属代理除了负责与外部代理交互以跟踪移动结点的COA外，还有一个很重要的功能。它的第二项工作就是监视到达的数据报，这些数据报寻址的结点的归属网络与该归属网络相同，但这些结点当前却在某个外部网络中。归属代理截获这些数据报，然后按一个两步骤的过程转发它们。通过使用移动结点的COA，该数据报先转发给外部代理，然后再从外部代理转发给移动结点。

让归属代理将通信者的原始完整数据报 **封装** 在一个新的(较大的)数据报中。这个较大的数据报被导向并交付到移动结点的COA。"拥有"该COA的外部代理将接收并拆封该数据报，提取原始数据，然后再向移动结点转发该原始数据报。

小结一下支持移动性所需的网络层新功能:
- 移动结点到外部代理的协议
    - 当移动结点连接到外部网络是，它向外部代理注册，离开外部网络时取消注册
- 外部代理到归属代理的注册协议
    - 外部代理将向归属代理注册移动结点的COA，当移动到一个新网络时，注册新的COA并注销旧的
- 归属代理数据报封装协议
    - 将通信者的原始数据报封装在一个目的地址为COA的数据报内，并转发之
- 外部代理拆封协议
    - 从封装好的数据报中取出通信者的原始数据报，然后再将该原始数据报转发给移动结点


##### 移动结点的直接路由选择

间接路由选择方法存在一个低效的问题，即 **三角路由选择问题** 。即在通信者和移动结点之间存在着一条更有效的路由，发往移动结点仍是先发给归属代理，然后再发生给外部网络。

**直接路由选择** 克服了三角路由选择的低效问题，但却是增加复杂性为代价的。在直接路由选择方法中，通信者所在网络中的一个 **通信者代理** 先知道该移动结点的COA。这可以通过让通信者代理向归属代理询问得知，这里假设与间接路由选择情况类似，移动结点具有一个归属代理注册过的最新COA。

但它引入了两个重要的其他挑战：
- 需要一个移动用户定位协议，以便通信者代理向归属代理查询获得移动结点的COA
- 当移动结点移动到另一个外部网络时，如何将数据报转发到新的外部网络？
    - 一种方案是创建一个新的协议来告知通信者变化后的COA
    - 另一种方案也是在GSM网络实践中采取的方案，工作方式如下：
        - 将首次发现移动结点的外部网络中的外部代理标识为 **锚外部代理** 。当移动结点到达一个新的外部网络后，移动结点向新的外部网络注册，并且新外部代理向锚外部代理提供移动结点的新COA。当锚外部代理收到一个发往已经离开的移动结点的封装数据报后，它可以使用新的COA重新封装数据报并将其转发给该移动结点。如果移动结点又移动到另外一个外部网络中，在该被访问的外部代理将与锚外部代理联系，以便建立到新外部网络的转发


### 移动IP

支持移动性的因特网体系结构与协议合起来称为移动IP。移动IP体系结构包含了许多我们考虑过的要素，包括归属代理、外部代理、转交地址和封装/拆封等概念。

移动IP标准由三部分组成：
- 代理发现
    - 移动IP定义了一个归属代理或外部代理用来向移动结点通告其服务的协议，以及移动结点请求一个外部代理或归属代理的服务所使用的协议
- 向归属代理注册
    - 移动IP定义了移动结点和外部代理向一个移动结点的归属代理注册或注销COA所使用的协议
- 数据报的间接路由选择


#### 代理发现

通过一个新的网络地址，才使移动结点中的网络层知道它已进入一个新的外部网络，这个过程被称为 **代理发现** 。代理发现可以通过两种方法实现：经代理通告或者经代理请求。

借助 **代理i通告** ，外部代理或归属代理使用一种现有路由器发现协议的扩展协议来通告其他服务。该代理周期性地在所有连接的链路上广播一个类型字段为9(路由器发现)的ICMP报文。路由器发现报文也包含路由器(该代理)的IP地址，因此允许一个移动结点知道代理的IP地址。路由器发现报文好包括了一个移动性代理通告扩展，其中包含了该移动结点所需的附加信息。

这种扩展中有如下一些比较重要的字段：
- 归属代理比特(H)
    - 指出代理是它所在网络的一个归属代理
- 外部代理比特(F)
    - 指出代理是它所在网络的一个外部代理
- 注册要求比特(R)
    - 指出在该网络中的某个移动用户必须向某个外部代理注册
- M、G封装比特
    - 指出除了"IP中的IP"(IP-in-IP)封装形式外，是否还要用其他的封装形式
- 转交地址(COA)
    - 由外部网络提供的一个或多个转交地址的列表

使用 **代理请求** ，一个想知道代理的移动结点不必等待接收代理通告，就能广播一个代理请求，该报文只是一个类型值为10的ICMP报文。收到该请求的代理将直接向该移动结点单播一个代理通告，于是该移动结点将继续处理，就好像刚收到一个未经请求的通告一样。


#### 向归属代理注册

一旦某个移动IP结点收到一个COA，则该地址必须要向归属代理注册。这可通过外部代理(由它向归属代理注册COA)或直接通过移动IP结点自己来完成。对于通过外部代理完成，一共涉及4个步骤：
- 1. 当收到一个外部代理通告后，一个移动结点立即向外部代理发送一个移动IP注册报文
    - 注册报文承载在一个UDP数据报中并通过端口434发送
    - 注册报文包含：一个外部代理通告的COA、归属代理的地址(HA)、移动结点的永久地址(MA)、请求的注册寿命和一个64比特的注册标识
        - 请求的注册寿命指示了注册的秒数。如果注册没有在规定的时间内在归属代理上更新，则注册将变得无效
        - 注册标识就像一个序列号，用于收到的注册回答与注册请求的匹配
- 2. 外部代理收到注册报文并记录移动结点的永久IP地址
    - 外部代理知道现在它应该查找这样的数据报，即它封装的数据报的目的地址与该结点的永久地址匹配
    - 外部代理然后向归属代理434端口发送一个移动IP注册报文
- 3. 归属代理接受注册请求并检查真实性和正确性
    - 归属代理把移动结点的永久IP地址与COA绑定在一起
    - 以后，到达该归属代理的数据报与发往移动结点的数据报将被封装并一隧道方式给COA
- 4. 外部代理接收注册响应，然后将其转发给移动结点

当某个结点离开其网络时，外部代理无需显式地取消某个COA注册。因为结点移动到一个新的网络并注册一个新COA时，上述情况自动发生。


### 蜂窝网络中的移动性管理

以GSM蜂窝网络体系结构作为案例

与移动IP类似，GSM采用了一直间接地路由选择方法，首先将通信者的呼叫路由选择到移动结点的归属网路，在从那到达被访问网络。移动用户的归属网络被称作该移动用户的 **归属公共地域移动网络(home Public Land Mobile Network)** 。我们直接称之为归属网络。

移动用户向某个蜂窝网提供商订购了服务，该蜂窝网就成为了这些客户的归属网络。被访问的PLMN，我们直接称之为被访问网络，是移动用户当前所在网络。

与移动IP中情况类似，归属网络和被访问网络的职责有很大区别：
- 归属网络维护一个称作 **归属位置注册器(HLR)** 的数据库，其中包括它每个用户的永久蜂窝电话以及用户个人概要信息，也包括这些用户的位置信息。
    - 当一个呼叫定位到一个移动用户后，通信者将与归属网络中一个被称作 **网关移动服务交换中心(GMSC)** 的特殊交换机联系
- 被访网络维护一个称作 **访问者位置注册(VLR)** 的数据库
    - VLR为每个当前在其服务网络中的移动用户包含一个表项，VLR表项因此随着移动用户进入和离开网络而出现或消失
    - VLR通常与移动交换中心(MSC)在一起，该中心协调到达后离开被访网络的呼叫建立


#### 对移动用户呼叫的路由选择

一个呼叫如何定位到被访问网络中的一个移动GSM用户？考虑如下步骤：
- 1. 通信者拨打移动用户的电话号码
    - 该号码本身不涉及一个特定的电话线路或位置，号码中的前几位数字足以全局地判别移动用户的归属网络
    - 呼叫从通信者通过公共交换电话网到达移动用户归属网络中的归属MSC
- 2. 归属MSC收到呼叫并查询HLR来确定移动用户的位置
    - 在最简单情况下，HLR返回 **移动站点漫游号码(MSRN)** ，我们称其为漫游号码
    - 移动用户的永久号码与移动用户的归属网络相关联，而漫游号码是短暂的：当移动用户进入被访问网络后，会给移动用户临时分配一个漫游号码
    - 漫游号码的作用就相当于移动IP中交换地址的作用，与COA类似，对通信者和移动用户是透明的
- 3. 给定一个漫游号码，归属MSC通过网络到达被访问网络的MSC建立呼叫的第二步
    - 至此，呼叫完成，从通信者到达归属MSC，在从归属MSC到达被访问MSC，然后到达移动用户提供服务的基站

那么HLR是如何获得有关移动用户位置的信息的？

当有一个移动电话切换或进入一个新的VLR所覆盖的被访问网络中以后，移动用户必须向被访问网络注册，这是通过在移动用户和VLR之间交换信令报文来实现的。被访问VLR随后向移动用户的HLR发送一个位置更新请求报文。这一报文告知HLR可以用来联系移动用户的漫游号码，或者VLR地址。作为这个交换的一部分，VLR同样从HLR那里获取移动用户的信息，以及确定被访问网络应该给予用户什么样的服务。


#### GSM中的切换

有几种原因导致切换的发生：
- 当前基站和移动用户之间的信号减弱，使得该呼叫有被中断的危险
- 一个蜂窝处理的呼叫太多，变得过载
    - 通过将一些用户切换到邻近不太拥挤的蜂窝中，使得这个拥塞得到缓解

一个基站决定切换一个移动用户时所包括的步骤：
- 1. 旧基站(BS)通知被访问的MSC即将要进行一次切换，通知移动用户将要切换到的BS
- 2. 被访问MSC发起建立新BS的路径，分配承载重路由选择的呼叫所需的资源，以及用信令告知新BS一个切换即将出现
- 3. 新BS分配并激活一个无线信道提供移动用户使用
- 4. 新BS发出信令返回被访问MSC和旧BS，即已经建立了被访问MSC到新BS的路径并且移动用户应当被告知即将发生的切换。新BS提供移动用户与新的BS想关联所需要的所有信息
- 5. 移动用户被告知它应当进行一个切换
- 6. 移动用户和新BS交换一个或多个报文，一完全激活新BS中的信道
- 7. 移动用户向新BS发送一个切换完成报文，该报文随后向上转发给被访问MSC。该被访问MSC然后重路由选择到移动用户正在进行的呼叫，使其经过新BS
- 8. 沿着到旧BS的路径分配资源随后释放

考虑如下情况：当移动用户移动到一个不同于旧BS的，与不同的MSC相关联的BS中时，并且当这种MSC之间的切换发生多次是，将发生什么。

GSM定义了 **锚MSC** 的概念。锚MSC是呼叫首次开始时候用户所访问的MSC，它因此在整个呼叫持续过程中保持不变。在整个呼叫持续时间，不论移动用户进行了多少次MSC切换。当移动用户从一个MSC覆盖区到达另一个MSC覆盖区后，正在进行的呼叫被重新路由选择，从锚MSC到包含新基站的被访问MSC。因此在任何情况下，通信者和移动用户之间至多有3个MSC(归属MSC、锚MSC、被访问MSC)。

另一种方法不用维持从锚MSC到当前MSC的单一MSC跳。将直接链接移动用户访问的MSC。每当用户到达一个新的MSC后，让旧MSC将正在进行的呼叫转发给新MSC


### 无线和移动性：对高层协议的影响

在移动用户的情况下，丢失可能源于网络拥塞(路由器溢出)或者切换。发送方并不知道报文段是由于拥塞，或在切换过程中还是由于检测到比特差错而被丢弃的。在任何情况下，发送方都是重传报文段。TCP的拥塞控制在所有场合也都是相同的，即TCP减小拥塞窗口。

但是由于无线网络的差错比特率普遍较多，所以导致重传的很有可能不是因为拥塞，一味的减小拥塞窗口导致路由器大量缓存空闲。

由于无线信道的高比特差错率和切换丢失的可能性，TCP的拥塞控制反应在无线情况下可能会有问题。有三大类可能的方法处理这一问题：
- 本地恢复
    - 在比特差错出现的当时和当地将其恢复
- TCP发送方知晓无线链路
    - 让TCP发送方和接收方知道无线链路的存在，从而将有线网络中发生的拥塞性丢包和无线网络中发生的差错丢包区分开，并且经对有线网络中的拥塞性丢包采取拥塞控制
- 分离连接方法
    - 移动用户和其他端点之间的端到端连接被打断为两个运输层连接：从一个移动主机到无线接入点，一个无线接入点到其他通信端点
    - 该端到端连接因此是由一个无线部分和一个有线部分级联形成
    - 经无线段的运输层能够是一个标准的TCP连接，或是一个特别定制运行在UDP上的差错恢复协议


## 多媒体网络

### 多媒体网络应用

我们将多媒体网络应用定义为任何应用音频或视频的网络应用


#### 视频的性质

视频最显著的特点或许是它的 **高比特率** 。因此，当设计网络视频应用时，我们心中必须记住的第一件事是视频的比特率要求。

视频的另一个重要特点是它能被压缩，因而要在视频质量和比特率间进行折中。视频是一个图像序列，图像通常一恒定的速率显示。

我们也能够使用压缩来生成相同视频的多重版本，每个版本质量等级不同。用户可以根据他们当前的带宽来选择画质。

#### 音频是性质

我们先考虑模拟音频(由人或乐器产生)如何转化成数字信号：
- 模拟音频信号首先以某种固定采样率采样
- 然后每个采样值被"四舍五入"为有限个数值的一个
    - 这种操作被称为量化
    - 这些有限个数值通常是2的幂
- 每个量化值有固定数量比特表示
    - 所有样本的比特表示级联在一起就形成了该信号的数字表示
        - 如一个模拟信号每秒8000个样值采样，而每个样本被量化并用8比特表示，则得到的数字信号的速率就为每秒64000比特
    - 通过扬声器播放，这个数字信号则被转换回来(解码)

我们刚才描述的基本编码技术称为 **脉冲编码调制(PCM)** 。然而PCM编码的语音和音乐很少在因特网中使用。与视频一样，取而代之的是使用压缩技术来减小流的比特率。一种接近CD质量立体声音乐的流行压缩技术是 **MPEG 1 第3层** ，也就是MP3。

#### 多媒体网路应用的类型

我们将多媒体应用分为三个大类：
- 1. 流式储存音频/视频
- 2. 会话式IP语音/视频
- 3. 流式实况音频/视频
    - 类似与传统的电台广播和电视

##### 流式储存音频和视频

这些预先录制好的视频放置在服务器上，用户向服务器发送请求按需观看视频。流式视频具有三个关键的不同特色：
- 流
    - 客户开始从服务器接收文件几秒后，开始播放视频，与此同时从服务器接收该视频的后续部分
- 相互作用
    - 用户可以对多媒体内容进行暂停、重新配置、前进、后退等
- 连续播放


### 流式储存视频

流式储存视频系统可以分为三种类型：**UDP流** , **HTTP流** , **适用性HTTP流** 。但今天大多数系统应用了HTTP流和适应性HTTP流。

所有三种形式的视频流的共同特点是广泛使用了客户端应用缓存，以此来缓解变化的端到端时延和变化的服务器和客户之间可用带宽量的变化。这种客户缓存具有两种重要的优点：
- 客户端能够吸收服务器到客户时延中的波动
- 如果服务器到客户带宽暂时低于视频消耗速率，在缓存没有耗尽的情况下，用户仍能流畅观看视频


#### UDP流

使用流，服务器通过UDP以某种稳定的速率记录下视频块，用与客户的视频消耗速率相匹配的速率传输视频。因为UDP未采用某种拥塞控制机制，所以服务器能够以视频的消耗速率将分组推进因特网中，而无TCP的速率控制限制。

在将视频块传递给UDP之前，服务器将视频块封装在运输分组中，该运输分组是专门为传输音频和视频而设计的，使用了 **实时传输协议(RTP)** 或某种类似的方案。

UDP流的另一种不同的性质是，除了服务器到用户的视频流外，两者间并行地维护一个单独的控制连接，通过该连接，客户可发送有关会话状态变化的命令(如暂停、重定位)等。

但UDP流有三个重大的不足：
- 由于服务器和控制之间的可用带宽无法预测且是变化的，恒定速率的UDP流不足以提供连续的播放
- 它要求如RTSP服务器这样的媒体控制服务器，以对每个进行中的客户会话处理客户到服务器的交互请求和跟踪客户状态
- 许多防火墙配置为阻塞UDP流量，防止这些防火墙后面的用户接收UDP视频


#### HTTP流

在HTTP流中，视频直接作为具有一个特定URL的普通文件储存在HTTP服务器上。当用户要看视频时，客户和服务器之间建立一个TCP连接，并且发送一个对该URL的HTTP GET请求。服务器则尽可能快地在HTTP响应报文中发送该视频文件，即已TCP拥塞控制和流控制允许的尽可能快的速率进行处理。在客户端上，字节收集在一个客户应用缓存中。一旦在缓存中字节数量超过预先设置的阀值，该客户应用程序开始播放。

在TCP上使用HTTP也使得视频穿越防火墙和NAT更容易。HTTP流消除了因需要媒体控制服务器带来的不便，减少了在因特网上大规模部署的成本。

##### 预取视频

由于客户能够以高于视频消耗速率的速率下载视频，因此 **预取** 将将来会被消耗的视频帧。预取的视频储存在客户应用中。这样的预取自然伴随着TCP流出现，因为TCP拥塞避免机制将试图使用服务器和客户端之间所有可用带宽。

##### 客户应用缓存和TCP缓存

考虑暂停视频时可能发生的现象。暂停期间，比特未从客户应用删除，甚至比特仍继续从服务器进入缓存。客户应用缓存有限，它可能最终会变满，这将反过来引起对服务器的"反向压力"。即：客户应用缓存变满，字节不再从客户TCP接收缓存中删除，因此它也会变满。一旦客户TCP接收缓存变满，字节不再从服务器TCP发送缓存中删除，因此它也变满。一旦客户TCP发送缓存变满，服务器不能向套接字中发送更多字节。因此如果用户暂停视频，服务器可能被迫停止传输，导致阻塞。

##### 视频的早期中止和重定位

HTTP流系统经常利用HTTP GET请求报文中的 **HTTP字节范围首部** ，该首部指示了客户当前要从希望的视频中获取的字节范围。当用户要在视频中跳跃时，客户发送一个新的HTTP请求，用字节范围首部指示出服务应从文件哪个字节开始发送。

在因特网中，大量的带宽因提前终止或重定位而浪费(缓存了没用)，因此多数流系统仅使用适当长度的客户应用缓存或限制HTTP请求中字节范围预取的视频帧数量。

##### 适应性流和DASH

HTTP流存在严重的缺陷，即所有客户接收到相同编码的视频。这就导致了一种新型基于HTTP的流的研发，它常常被称为 **经HTTP的动态适应性流(Dynamic Adaptive Streaming over HTTP, DASH)** 。在DASH中，视频编码为几个不同的版本，其中每个版本具有不同的比特率，对应不同的质量水平。

- DASH允许客户使用不同的以太网接入速率流式播放具有不同码率的视频
- 如果端到端带宽在会话过程中改变的话，DASH允许客户适应可用贷款

使用DASH后，每个视频版本储存在HTTP服务器中，每个都有一个不同的URL。HTTP服务器也有一个 **告示文件** ，没每个版本提供了一个URL及其比特率。客户首先请求该告示文件并且得知各种各样的版本。然后客户通过在HTTP GET请求报文中对每块指定一个URL和一个字节范围，一次选择一块。下载块的同时，客户也测量接收带宽并运行一个速率决定算法来选择下次请求的块。因此DASH允许客户自由地在不同质量等级之间切换。

##### 内容分发网

一个网络视频公司每天要向几亿个用户分发流，这显然是个挑战，最直接的提供流式视频服务的方法就是建立单一的大规模数据中心。但这种方法有三个缺点：
- 如果客户远离数据中心，服务器到客户的分组要跨越很多ISP，如果这些链路之一的吞吐量小于视频的消耗速率，这造成很大的延迟
- 流行的视频很可能经过相同的通信链路发送多次。浪费带宽
- 单个数据中心代表一个单点故障，如果数据中心或其通向因特网的链路崩溃，它将不能发送任何视频流

因此， **内容分发网(CDN)** 应运而生。CDN管理分布在多个地理位置上的服务器，在它的服务器中储存视频(或别的类型)的副本，并且试图将每个用户请求定向到一个能提供最好用户体验的CDN位置。

CDN通常采用两种不同的服务器安置原则：
- **深入** 
    - 通过在遍及全球的接入ISP中部署服务集群来深入到ISP的接入网中
    - 目标是靠近端用户，通过减少端用户和CDN集群之间链路和路由器的数量，从而改善了用户感受的时延和吞吐量
- **邀请做客** 
    - 通过在少量关键位置建立大集群并使用专用高速网络连接这些集群来邀请ISP做客
    - 不是将集群放在接入ISP中，这些CDN通常将每个集群放置在同时接近许多第一层ISP的PoP的位置上

一旦CDN集群准备就绪，它就可以跨集群复制内容。CDN不会将每个视频的副本放置在每个集群中，因为有些视频很少观看或在某些地区不流行。多数CDN采用一直拉的策略，即如果客户向一个为储存该视频的集群请求某视频，则该集群从某仓库中心检索视频，向客户流式传输并保存一个到本地。当某集群储存器变满时，删除不常请求的视频。


##### CDN操作

但用户主机中检索一个特定的视频时(URL)，CDN必须截取请求，以便能够：
- 1. 确定此时适合于用客户的CDN服务器集群
- 2. 将客户的请求重定向到该集群的某台服务器

过程大概如下：
- 1. 用户访问某Web网页
- 2. 用户点击某视频链接时，用户主机发送一个对于该链接的DNS请求
- 3. 用户的本地DNS(LDNS)服务器中继该DNS请求到一台该URL对应的权威服务器，该服务器返回一个CDN权威服务器
- 4. 用户的LDNS向CDN权威服务器发送请求，得到内容CDN服务器结点的IP地址
- 5. LDNS向用户主机转发内容CDN服务器结点的IP地址
- 6. 用户收到内容CDN服务器的IP地址后就可以建立TCP连接，并发送对视频的HTTP GET请求


##### 集群选择策略

任何CDN部署，其核心是 **集群选择策略** ，即动态地将客户定向到CDN中服务器集群或数据中心的机制。一种简单的策略是指派客户到 **地理上最为邻近** 的集群。但地理上最邻近不一定是链路上最短。

为了基于当前流量条件为客户决定最好的集群，CDN能够对其集群和客户之间的时延和丢包性能执行周期性的 **实时测量** 。一下是几种测量的方法
- CDN让它的每个集群周期性地向位于全世界的所有LDNS发送探测分组
    - 缺点是许多LDNS配置为不会对这些探测进行响应
- 使用客户与CDN服务器之间近期和进行中的流量特点：如通过观察三次握手中的时隙估计
    - 缺点是需要时不时地将客户重定向到(可能的)次优化集群
- 使用DNS请求流量来测量客户和集群之间的时延
    - 使用这种方案，DNS服务器继续向该客户返回优化的集群，使得交付视频和其他Web对象不受到伤害
- 使客户与CDN服务器匹配的一种非常不同的方法是使用 **IP任播** 
    - IP任播基于的思想是让因特网中的路由器将客户的分组路由到"最近的"集群，就像BGP决定那样。然而IP任播策略仍未顾及因特网在短时间范围内的动态性质

除了时延、丢包和带宽性能等网络相关考虑外，还有许多因素需要考虑，如：集群上的负载、ISP的交付成本等


### IP语音

经因特网的实时会话式语音通常称为 **IP语音(Voice-over IP, VoIP)** 


#### 尽力而为服务的限制

因特网的网络层IP协议提供了尽力而为的服务。就是说服务尽全力传输数据报，但不能保证超时和丢包。这对会话式应用设计提出了分组时延、时延抖动和丢包等挑战。

- 丢包
    - 如果VoIP使用的是TCP(可靠传输)
        - 由于可靠传输的重传机制，带来的时延往往是不可接受的
    - 几乎所有VoIP应用都默认运行在UDP上
        - 虽然UDP是不可靠传输的，但使用一定的方法把丢包率控制得较小就可以接受了
- 端到端时延
    - 时延的因素：路由器中的传输、处理和排队的时延和端系统的处理时延
- 分组时延抖动
    - 如果接收方一收到分组就播放，那由于网络的波动，音频的质量容易变得不易理解
    - 需要为分组标上序号并延时播放


#### 在接收方消除音频的抖动

通常结合下面两个机制来实现：
- 每个块预先计划一个时间戳
- 接收方延迟播放
    - 以便大多数分组在他们预订的播放时间之前被收到

##### 固定播放时延

使用固定播放时延策略，接受方试图在产生块*q ms* 后播放它。因此如果一个块在t时刻打上时间戳，接收方将在*t+q* 播放这个块，如果块在预订播放时间之后到达，则分组将被丢弃，被认定为丢失。

q的选择就成为了关键，q太小则网络的抖动可能使许多分组错过预订的播放时间。概括的说，如果端到端时延经常发生大的变化，用一个大的q更好;如果时延很小且变化很小，用一个较小的q更好

##### 适应性播放时延

估计网络时延和网络时延的变化，并且在每个话音突峰的开始相应地调整播放时延。在话音突峰开始调整会时发送方的静默期压缩或拉长，但静默期的谈话不易察觉。

算法如下：令

- $t_i = 分组i在发送方产生的时间$
- $r_i = 分组i被接收方接收的时间$
- $p_i = 分组在接收方播放的时间$

第i个分组的端到端网络时延是$r_i - t_i$，令$d_i$表示接收到第i个分组的平均网络时延的估计值，则：

$$d_i = (1-u)d_{i-1} + u(r_i - t_i)$$

式中u是一个固定的常数，如u=0.01。这样$d_i$是观察到的网络时延的一个平滑均值。

令$v_i$表示估计平均时延与平均时延的绝对偏差的估计值：

$$v_i = (1-u)v_{i-1} + u|r_i - t_i - d_i|$$

为每个接收的分组计算估计值$d_i$和$v_i$，尽管他们仅能用于为任何话音突峰的第一个分组的确定播放点。

接收方为分组播放应用下列算法

$$p_i = t_i + d_i +Kv_i$$

这里K是一个正的常数。$Kv_i$项的目的是给将来设置足够大的播放时间，以便话音突峰中只有一小部分分组迟到而丢失。在一个语音突峰期中任何后续分组的播放点被计算为对于这个语音突峰期的第一个分组的偏移。令

$$q_i = p_i - t_i$$

表示从话音突峰是第一个分组产生到它播放的时间长度。如果分组j也属于这个话音突峰期，则它的播放时刻是

$$p_j = t_j + q_i$$


#### 从丢包中恢复

我们定义广义的丢包：如果某分组不能到达接收方或者在它的播放时间之后到达，则该分组丢失。

重传丢失的分钟带来的延时往往是不能接受的。VoIP应用通常使用某种类型的丢包预期方案。两种类型的丢包预期方案是：
- **向前纠错(FEC)** 
- 交织

##### 向前纠错

FEC的基本思想是给初始分组增加冗余信息，以稍微增加传输速率为代价，这些冗余信息可以用来重建丢失的分组的近似或者准确版本。我们概括了两种简单的FEC机制。

第一种是每发送n个块之后发送一个冗余编码块。这个冗余块通过异或n个初始块来获得。这样，在这n+1个分组中，有任何一组丢失都能恢复，但当有两组或以上丢失时无法重建。可以通过减小n+1的长度，这样大部分丢失的分组能够恢复，但会增加冗余分组。

第二种机制发送一个较低分辨率的分组作为冗余分组。如发送方可创建一个标称的音频流和一个相对低比特率的音频流，每个标称的块带着上一块的较低分辨率版本的块一起发送。这样当第i组丢失时，可用下一组携带的低分辨率的块来替代。当然，一可携带2个3个低分辨率的块。

##### 交织

作为冗余传输的另一种代替方案，VoIP应用可以发送交织的音频。发送方在传输之前把音频划分成更小的单元，使得最初相邻的单元在传输流中以一定的距离分开，然后在接收方出再重新排序。

交织可以减轻丢包的影响，单个丢包导致的小间隙与非交织流中的丢包导致的大间隙形成对比。

交织能够明显提高音频流可感觉到的质量。它开销也低。交织的明显缺点是增加了时延(需要额外的字段来分组排序)。但它能很好的处理流式储存音频。不增加流的宽带需求。

##### 差错掩盖

差错掩盖方案试图为丢失的分组产生一个与初始分组类似的替代物。因为音频信号呈现大量的短期自相似性，故该方法是可行的。

因此这些技术适合于工作在相对小丢包率和小分组的情况。

        
### 实时会话式应用的协议

#### RTP

VoIP应用发送方在发送之前要在附加上首部字段(如时间戳、序号等)，RTP就是这样一个标准。RTP能够用于传输通用格式，也可用于传输专用的声音和视频格式。

##### RTP基础

RTP通常运行在UDP上。发送端在RTP分组中封装媒体块，然后在UDP报文中封装该分组，然后将该报文段递交给IP。接受端从UDP报文中提取出这个RTP分组，然后从RTP分组中提取媒体块，并将这个块传递给媒体播放器来解码和呈现。

发送端在每个语音数据块前面加上一个RTP首部，这个首部包含音频编码类型、序号和时间戳。RTP首部通常是12字节。音频块和RTP首部一起形成了 **RTP分组** 。然后向UDP套接字接口发送该RTP分组。

RTP并不提供任何机制来保证数据的及时交付，或者提供其他服务(QoS)保证;它甚至不保证分组的交付或防止分组的失序交付。

RTP封装的东西仅为端系统所见。路由器不区分携带RTP分组的IP数据报和不携带RTP分组的IP数据报。

RTP允许每个源(相机或麦克风等)分配一个它自己的独立RTP分组流。在编码过程中很多流行的技术将音频和视频捆绑在单个流中，当捆绑时每个方向只产生一个RTP流。


##### RTP分组首部字段

4个主要的RTP分组首部字段是有效载荷类型、序号、时间戳和源标识符字段。

- 有效载荷类型
    - 长度7比特，用于指示所使用的编码类型
- 序号字段
    - 长度16比特，每发送一个RTP分组该序号增加1,而且接收方可以使用该序号来检测丢包和恢复分组序列
- 时间戳字段
    - 长度32比特，它反映RTP数据分组中的第一个字节的采样时刻
- 同步源标识(SSRC)
    - 长32比特，它标识了RTP流的源
    - SSRC不是发送方的地址，而是当新的流开始时源随机分配的一个数，如果分配的数相同则重新选择一个SSRC值


#### SIP

**会话发起协议(SIP)** 是一个开放和轻型的协议，其功能如下：
- 提供了在主叫者和被叫者之间经IP网络建立呼叫的机制
    - 它允许主叫者通知被叫者它要开始一个呼叫
    - 它允许参与者约定媒体编码，也允许参与者结束呼叫
- 提供了主叫者确定被叫者的当前IP地址的机制
    - 因为用户可能动态地分配到地址(DHCP)，而且可能有多台设备，每个设备有不同IP地址
- 提供了用于呼叫管理的机制
    - 这些机制包括在呼叫期间增加新媒体流、在呼叫期间改变编码、在呼叫期间邀请新的参与者、呼叫转移和呼叫保持等

##### 向已知IP地址建立一个呼叫

我们假设通信双方知道对方的IP地址

- 1. 主叫者向被叫者发送一个INVITE报文(类似HTTP的请求)
    - 该INVITE报文通过UDP发送给SIP的周知端口5060(SIP报文也可经TCP发送)。
    - 该报文包括了对被叫者的标识、主叫者的IP地址的指示、主叫者希望接收音频类型指示，以及它希望在哪个端口接受RTP分组的指示等
- 2. 被叫者收到INVITE报文后发送一个SIP响应报文
    - 该响应报文也发送到SIP周知端口5060
    - 响应报文包括一个OK和它的IP地址指示、它希望接收的编码和分组话以及数据应发送到达的端口号等
- 3. 接收到响应后主叫者向被叫者发送SIP确认报文，之后便可开始交谈
    - 双方会根据要求对音频编码和分组化

SIP的一些关键特性：
- SIP是一个外带协议
    - 发送和接收SIP报文使用了一个不同于发送和接受媒体数据报的套接字
- SIP报文本身是可读的ASCII
- SIP要求所有的报文都要确认，因此它能够在UDP或TCP上运行

如果没有指定的编码器，则发送一个606不可接受来响应，并列出能够接受的所有编码，然后对方重新发送一个INVITE报文以通告选择的编码器。


##### 名字翻译和用户定位

主叫者要如何获得被叫者正在使用的设备的IP地址呢？

为了获得它主叫者建立一个INVITE报文，它以被叫者的SIP地址(类似于邮箱，唯一的)开始，并将该报文发送给一个 **SIP代理** 。该代理将以一个SIP回答来响应，回答包含被叫者正在使用的设备的IP地址。

那代理服务器是如何获得被叫这正在使用的设备的IP地址的呢？

每个SIP用户都有一个相关联的 **SIP注册器** 。任何时候用户在设备上发起SIP应用时，应用给注册器发送一个SIP注册报文，通知注册器它现在的IP地址。每切换到一个新的SIP设备时，该新设备将发送注册报文。注册器和DNS权威名字服务器类似，SIP注册器把固定的SIP地址翻译成一个动态的IP地址。SIP注册器和SIP代理通常运行在同一台主机上。

所以代理服务器要获得被叫者的IP地址，只要转发主叫者的INVITE报文给被叫者的注册器/代理即可。然后注册器/代理将该报文转发给被叫者正在使用的SIP设备。

SIP通常是一个发起和结束会话的信令协议。


### 支持多媒体的网络

网络(而不是应用程序或者仅应用级的基础设施)是否可以提供支持多媒体内容交付的机制？答案是肯定的。一下总结了能够对多媒体应用提供网络级支持的三种宽泛方法：

| 方法                    | 粒度                   | 保证     | 机制                                    | 复杂性 | 当前部署 |
|-------------------------|------------------------|----------|-----------------------------------------|--------|----------|
| 尽可能利用尽力而为服务  | 公平处理所有流量       | 无或者软 | 应用级支持，CDN覆盖网络，网络级资源供给 | 最小   | 无处不在 |
| 分区服务                | 不同类型的流量处理不同 | 无或者软 | 分组标识，监管，调度                    | 中等   | 某些     |
| 每连接服务质量(QoS)保证 | 每个源到目的流处理不同 | 软或者硬 | 分组表示，监管，调度，呼叫准入和信令    | 高     | 很少     |

- 尽可能利用尽力而为服务  
    - 如遇见需求增加，ISP部署额外的带宽和交换能力
- 分区服务                
    - 当两类流量在一台路由器排队时，一种类型的流量可以给定严格的优于另一种类型的流量
    - 如VoIP对带宽敏感，邮件不怎么敏感，所有VoIP流量优先级可以设置高于邮件流量
- 每连接服务质量(QoS)保证 
    - 每个应用的实例显式地预约端到端带宽，并因此确保端到端的性能
    - **硬保证** 意味着用用必定接收到它所请求的服务质量
    - **软保证** 意味着应用以很高的概率接收到请求的服务质量
    - 但是允许应用做预约和请求网络同意该预约需要一些很大的变化
        - 1. 我们需要一个协议来代表应用程序，从发送方到其接收方沿路预约链路带宽
        - 2. 路由器队列中将需要新的调度策略，使每连接带宽预约能够兑现
        - 3. 应用程序必须向网络给出描述来说明它们希望发送进网络的流量，并且网络将需要监管每个应用程序的流量以保证它遵守这个规则


#### 定制尽力而为网络

为了预测两个网络端点之间的应用级性能，必须处理下列问题，并因此提供充足的容量来满足应用的性能要求：
- 网络端点之间的流量要求模型
    - 这些模型可能需要定义在呼叫层次和分组层次
    - 注意负载可能随着时间而变化
- 定义良好的性能要求
    - 分组端到端时延超过可容忍量的概率很小
- 对给定的负载模型预测端到端性能的模型，以及求出最小成本带宽分配的技术


#### 提供多种类型的服务

也许对互联网的一种简单的强化是将流量划分为多种类型，并为这些不同类型的流量提供不同等级的服务。

另一种做法是，ISP可能直接向愿意对这种改进服务支付更多费用的顾客提供更高质量的服务。

##### 调度机制

几个重要的调度规则
- 先进先出(FIFO)
- 优先级队列
    - 到达输出链路的分组被分类放入输出队列中的优先级类
    - 一个分组的优先级类可能取决于其分组首部携带的一个明显的标记、它的源或者目的地址、它的目的端口号或者其他标准
    - 每个优先级类通常都有自己的队列，当选择一个分组传输时，有限级队列将从队列为非空的最高优先级类中传输一个分组
- 循环和加权公平排队
    - 分组像使用优先级队列一样被分类，但循环调度器在这些类之间轮流提供服务
    - 当寻找给定类的分组但是没找到时，将立即检查循环序列中的下一个类

在QoS体系结构中已经得到大量使用的循环排队的一个抽象是 **加权公平排队(WFQ)** 规则。到达的分组被分类并在合适的每个类的等待区中排队。于循环调度一样，WFQ调度器也以循环的方式为各个类提供服务。

WFQ和循环队列不同之处在于，使用WFQ方式，在类i有分组要发送的任何时间间隔中，第i类将确保接收到的服务部分等于$\frac{w_i}{\sum{w_j}}$


##### 监管：漏桶

应该对一个流的分组速率的哪方面进行监管呢？一下列出3个重要的监管准则，每个准则根据被监管分组的时间范围的而不同
- 平均速率
    - 一个关键的问题是平均时间间隔
        - 如每秒100个分组的流要比没分组6000可分组的流受到的约束更加严格，因为后者允许一个流在给定1秒钟内发送1000个分组，而后者不能
- 峰值速率
    - 峰值约束限制了一个较短时间内能够发送的最大分组数
- 突发长度
    - 网络也许还希望限制极短时间间隔内能够发送的最大分组数

漏桶机制是一个能够用来表征这些监管机制的抽象。

过程如下：
- 漏桶由一个能容纳b个令牌的桶组成
- 而且可能r的速率添加令牌(这里假设r/每秒)
- 之所以说是可能，是因为当桶内令牌大于等于b时(满了)不产生令牌
- 一个分组向网络传输之前必须先从桶中取出一个令牌，所以漏桶监管的流的最大突发长度是b个分组
- 如果考虑t的时间间隔，则在这个时间能能够进入网络的最大分组为tr+b个
- 因此令牌的产生速率r用于限制分组能够进入网络的长期平均速率

前面讲WFQ时，每个流i保证收到知道等于$R \cdot \frac{w_i}{\sum{w_j}}$的共享链路带宽，其中R是以分组/秒为单位的链路传输速率。当以WQF方式等待服务时，分组经受的最大时延是什么？

关注WFQ中一条流i，流i中的令牌桶是满的，然后$b_i$个分组突发的流到流i的漏桶监管器。漏桶分发掉所有$b_i$个令牌给这些分组，然后把它们加入了流i的等待区。因为这$b_i$个分组以至少$R \cdot \frac{w_i}{\sum{w_j}}$分组/秒的速率得到服务，直到传输完成，所以对于这$b_i$个分组，最大时延$d_{max}$为：
$$d_{max} = \frac{b_i}{R \cdot \frac{w_i}{\sum{w_j}}}$$


#### 区分服务

Diffserv提供服务区分，也就是因特网中以一种可扩展方式用不同方法处理不同类型流量的能力。可扩展性源于这样一个事实：在因特网中的一个主干路由器上同时存在几十万个源到目的地的并行流。

区分服务系统由以下两个功能元素构成：
- 边界功能：分组分类和流量调节
    - 在网络的入边缘，到达的分组被标记
    - 分组得到的标记标识了该分组所属的流量类型。然后不同类型的流量将在核心网络接受到不同的服务
- 核心功能：转发
    - 当一个DS标记的分组到达一个Diffserv使能的路由器时，根据与分组类型相关的所谓的 **每跳行为(PHB)** ，该分组被转发到它的下一跳
    - 每跳行为影响在竞争的流量类型之间共享路由器缓存和链路贷款的方式
    - Diffserv体系结构的一个关键原则是路由器的每跳行为只基于分组标记，即分组所属类型

到达边缘路由器的分组首先被分类。分类器根据一个或多个分组首部字段的值来选择分组。在某些情况下，端用户可能已经同意限制其分组发送速率以符合某个申报的 **流量配置文件** 。该流量配置文件可能包含对峰值速率和分组流的突发度的限制。只要用户以符合协商的流量配置文件的方式向网络中发送分组，这些分组就会得到它们的优先标记，并转发。如果违反了流量配置文件，那些超出流量配置文件的分组可能被打上不同的标记或被整形或被丢弃。

Diffserv体系结构的第二个关键组件涉及由Diffserv使能的路由器所执行的 **每跳行为(PHB)** ，被定义为"Diffserv结点的外部可观察的转发行为的描述，该结点应用了一个特定的Diffserv行为聚合"，它里面包含的几个重要的考虑：
- PHB能够导致不同类型的流量接受到不同的性能
- 虽然PHB定义了各种类型之间的性能差别，但它不强求为了获得这些行为的任何特定机制
    - 只要外部可观察的性能准则得到满足，任何实现机制和任何缓存/带宽分配策略都可以使用
    - PHB是最后的结果，资源分配和实现机制是到达PHB的手段
- 性能的差别必须的可观察的，因而是可测量的

已经定义了两种PHB：
- 加速转发(EF)PHB
    - 规定了一类流量离开路由器的速率必须等于或大于某个已配置的速率
- 确保转发(AF)PHB
    - 将流量分为4类，其中每个AF类都确保提供某种最小数量的带宽和缓存


#### 每连接服务质量保证：资源预约和呼叫准入

设两个需要1Mbps的音频应用经过1.5Mbps的共享链路传输它们的分组。显然两个流结合的速率超过了共享链路的容量。如果两条流公平分配链路，则每个应用会丢失其25%的分组。显然是无法接受的，其这样传输的分组也是无用的。解决方法很明确了：应用流中的一个应当被阻塞，而另一个应当允许继续进行，使得该应用使用所需的全部1Mbps。

通过基于流的资源要求以及已经准入的资源要求明确的准入或阻塞流，网络能保证准入流可得到它们所需求的QoS。让流申告它的QoS要求，然后让网络接受该流或阻塞该流的过程称为 **呼叫准入** 。

几种新的网络机制和协议的要求：
- 预留资源
    - 为了满足一个呼叫所需的QoS，确保它具有所需的资源的唯一方法是显式地为该呼叫分配这些资源
    - 一旦呼叫预约了资源，它在整个过程中按需访问这些资源，而不管所有其他呼叫的请求
- 呼叫准入
    - 如果预留了资源，则该网络必须具有一种用于呼叫请求和预留资源的机制
    - 如果请求的资源不可用，则进行呼叫的准入请求将被拒绝准入，即阻塞
    - 知道成功完成呼叫准入过程才能被允许向网络发送流量
- 呼叫建立信令
    - 每天路由器必须决定会话所请求的本地资源，考虑已经承诺给其他进行中会话的资源量，并决定它是否有足够的资源来满足该会话的每跳QoS要求
    - 需要本地资源的每跳分配，以及该呼叫是否能够在沿着端到端路径上的每台路由器中预约充分的资源


## 计算机网络中的安全

我们能够指出 **安全通信** 具有一下所需的特性：
- 机密性
    - 仅有发送方和希望的接收方能够理解传输报文的内容
- 报文完整性
    - 报文传输过程内容未被改变
- 端点鉴别
    - 发送方和接收方都应该证实通信过程涉及的另一方，以确实他们的身份
- 运行安全性


### 密码学的原则

#### 对称密钥密码体制

##### 块密码

要加密的报文被处理为k比特的块。每块被单独加密。为了加密一个块，该密码采用了一对一映射，将k比特的明文块映射为k比特的密文。

如果k的值小，很快就能够破解;如果k值很大，那需要维护一张具有$2^{k}$个输入值的表，这是一个很难实现的任务。取而带之的是，块密码通常使用函数模拟随机排列表。如：一个k=64的块，函数首先将64比特块划分为8个8比特的小块，每个8比特小块由一个"8比特到8比特"的表处理，第一个块由表$T_i$来处理，然后这8个输出块被重新装配成64比特的块并作为下一轮的函数输入，如此循环n次后，该函数提供了一个64比特的密文块。循环多次的目的是使得每个输入比特影响最后输出比特的大部分


##### 密码块链接

我们通常需要加密长报文，如果我们使用前面提到的块密码直接把报文加密成独立的块会出现一个问题。即会出现两个或更多明文块是相同的。攻击者看到这些相似的密文后，可能潜在的猜出明文，甚至整个报文。

我们需要在密文中混入一些随机性，使得相同的明文块产生不同的密文块。令$m(i)$表示第i个明文块，$c(i)$表示第i个密文块，将密钥S的块密码加密算法表示为$K_S$。

基本思想如下：
- 发送方为第i块生成一个随机的k比特数r(i)，密文就等于$c(i) = K_S(m(i) \bigoplus r(i))$
    - 注意到每个块都选择一个新的k比特随机数
- 发送方发送$c(1), r(1), c(2), r(2), ..., c(i), r(i)$给接收方
- 接收方通过$m(i) = K_S(c(i) \bigoplus r(i))$就可以回复明文

虽然随机数是以明文的方式发送，但攻击者不知道块密码加密算法K。同时两个明文块出想相同的概率很低。

但这样又引入了新的问题，即发送方必须传输的是以前的两倍。对于这个问题，块密码通常使用一种称为 **密码块链接(CBC)** 的技术。其基本思想是仅发送一个随机数，然后让接收方计算出后续的随机数。

CBC过程如下：
- 加密报文之前，发送方生成一个k比特的随机数，称为 **初始向量(IV)** ，记为c(0)
- 对于第一个块，发送发发送$c(1) = K_S(m(1) \bigoplus c(0))$
- 对于第i个块，发送发发送$c(i) = K_S(m(i) \bigoplus c(i-1))$

这样仅用1个随机数加密文就可以完成


#### 公开密钥加密

发送方用接收方公开的 **公钥** 加密的报文，接收方用为公开的 **私钥** 就可解密得到明文。公钥加密私钥解，私钥加密公钥解。

这种方式需要注意：
- 任何人可以通过公钥加密一段报文然后发送给接收方，接收方因此需要方法报文的篡改和伪造。

##### RSA

RSA算法已然成为了公开密钥密码的代名词。

首先我们需要知道以下事实：
- 模算数遵循交换率和结合率
    - $a \bmod n + b \bmod n \equiv a + b \bmod n$
    - $a \bmod n \cdot b \bmod n \equiv a \cdot b \bmod n$
- 由上述事实能够有
    - $(a \bmod n)^d \bmod n \equiv a^d \bmod n$

RSA生成密钥的过程:
- 1. 选择两个大素数p和q
    - p和q越大破解越困难
- 2. 计算$n = pq$和$z = (p-1)(q-1)$
- 3. 选择小于n的一个数e，且e和z互素
- 4. 求一个数d，使得ed-1可以被z整除，即给定e选择d使得$ed \bmod z = 1$
- 5. 这样外界可用公钥$K^+_B$是一对数(n, e);其私钥$K^-_B$是一对数(n, d)
    - 加密过程：$c = m^e \bmod n$
    - 解密过程：$m = c^d \bmod n$

由于RSA所要求的指数运算是相当耗费时间的，形成对比的是对称加密要比比RSA快得100～10000倍。所以在实际情况中RSA通常与对称密钥结合起来使用。即发送方使用RSA来通知接收方接下来进行对称加密通话使用的密钥，然后进行对称加密通话。


##### RSA的工作原理

在RSA加密过程中，一个报文m使用模n算术做e次幂运算

$$c \equiv m^e \bmod n$$

解密则先执行d次幂，在做模n运算，因此先加密后解密的结果是$(m^e \bmod n)^d \bmod n$由这样一个事实$(a \bmod n)^d \bmod n \equiv a^d \bmod n$得：

$$(m^e \bmod n)^d \bmod n \equiv m^{ed} \bmod n$$

在数论中有这样的结论：如果p和q是素数，且有n=pq和z=(p-1)(q-1)，则$x^y \bmod n$与$x^{(y \bmod z)} \bmod n$是等同的，可得

$$m^{ed} \bmod n \equiv m^{ed \bmod z} \bmod n$$

由于我们选的e，d有$ed \bmod z = 1$所以：

$$m^ed \bmod n \equiv m^1 \bmod n = m$$

甚至我们可以先对m做d次幂(加密)在做e次幂(解密)，也能得到初始值m

RSA的安全性依赖于这样的事实：目前没有已知算法可以快速进行一个数的因素分解，因此公开值n无法快速分解成素数p和q。但也因为这点存在RSA算法存在隐患，即不确定是否存在一个因数分解的算法。


### 报文完整性和数字签名

报文完整性需要证实
- 该报文确实来自希望的发送方，而非伪造的
- 该报文在发送途中没有没篡改


#### 密码散列函数

密码散列函数要求具有一下性质：
- 找到任意两个不同的报文x和y使得H(x)=H(y)在计算上是不可能的

MD5散列算法是如今正在广泛使用的，这个算法通过4个步骤得到128比特的散列
- 1. 填充
    - 先填1,然后填足够多的0，知道报文长度满足一定的条件
- 2. 添加
    - 在填充前添加一个64比特表示的报文长度
- 3. 初始化累加器
- 4. 循环
    - 对报文的16字块进行4轮处理


#### 报文鉴别码

通过散列函数，我们可以执行报文的完整性检测
- 1. 发送方和接收方共享 **鉴别密钥** s
    - 防止攻击者伪造报文
    - 这个过程可以通过物理上配置：面谈、一台一台机器的配置等
    - 也可通过公钥加密该密钥，通过网络发送加密的密钥
- 2. 发送方生成报文m
    - 用s级联m以生成m+s，并计算H(m+s)，H(m+s)被称为 **报文鉴别码(Message Authentication Code, MAC)** 
- 3. 发送方将MAC附加到报文m上，(m, H(m+s))，发送给接收者
- 4. 接收者收到报文(m, h)，由于知道s，通过计算H(m+s)，如果H(m+s)=h，则一切正常


#### 数字签名

数字签名用来指出一个文件的所有者或创作者

数字签名应该是可鉴别的、无法伪造的，一下是一个数字签名方案：使用私钥加密，即数字签名是$K_B^-(m)$。这样的数字签名是否满足要求呢？
- 无论谁签署这个报文，都必须使用私钥，所以是不可伪造且可鉴别的
- 如果源文档m被修改过，比如改成m'，则签名对m'无效，因为$K_B^+(K_B^-(m)) \neq m'$，所以提供了完整性

但是我们知道非对称加密和解密的计算代价是昂贵的。因此将散列函数引入数字签名。

一种散列算法取一个任意长的报文m，计算生成该报文的一个固定长度的数据"指纹"，表示为$H(m)$。对报文的散列签名，而不是对报文本身签名，即$K_B^-(H(m))$。因为H(m)通常比报文m小得多，计算的消耗大大降低。


##### 公钥认证

数字签名的一个重要应用的公钥认证，即证实一个公钥属于某个特定的实体。

要使公钥有用，需要证实你具有的公钥是与你要进行通信的实体的公钥，而不是攻击者对你的欺骗。

将公钥与特定实体绑定通常是由 **认证中心(CA)** 完成的，CA的职责就是使识别和发行证书合法话，(CA就像警察局)CA具有下列作用：
- CA证实一个实体的真实身份
    - 如何证实没有强制的过程，当与一个CA打交道时，一方必须信任这个CA能够执行适当的严格身份验证
- 一旦CA验证了某个实体的身份，这个CA会生成一个把其身份和实体公钥绑定起来的 **证书** 。
    - 这个证书包含这个公钥和公钥所有者全局唯一的身份标识
    - 由CA对这个证书进行签名

当发送者发送报文时，他也发送其CA部署的证书。接收者使用CA的公钥来核对发送者发送的证书的合法性并提取发送者的公钥。


### 端点鉴别

端点鉴别就是一个实体经过计算机网络向另一个实体证明其身份的过程。以下讨论网络通信双方如何能够鉴别彼此，通过使用 **鉴别协议(ap)** 

#### 鉴别协议

**不重数(nonce)** 是在一个协议的生存期中只使用一次的数，鉴别协议通过以下方式使用不重数
- 发送方向接收方发送一则报文m
- 接收方选择一个不重数R，然后发送给发送方
- 发送方使用他与接收方共享的对称密钥K来加密这个不重数，然后把加密的不重数K(R)发送给接收方
    - 由于加密密钥的双方共享的，所以接收方解密后知道是有发送方产生的
- 接收方收到密文后，如果解密得到的不重数等于他发送的不重数，则知道是发送方产生的


### 安全电子邮件

我们使用上面讲的工具，包括对称加密、非对称加密、端点鉴别等来在因特网中提供安全性。

为因特网协议栈上面4层的任一层提供安全性服务是可能的：为一层提供安全性服务，所使用这样协议的上一层应用程序将得到安全性服务。

为什么在因特网的多个层次上提供安全性能呢？仅在网络层提供还不足够吗？
- 首先，需要用户级安全性，如：一些站点希望依赖IP层安全性来鉴别，一些站点则不希望依赖IP
- 第二，在协议栈的比较高层上部署新的因特网服务通常比较容易


#### 安全电子邮件

安全电子邮件应该具有以下安全特性：
- 机密性
- 发送方鉴别
- 报文完整
- 接受方鉴别

为了提供机密性、发送方鉴别和报文完整性，使用数字签名和报文摘要来完成这个任务：
- 发送方对他要发送的报文m应用一个散列函数H(如MD5)，从而得到一个报文摘要
- 他通过私钥$K_B^-$对摘要进行签名
- 发送方把初始报文和该数字签名级联起来生成一个预备包
- 发送方选择一个随机对称会话密钥$K_S$
- 用这个对称密钥加密预备包，用接收方的公钥对这个对称密钥加密
- 接收方收到密文后用自己的私钥解密得到对称加密使用的会话密钥
- 使用会话密钥解密后得到数字签名和报文
- 使用发送方的公钥对签名进行认证
    - 要获取发送方的公钥的常用方法是通过CA验证该公钥


#### PGP

**PGP(Pretty Good Privacy)** 是一个电子邮件加密方案。


### 使TCP连接安全：SSL

用安全性服务加强TCP，该安全性服务包括机密性、数据完整性和端点鉴别。TCP的这种强化版本通常称为 **安全套接子层(SSL)** 。SSL版本3的一个稍加修改的版本被称为运输层安全性。

假设Bob在网购，到达了Alice的公司的网站，在提交订单进行购物时，如果不采用安全设施，Bob也许会有一些意外：
- 如果没有使用机密性，Bob的订单信息、支付卡号等可能被盗用
- 如果没有完整性，攻击者可以修改Bob的订单
- 如果没有使用服务器鉴别，Bob到达的Alice的网站可能是攻击者假冒的

SSL就可以解决这些问题


#### 宏观描述

我们先描述一个简化的SSL版本，我们称为"类SSL"。SSL具有三个阶段：握手、密钥导出和数据传输。对于一个客户(Bob)和一个服务器(Alice)之间的通话：

- 握手
    - 与Alice建立TCP连接
    - TCP连接建立后，Bob向Alice发送"hello报文"
    - Alice用他的证书进行响应，Bob收到证书后验证Alice的证书
        - 需要CA
    - 发送给Alice主密钥(MS)，用Alice的公钥加密MS发送给Alice
        - 双方用该主密钥生成SSL所需的对称密钥
- 密钥导出
    - 通过握手，Bob和Alice双方已经共享了MS，MS能够用作后续加密和数据完整性检查的对称会话密钥
    - Alice和Bob都使用MS生成4个密钥：
        - $E_B$，用于从Bob发送到Alice的数据的会话加密密钥
        - $M_B$，用于从Bob发送到Alice的数据的会话MAC密钥
        - $E_A$，用于从Alice发送到Bob的数据的会话加密密钥
        - $M_A$，用于从Alice发送到Bob的数据的会话MAC密钥
- 数据传输
    - SSL将数据流分割成记录(因为我们不希望TCP会话结束时才检验)，对每个记录附加一个MAC用于完整性检查，然后加密该"记录+MAC"
    - Bob维护一个序号计数器，当她计算MAC时，把序号包括在MAC的计算中。Alice跟踪Bob的序号，通过在MAC的计算中包括适当的序号来验证完整性
        - 防止了攻击者的插入、删除、替换、颠倒等

SSL记录如下

| 类型 | 版本 | 长度 | 数据 | MAC |
|------|------|------|------|-----|

前三个字段是不加密的，类型字段指出是握手报文还是包含应用数据的报文。


#### 更完整的描述

##### SSL握手

SSL并不强制Alice和Bob用一种特定的对称密钥算法、一种特定的公钥算法或一种特定的MAC。此外，在握手阶段，Alice和Bob彼此发送不重数，用户会话密钥的生成。真正的SSL握手步骤如下：
- 1. 客户发送它支持的密码算法的列表，连同一个客户的不重数
- 2. 从列表中选择一种对称算法、一种公钥算法和一种MAC算法。把服务器的选择以及证书和一个服务器不重数返回给客户
- 3. 用户验证证书，提取公钥，生成一个 **前主密钥(PMS)** ，用服务器的公钥加密该PMS，并发送给服务器
- 4. 是要相同的密钥导出函数，客户和服务器独立从PMS和不重数中计算 **主密钥(MS)** 。然后该MS被切片成两个密码和两个MAC密钥
    - 当选择的对称密码应用于CBC，则两个初始向量(IV)也从MS获得
- 5. 客户发送所有握手报文的一个MAC
- 6. 服务器发送所有握手报文的一个MAC

最后两步使握手免受篡改的危害。因为在用户的密码算法列表中，有一些算法强，有一些算法弱，攻击者可以从列表中删除交强的算法。步骤5中客户发送一个级联他已发送和接受的所有握手报文的MAC，服务器能够比较这个MAC和它所发送的握手报文的MAC。步骤6同理。


##### 连接关闭

在类型字段中指出该记录是否用于终止SSL。虽然类型字段是明文发送，但接收方可以用MAC来验证。


### 网络层安全性：IPsec和虚拟专用网

**IP安全(IP Security)** 协议通常被称为**IPsec** ，它为网络层提供了安全性。许多机构使用IPsec创建了运行在公共网络之上的 **虚拟专用网(virtual private network, VPN)** 。

为网络层提供机密性所包含的意义：在网络实体(路由器、主机等)对之间具有网络层机密性，发送实体加密它发送的所有数据报的载荷(可以是一个TCP报文段、UDP报文段等)。如果网络层服务适当的话，一个这样数据报可隐形于任何嗅探该网络的第三方。

除了机密性，它还提供源鉴别、完整性、防止重放攻击等功能


#### IPsec和虚拟专用网络

某些机构可能希望拥有自己的IP网络，使它的主机和服务器能够以一种安全和机密的方式通信，这样一种为特定机构专用的分立网络称为 **专用网络** 。

然而机构需要购买设施和维护，成本很大。所以如今许多机构在现有的公共因特网上建立VPN。为了提供机密性，流量在进入公共因特网之前进行加密。当要经过公共因特网时，要先将IP数据报转换成IPsec数据报，然后将该IPsec数据报转发进因特网。


#### AH协议和ESP协议

在IPsec协议族中，有两个主要协议： **鉴别首部(AH)** 协议和 **封装安全性载荷(ESP)** 协议。当某源IPsec实体向一个目标实体发送安全数据报时，它可使用AH协议或ESP协议。

AH协议提供源鉴别和数据完整性服务，但不提供机密性服务。ESP协议提供了源鉴别、数据完整性和机密性服务。


#### 安全关联

IPsec数据报在网络实体对之间发送，在从源实体向目的实体发送IPsec数据报之前，源和目的的实体创建了一个网络层的逻辑连接，称为 **安全关联(SA)** 。一个SA是一个单工逻辑连接。如果两个实体要互相发生安全数据报，则需创建两个SA，每个方向一个。

路由器需要维护有关SA的状态信息，包括：
- SA的32比特的标识符，称为 **安全参数索引(SPI)** 
- SA的初始接口和SA的目的接口
- 将使用的加密类型
- 加密密钥
- 完整性检查的类型
- 鉴别密钥

当路由器需要构建一个IPsec数据报经过这个SA转发时，它访问该状态信息以决定它应当如何鉴别和加密该数据报。

一个IPsec实体经常维护许多SA的状态信息。一个IPsec实体在它的 **安全关联数据库(SAD)** 中储存其中所有SA的状态信息，SAD是实体操作系统内核中的一个数据结构。


#### IPsec数据报

IPsec有两种不同的分组形式，一种用于所谓的 **隧道模式** ，另一种用于所谓的 **运输模式** 。更为适合VPN的隧道模式部署更广泛，以下我们关注隧道模式。

IPsec数据报的格式

| 新IP首部 | ESP首部 | 初始IP首部 | 初始数据报载荷 | ESP尾部 | ESP MAC |
|----------|---------|------------|----------------|---------|---------|

一台路由器将一个"普通的IPv4数据报"转换成一个IPsec数据报：
- 在初始IPv4数据报后面附加上一个"ESP尾部"字段
- 使用算法和由SA规定的密钥加密该结果
- 这个加密的前面附加上一个称为"ESP首部"的字段;得到的包称为"enchilada"，即包括ESP首部，初始IP首部、初始数据报载荷、ESP尾部
- 使用算法和由SA规定的密钥生成一个覆盖整个enchilade的鉴别MAC
- 该MAC附加到enchilada后面形成载荷
- 最后，生成一个具有所有经典IPv4首部字段的全新IP首部，附加到初始载荷之前

类似IPv4转IPv6的隧道，包裹在里面的初始数据报包含最终目的地的IP地址，而新IP首部则是指示隧道两个端点的路由器接口。同时这个新的IPv4首部字段中的协议号被设置为50，指示这是一个IPsec数据报。

观察enchilada的组成，ESP尾部包含三个字段组成：
- 填充
    - 因为块密码要求被加密的报文必须为块长的整数被，所以使用填充附加到初始数据报文上
- 填充长度
    - 填充长度字段指示填充了多少(并且需要别删除)
- 下一个首部
    - 下一个首部字段指示包含在载荷数据字段中数据的类型(如UDP)

附加到这个加密单元前面的是ESP首部，该首部以明文发送，它由两个字段组成：
- SPI字段
    - 指示接收实体数据属于哪个SA，接收实体则能够用该SPI索引其SAD以确定适当的鉴别/解密算法和密钥
- 序号字段。
    - 防御重放攻击

一个主机接收到IPsec数据报时，发现数据报的目的IP地址是自己，则该主机处理这个数据报
- 因为协议字段是50，明白对该数据报施加IPsec ESP处理
    - 针对enchilada，主机通过SPI确定该数据报属于哪个SA
    - 计算enchilada的MAC并验证
    - 检查序号
    - 使用与SA关联的解密算法和密钥解密该加密单元
    - 删除填充并抽取初始的IP报文
    - 最后朝着最终的目的地将该初始数据报转发进分支结构网络

一个重要但细微的问题：当位于专用网络中的一台主机收到一个未加密的数据报，并且该数据报要发网专用网外部，则这个主机怎么才能知道它应当转换成一个IPsec数据报呢？并且如果把它IPsec处理，主机如何知道它应当使用哪个SA来构造这个IPsec数据报呢？
- 除了SAD外，IPsec实体也维护另外一个数据结构，它称为 **安全策略库(SPD)** 。该SPD指示哪些类型的数据报将被IPsec处理;并且对这些将被IPsec处理的数据报应用哪个SA

IPsec在任何通过网络层处理分组的设备之间，提供了机密性、源鉴别、数据完整性和重放攻击防护。


#### IKE：IPsec中的密钥管理

当VPN端点很少时，人工配配置SAD中的SA信息很方便，但在大型的、分散的部署中要求一个自动的机制来生成SA。IPsec使用 **因特网密钥交换(IKE)** 协议来从事这项工作。

IKE与SSL中的握手具有某些类似。每个IPsec实体具有一个证书，该证书包括了该实体的公开密钥。IKE协议让两个实体交换证书，协商鉴别和加密算法，并安全地交换用于在IPsec SA中生成会话密钥的密钥材料。IKE应用两个阶段来执行这些任务：
- 第一个阶段由两台主机之间报文对的两次交换组成
    - 在报文第一次交换期间，两侧使用Diffic-Hellman在路由器之间生成一个双向的 **IKE SA** 
        - 该IKE SA在这两台路由器之间提供了一个鉴别的和加密的信道
        - 首个报文对交换期间，创建用于IKE SA的加密和鉴别的密钥
        - 还创建了将用于计算后期在阶段2使用的IPsec SA密钥的一个主密钥
    - 在报文的第二次交换期间，两侧通过对其报文签名而透露他们的身份
        - 同时在这个阶段期间，两侧协商由IPsec SA应用的IPsec加密和鉴别算法
- 第二阶段两侧生成在每个方向的一个SA
    - 阶段2结束时，对这两个SA的每一侧都建立了加密和鉴别会话密钥，然后这两侧都能使用SA来发送安全的数据报


### 使无线LAN安全

最初在802.11规范中标准化的安全性机制，该规范统称为 **有线等效保密(WEP)** 。顾名思义，WEP欲提供类似在有线网络中的安全性水平。


#### 有线等效保密

WEP并没有指定密钥管理算法，应为它假定主机和无线接入点之间通过带外方式就密钥达成某种一致。鉴别以下列方式进行：
- 1. 无线主机通过接入点请求鉴别
- 2. 接入点以一个128字节的不重值响应该鉴别请求
- 3. 无线主机用它与这个接入点共享的密钥加密这个不重值
- 4. 接入点解密主机加密的不重值
    - 如果加密得到的不重值与初始发送的值相同，则鉴别了主机

假定主机和接入点都知道一个秘密的40比特对称密钥$K_S$。此外，一个24比特的初始向量(IV)附加到这个40比特的密钥后面，产生用于加密单个帧的一个64比特密钥。每个帧所使用的IV都不同，所以每个帧都由不同的64比特密钥加密。加密以如下方式进行。
- 首先为每个数据载荷计算一个4字节的CRC值
- 然后用RC4流密码加密该载荷和该4字节CRC
    - 对于一个密钥值，RC4算法产生一个密钥值的流$k_1^{IV},k_2^{IV},k_2^{IV},..., k_i^{IV}$，这些密码值用于加密一帧中的数据和CRC值
    - 我们可以认为每次对一个字节执行这些操作。通过吧数据的第i字节$d_i$和由($K_S$、IV)对生成的密钥值流中的第i个密钥$k_i^{IV}$执行异或操作加密
        - $c_i = d_i \bigoplus k_i^{IV}$
    - IV的值逐帧变化，以明文的形式出现在每一WEP加密的802.11帧首部中，接收方取它与发送方共享的40比特对称密钥，添加上该IV，并使用形成的64比特的密钥来解密这个帧
        - $d_i = c_i \bigoplus k_i^{IV}$

| 802.11首部 | IV | WEP加密的数据加CRC |
|------------|----|--------------------|

正确使用RC4算法要求同一个64比特密钥绝不能使用超过1次。如果WEP密钥一帧一换，则只有$2^{24}$个不同的密钥可用。因此很可能会出现密钥相同的情况。此外，因为IV值以明文形式传输，攻击者会发现何时使用了一个重复的IV。

举个例子：假定攻击者Trudy(可能使用IP洪骗)向Alice发出一个请求(如HTTP请求)，要求Alice传输内容已知的文件$d_1, d_2, ...$，Trudy也观察到Alice发送的已加密数据$c_1, c_2, ...$，由于$d_i = c_i \bigoplus k_i^{IV}$，如果这个等式两边同时异或$c_i$得：

$$d_i \bigoplus c_i = k_i^{IV}$$

根据这个关系，Trudy就可以使用已知的$d_i$和$c_i$计算出$k_i^{IV}$。下一次Trudy看到使用同一IV是他知道这个密钥流$k_1^{IV},k_2^{IV}, ..$，并可使用这些密钥破解密文


#### IEEE 802.11i

具有更强安全性机制的802.11的新型、改进版本被称为802.11i。虽然WEP提供了相对较弱的加密、仅有单一方式执行鉴别并且没有密钥分发机制，但802.11i却提供了强得多的的加密形式、一种可扩展的鉴别机制集合以及一种密钥分发机制。

除了无线客户端和接入点外，802.11i定于i了一台鉴别服务器，AP能够与它通信。鉴别服务器与AP分离是的一台鉴别服务器服务器许多AP，集中在一台服务器中作出有关鉴别和接入的决定，降低了AP的成本和复杂性。

802.11i运行分为4个阶段：
- 1. 发现
    - 发现阶段，AP通告它的存在以及它能够向无线客户节点提供的鉴别和加密形式
    - 客户则请求它希望的特定鉴别和加密形式
    - 尽管客户和AP已经交换了报文，但该客户还没有鉴别，也没有加密密钥，因此在该客户能够通过无线信道与任何远程主机通信之前，还需要进行几个步骤
- 2. 相互鉴别和主密钥(MK)生成
    - 鉴别发生在无线客户和鉴别服务器之间。在这个阶段，接入点在客户和鉴别服务器之间转发报文
    - **可扩展鉴别协议(EAP)** 定义了客户和鉴别服务器之间交互时简单的请求/响应模式中使用的端到端报文格式
        - EAP报文使用EAPoL(EAP over LAN)进行封装，并通过802.11无线链路发送
        - 这些EAP报文在接入点拆封，然后再使用RADIUS协议重新封装，经UDP/IP传输到鉴别服务器
- 3. 成对主密钥(PMK)生成
    - MK是一个仅为客户和鉴别服务器所知的共享密钥，它们都使用MK来生成一个次密钥，即成对主密钥(PMK)
    - 鉴别服务器则向AP发送该PMK
    - 客户和AP现在具有一个共享的密钥，并彼此相互鉴别
- 4. 临时密钥(TK)生成
    - 使用PMK，无线客户和AP现在能够生成附加的、将用于通信的密钥。其中的关键是临时密钥，TK将被用于执行经无线链路向任意远程主机发送数据的加密
    





---


## TCP

面向连接的传输

三次握手
- 用户发送特殊的TCP报文
- 服务器用一个特殊的TCP报文回复
    - 两次握手后建立起连接
    - 连接建立后可以互相发送数据
- 最后用户通过第三次报文发送有效载荷


### TCP报文结构

TCP报文段首部包含一下字段:
- 源端口/目的端口
- 校验和
- 32比特的序号字段和确认号字段
- 16比特的接收窗口字段
    - 用于流量控制, 用于指示接收方愿意接受的字节数量
- 可选与变长的选项字段
- 4比特的首部长度字段
    - 因为首部长度是可变的
- 6比特的标志字段
    - ACK比特用于指示字段中的值是否有效
    - RSY, SYN, FIN比特用于连接的建立和拆除
    - URG比特用来指示报文里"紧急"数据
        - 紧急数据的最后一个字节由16比特的**紧急数据指针**字段指出

字段的具体表现
- 最大报文段长度(MSS)
    - TCP从缓存中取出并放入报文段是数据量受MSS限制
    - 应用层数据的最大长度
    - MSS通常由最初确定的由本机发送的最大链路层帧(MTU)长度设置
- 最大传输单元(MTU)
    - 如果链路层协议有1500字节的MTU, 报文首部长40字节, 则MSS长1460字节
- 一个报文的序号
    - 报文段首字节的字节流编号
        - 如一个500 000字节的文件, MSS为1000字节, 第一个首字节编号为0, 第二个为1000...
- 超时间隔计算
    - $TimeoutInterval = EstimatedRTT + 4DevRTT$
    - 每次重传时都会将超时间隔设置为上一个值的两倍
        - 应为有时真的很拥堵
        - 但是也不能这么一直的指数增长
        - 当接受到ACK后重新估计
        - 收到3个冗余ACK后执行快速重传
    - 往返时间(RTT)的估计: $EstimatedRTT = (1 - \alpha)EstimatedRTT + \alpha SampleRTT$
        - $\alpha$通常为0.125
        - 在某个时间会测量一次SampleRTT
    - 波动时间: $DevRTT = (1 - \beta)DevRTT + \beta{|SampleRTT - EstimatedRTT|}$
        - $\beta$通常为0.25
- 流量控制
    - 防止缓冲区溢出
- 拥塞控制
    - 当网络阻塞时遏制网络


#### TCP连接管理

TCP连接管理包括连接的建立和连接的关闭

连接建立的过程
- 1. 客户端向服务发送一个特殊的TCP报文
    - 不包含应用层数据
    - 首部标志位SYN设置为1
    - 客户端还会适当的随机选择一个初始序号(client\_isn), 置于序号字段中
- 2. 服务器回复
    - 服务器收到TCP SYN报文后提取数据, 并为TCP分配缓存和变量
    - 服务器将自己的初始序号(server\_isn)放到报文段中
        - SYN置为1
        - client\_isn + 1
    - 向客户端发送允许连接的报文段
        - 允许连接的报文段有时候被称为**SYNACK报文段**
- 3. 客户端向服务器
    - 客户端也要为连接分配缓存和变量
    - 段对服务器的允许报文进行确认
        - 通过server\_isn + 1放置在报文段中进行确认
        - SYN置为0
    - 可以在报文段中携带客户到服务器的数据

三次握手完成后客户端便可与服务器相互通信. 但是如果只进行了前两次握手, 分配了资源, 但是没有第三次握手就会造成大量资源浪费. **SYN洪泛攻击**就是利用这点. 现在的一种有效的防御系统称为**SYN cookie**

连接关闭
- 客户端向服务器发送
    - 标志位FIN置为1
    - 服务器确认后回复(ACK)
- 服务器向客户端发生它自己的终止报文
    - 标志位FIN置为1
    - 客户端确认后回复(ACK)
- 连接资源释放


#### 拥塞控制的原理

拥塞原因
- 情况1: 两个发送方和一台有无限大缓存的路由器
    - 假设共用的链路吞吐量为R
    - 当两个发送方都以R/2的速率发送时, 速率达到最优
    - 由于共用的吞吐量有限, 当超过R/2时, 排队队列会趋于无限大, 平均排队时间也无限大
- 情况2: 两个发送方和一台有限大缓存的路由器
    - 存在缓存溢出, 溢出部分还得重传
- 情况3: 四个发送方和有无限大缓存的路由器以及多跳路径

拥塞控制的方法
- 端到端拥塞控制
    - 网络层没有提供显示支持
- 网络辅助的拥塞控制
    - 网络层构件(即路由器)向发送方提供拥塞状态的反馈信息(拥塞分组)
        - 可以有路由器直接发给发送方
        - 也可是路由器标记或更新发送发向接受方的分组, 以提示接收方, 再由接收方提示发送方
            - 会多一个完整的往返时间

**网络辅助的拥塞控制例子: ATM ABR拥塞控制**
- 数据中夹杂着所谓的**资源管理信元(RM信元)**
    - 这些信元用来在主机和交换机之间传递拥塞信息
    - 默认32个数据信元中有一个RM信元
- EFCI比特(显示转发拥塞指示)
    - 拥塞的网络交换机可以把数据信元中的EFCI比特设置为1来向主机发送网络已拥塞的信令
    - 如果多数近来收到EFCI为1,则目的地将RM信元的拥塞指示比特(CI比特)设置为1, 并把该信元发送回发送方
- CI和NI比特
    - CI比特是RM信元中拥塞指示(Congestion Indication, CI)比特
    - NI比特是RM信元中的无增长(No Increase)比特
    - 交换机可以在轻微拥塞时将NI比特设置为1, 在严重拥塞时将CI比特设置为1
- ER的设置
    - 每个RM信元还包含一个两字节的显示速率(Explicit Rate, ER)字段
    - 拥塞的交换机也许会降低经过的信元中ER的值


#### TCP拥塞控制

TCP必须使用端到端拥塞控制而不是使用网络辅助拥塞控制, 因为IP层不向端系统提供显示的网络拥塞反馈. TCP采用的方法是让每个发送方根据所感知的网络拥塞程度来限制其能向连接发送流量的速率.

- 限制流量的方式, 拥塞窗口(congestion window, cwnd)
    - 限制发送流量的速率, 就是流水线的窗口的作用
- 拥塞感知
    - 一个丢失的报文(超时或3个冗余)意味着拥塞
    - 一个确认报文指示能正常接收, 不拥塞
    - 宽带探测, 通过改变速率和检测丢包, ACK来探测
- 速率修改的策略
    - TCP拥塞控制算法
        - 1. 慢启动
        - 2. 拥塞避免
        - 3. 快速恢复
        - 慢启动和拥塞避免是TCP的强制部分

**TCP拥塞控制算法**
- 慢启动
    - 开始时cwnd设置为一个MSS的较小值, 大约为MSS/RTT
    - 如果都是ACK回复, 则一个RTT发送速率就会翻番
    - 指数增长
    - 慢启动结束的第一种标志: 当遇到超时引发的丢包现象时, 将拥塞阀值ssthresh设置为cwnd/2, 然后将cwnd设置为1, 重新开始慢启动
    - 慢启动结束的第二种标志: 达到阀值
    - 慢启动结束的第一种标志: 当遇到3个ACK冗余引发的丢包现象时, 进入快速恢复状态
- 拥塞避免
    - 当cnwd达到阀值ssthresh时, 进入拥塞避免模式, cnwd不再指数增长, 而是每个RTT增加一个MSS
- 快速恢复
    - 很多变种, 不一一陈述, 如冗余丢包后cwnd=ssthresh+1等

TCP拥塞控制常被称为加性增, 乘性减(AIMD)拥塞控制方式


## UDP

无连接传输

优点
- 控制更加精细
    - TCP的拥塞控制机制在链路变得拥塞时来遏制运输层的TCP发送方. 
    - TCP会不惜一切时间代价来确认报文被接收且确认, 对于有最小发送速率要求的应用不友好.
    - 对于不希望过分延时但能容忍一些数据丢失的应用来说是好的
- 无需连接建立
    - TCP需要三次握手, 而UDP不会, 故UDP不会引入建立连接时延
- 无状态连接
    - TCP需要维护连接状态, 接收和发送缓存, 拥塞控制参数以及确认号的参数等等
- 首部开销很小

**UDP提供了差错检测**, 通过在报文中添加校验和(checksum). 校验和工作原理如下

``` 
将报文段中 所有的16比特字的和 进行反码运算, 求和时遇到任何溢出都被回卷.
得到的结果放在报文的校验和字段中. 接收方收到后将所有16比特字和检验和相加应该得到16个1

简单举例: 要三个字段
10011
00111
01111

10011
00111
-------
11010
01111
-------
01001

checksum: 10110 # 和的反码
```
